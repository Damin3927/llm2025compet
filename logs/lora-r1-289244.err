++ date
+ echo '===== ジョブ開始: Fri Jul 25 06:50:30 PM JST 2025 ====='
++ pwd
+ echo 'cwd  = /home/Competition2025/P02/P02U006/ColossalAI'
++ hostname
+ echo 'host = osk-gpu54'
+ echo 'JOB  = 289244'
+ echo 'NODES= osk-gpu[54,56,91]'
+ source /home/Competition2025/P02/P02U006/miniconda3/etc/profile.d/conda.sh
++ export CONDA_EXE=/home/Competition2025/P02/P02U006/miniconda3/bin/conda
++ CONDA_EXE=/home/Competition2025/P02/P02U006/miniconda3/bin/conda
++ export _CE_M=
++ _CE_M=
++ export _CE_CONDA=
++ _CE_CONDA=
++ export CONDA_PYTHON_EXE=/home/Competition2025/P02/P02U006/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/home/Competition2025/P02/P02U006/miniconda3/bin/python
++ '[' -z x ']'
+ conda activate deepseeksft310
+ local cmd=activate
+ case "$cmd" in
+ __conda_activate activate deepseeksft310
+ '[' -n '' ']'
+ local ask_conda
++ PS1=
++ __conda_exe shell.posix activate deepseeksft310
++ '[' -n '' ']'
++ /home/Competition2025/P02/P02U006/miniconda3/bin/conda shell.posix activate deepseeksft310
+ ask_conda='unset _CE_M
unset _CE_CONDA
PS1='\''(deepseeksft310) '\''
export PATH='\''/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/condabin:/home/Competition2025/P02/P02U006/.local/bin:/home/Competition2025/P02/P02U006/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(deepseeksft310) '\''
export CONDA_EXE='\''/home/Competition2025/P02/P02U006/miniconda3/bin/conda'\''
export CONDA_PYTHON_EXE='\''/home/Competition2025/P02/P02U006/miniconda3/bin/python'\'''
+ eval 'unset _CE_M
unset _CE_CONDA
PS1='\''(deepseeksft310) '\''
export PATH='\''/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/condabin:/home/Competition2025/P02/P02U006/.local/bin:/home/Competition2025/P02/P02U006/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin'\''
export CONDA_SHLVL='\''1'\''
export CONDA_PROMPT_MODIFIER='\''(deepseeksft310) '\''
export CONDA_EXE='\''/home/Competition2025/P02/P02U006/miniconda3/bin/conda'\''
export CONDA_PYTHON_EXE='\''/home/Competition2025/P02/P02U006/miniconda3/bin/python'\'''
++ unset _CE_M
++ unset _CE_CONDA
++ PS1='(deepseeksft310) '
++ export PATH=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/condabin:/home/Competition2025/P02/P02U006/.local/bin:/home/Competition2025/P02/P02U006/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
++ PATH=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/condabin:/home/Competition2025/P02/P02U006/.local/bin:/home/Competition2025/P02/P02U006/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
++ export CONDA_SHLVL=1
++ CONDA_SHLVL=1
++ export 'CONDA_PROMPT_MODIFIER=(deepseeksft310) '
++ CONDA_PROMPT_MODIFIER='(deepseeksft310) '
++ export CONDA_EXE=/home/Competition2025/P02/P02U006/miniconda3/bin/conda
++ CONDA_EXE=/home/Competition2025/P02/P02U006/miniconda3/bin/conda
++ export CONDA_PYTHON_EXE=/home/Competition2025/P02/P02U006/miniconda3/bin/python
++ CONDA_PYTHON_EXE=/home/Competition2025/P02/P02U006/miniconda3/bin/python
+ __conda_hashr
+ '[' -n '' ']'
+ '[' -n '' ']'
+ hash -r
+ export FLASH_ATTENTION_DISABLE=1
+ FLASH_ATTENTION_DISABLE=1
+ export HF_TRANSFORMERS_CACHE_DISABLE_FLASH_ATTN_2=1
+ HF_TRANSFORMERS_CACHE_DISABLE_FLASH_ATTN_2=1
+ echo FLASH_ATTENTION_DISABLE=1
+ echo HF_TRANSFORMERS_CACHE_DISABLE_FLASH_ATTN_2=1
+ export MASTER_PORT=21244
+ MASTER_PORT=21244
+ srun colossalai run --master_port 21244 --nproc_per_node 8 /home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py --pretrained /home/Competition2025/P02/shareP02/DeepSeek-R1-0528-BF16 --dataset /home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_sft_data.jsonl --plugin zero2 --pp 3 --ep 8 --batch_size 24 --lr 2e-5 --max_length 256 --lora_rank 8 --lora_alpha 16 --num_epochs 2 --warmup_steps 100 --mixed_precision bf16 --use_grad_checkpoint --tensorboard_dir logs/tb --save_dir DeepSeek-R1-0528-lora
W0725 18:50:35.319000 23352651859008 torch/distributed/run.py:779] 
W0725 18:50:35.319000 23352651859008 torch/distributed/run.py:779] *****************************************
W0725 18:50:35.319000 23352651859008 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0725 18:50:35.319000 23352651859008 torch/distributed/run.py:779] *****************************************
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
W0725 18:50:35.421000 22897728083008 torch/distributed/run.py:779] 
W0725 18:50:35.421000 22897728083008 torch/distributed/run.py:779] *****************************************
W0725 18:50:35.421000 22897728083008 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0725 18:50:35.421000 22897728083008 torch/distributed/run.py:779] *****************************************
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
E0725 18:50:35.488000 23352651859008 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3373636) of binary: /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
IndentationError: unexpected indent
Traceback (most recent call last):
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu56
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3373637)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu56
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3373638)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu56
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 3373639)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu56
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 3373640)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu56
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 3373641)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu56
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 3373642)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu56
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 3373643)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu56
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3373636)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
E0725 18:50:35.593000 22897728083008 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 785552) of binary: /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
Traceback (most recent call last):
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu91
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 785553)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu91
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 785554)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu91
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 785555)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu91
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 785556)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu91
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 785558)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu91
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 785559)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu91
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 785560)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-25_18:50:35
  host      : osk-gpu91
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 785552)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
W0725 18:50:35.916000 22690134197312 torch/distributed/run.py:779] 
W0725 18:50:35.916000 22690134197312 torch/distributed/run.py:779] *****************************************
W0725 18:50:35.916000 22690134197312 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0725 18:50:35.916000 22690134197312 torch/distributed/run.py:779] *****************************************
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
srun: error: osk-gpu56: task 1: Exited with exit code 1
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
  File "/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py", line 148
    with open(args.config_file, "w") as f:
IndentationError: unexpected indent
E0725 18:50:36.095000 22690134197312 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3608472) of binary: /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
Traceback (most recent call last):
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2025-07-25_18:50:36
  host      : osk-gpu54
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3608473)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2025-07-25_18:50:36
  host      : osk-gpu54
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 3608474)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2025-07-25_18:50:36
  host      : osk-gpu54
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 3608475)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2025-07-25_18:50:36
  host      : osk-gpu54
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 3608476)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2025-07-25_18:50:36
  host      : osk-gpu54
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 3608477)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2025-07-25_18:50:36
  host      : osk-gpu54
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 3608478)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2025-07-25_18:50:36
  host      : osk-gpu54
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 3608479)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-07-25_18:50:36
  host      : osk-gpu54
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3608472)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: osk-gpu91: task 2: Exited with exit code 1
srun: error: osk-gpu54: task 0: Exited with exit code 1
