===== ジョブ開始: Fri Aug  1 04:35:34 PM JST 2025 =====
cwd  = /home/Competition2025/P02/P02U006/ColossalAI
host = osk-gpu54
JOB  = 312303
NODES= osk-gpu[54,56,91]
FLASH_ATTENTION_DISABLE=1
HF_TRANSFORMERS_CACHE_DISABLE_FLASH_ATTN_2=1
=== CUDA環境 ===
CUDA_HOME=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/nvcc
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2025 NVIDIA Corporation
Built on Tue_May_27_02:21:03_PDT_2025
Cuda compilation tools, release 12.9, V12.9.86
Build cuda_12.9.r12.9/compiler.36037853_0
=== Pythonライブラリのバージョン ===
python 3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0]
torch 2.4.1+cu124
torchvision 0.19.1+cu124
torchaudio 2.4.1+cu124
numpy 1.26.4
please install Colossal-AI from https://www.colossalai.org/download or from source
colossalai 0.0.0
transformers 4.46.3
PATH=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/condabin:/home/Competition2025/P02/P02U006/.local/bin:/home/Competition2025/P02/P02U006/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
LD_LIBRARY_PATH=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
CPATH=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/nvidia/cublas/include:
LIBRARY_PATH=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
MASTER_ADDR=osk-gpu54  MASTER_PORT=24303
== [Pre-launch NCCL env] ==
NCCL_NET_PLUGIN=none
NCCL_SOCKET_IFNAME=mlx5_0
NCCL_DEBUG=INFO
NCCL_TIMEOUT=900
NCCL_IB_HCA=mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
TORCH_NCCL_BLOCKING_WAIT=1
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
on master: osk-gpu54
== [Pre-launch NCCL env (inside srun block)] ==
NCCL_NET_PLUGIN=none
NCCL_SOCKET_IFNAME=enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_DEBUG=INFO
NCCL_TIMEOUT=900
NCCL_IB_HCA=mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
TORCH_NCCL_BLOCKING_WAIT=1
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/colossalai
/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python
/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/torchrun
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from sourceplease install Colossal-AI from https://www.colossalai.org/download or from source

please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
dataset size: 2160
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=True  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
[DEBUG] Creating tensorboard dir: /home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] Tensorboard SummaryWriter created
[DEBUG] Saving config to training_config.json
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
[08/01/25 16:36:43] INFO     colossalai - colossalai - INFO:                    
                             /home/Competition2025/P02/P02U006/ColossalAI/coloss
                             alai/initialize.py:75 launch                       
                    INFO     colossalai - colossalai - INFO: Distributed        
                             environment is initialized, world size: 24         
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
Training Info:
Config file: training_config.json 
Tensorboard logs: /home/Competition2025/P02/P02U006/ColossalAI/logs/tb 
Model checkpoint: /home/Competition2025/P02/P02U006/ColossalAI/DeepSeek-R1-0528-lora
Load dataset: /home/Competition2025/P02/shareP02/hci_colossalai_deepseekr10528_lorasft.jsonl
dataset size: 2160
dataloader batch_size: 8, total batches: 33
Max device memory after data loader: 0.00 MB
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.04562115669250488 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 1.779956579208374 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 1.4058098793029785 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.08610057830810547 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 1.2055959701538086 seconds
[extension] Time taken to load cpu_adam_x86 op: 0.50760817527771 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.07771110534667969 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 0.20456862449645996 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.8051338195800781 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.11184287071228027 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 1.7496709823608398 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 2.4069929122924805 seconds
[extension] Time taken to load cpu_adam_x86 op: 3.7084529399871826 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 2.006338596343994 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.08046507835388184 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 3.1079139709472656 seconds
[extension] Time taken to load cpu_adam_x86 op: 2.6086530685424805 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.08330726623535156 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 3.3083786964416504 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.08312368392944336 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 0.20478272438049316 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 0.3045308589935303 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 2.7071964740753174 seconds
[extension] Time taken to load fused_optim_cuda op: 0.3034226894378662 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 3.108206272125244 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 4.109114646911621 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.08298659324645996 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 0.10393142700195312 seconds
[extension] Time taken to load fused_optim_cuda op: 0.10306334495544434 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 2.2056500911712646 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 3.109520196914673 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.0728151798248291 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[08/01/25 16:40:33] WARNING  colossalai - colossalai - WARNING:                 
                             /home/Competition2025/P02/P02U006/ColossalAI/coloss
                             alai/booster/plugin/hybrid_parallel_plugin.py:1518 
                             enable_lora                                        
                    WARNING  colossalai - colossalai - WARNING: You have enabled
                             LoRa training. Please check the hyperparameters    
                             such as lr                                         
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ====== [Debug] Gradient checkpointing enabled successfully ===
Gradient checkpointing enabled successfully
=== [Debug] model was about to set to eval mode, but disabled ===

=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] model was about to set to eval mode, but disabled ===
Model params: 671.03 B
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.23853302001953125 seconds
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.22396445274353027 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.1733715534210205 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 2.045619249343872 seconds
[extension] Time taken to load fused_optim_cuda op: 2.2122962474823 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 2.211765766143799 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 2.1366512775421143 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.47106361389160156 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.16690993309020996 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.11151814460754395 seconds
[extension] Time taken to load fused_optim_cuda op: 0.10448884963989258 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 0.2296006679534912 seconds
[extension] Time taken to load cpu_adam_x86 op: 0.2319793701171875 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.35446715354919434 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 0.40452051162719727 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 0.4046955108642578 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
Default dtype set to torch.bfloat16
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
Error: failed to run torchrun --nproc_per_node=8 --nnodes=3 --node_rank=2 --master_addr=osk-gpu54 --master_port=24303 /home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py --pretrained /home/Competition2025/P02/shareP02/DeepSeek-R1-0528-BF16 --dataset /home/Competition2025/P02/shareP02/hci_colossalai_deepseekr10528_lorasft.jsonl --plugin moe --pp 3 --ep 8 --batch_size 8 --lr 2e-5 --max_length 256 --lora_rank 8 --lora_alpha 16 --num_epochs 2 --warmup_steps 8 --mixed_precision bf16 --use_grad_checkpoint --tensorboard_dir /home/Competition2025/P02/P02U006/ColossalAI/logs/tb --save_dir /home/Competition2025/P02/P02U006/ColossalAI/DeepSeek-R1-0528-lora on osk-gpu91, is localhost: False, exception: Encountered a bad command exit code!

Command: 'cd /home/Competition2025/P02/P02U006/ColossalAI && export SHELL="/bin/bash" SLURM_GPUS_PER_NODE="8" GCC_RANLIB="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gcc-ranlib" SLURM_STEP_NUM_TASKS="1" SLURM_JOB_USER="P02U006" SLURM_TASKS_PER_NODE="1" SLURM_JOB_UID="11034" SLURM_STEP_GPUS="0,1,2,3,4,5,6,7" HISTCONTROL="ignoredups" SLURM_TASK_PID="986591" CONDA_EXE="/home/Competition2025/P02/P02U006/miniconda3/bin/conda" SLURM_JOB_GPUS="0,1,2,3,4,5,6,7" PMIX_HOSTNAME="osk-gpu54" SLURM_LOCALID="0" build_alias="x86_64-conda-linux-gnu" SLURM_SUBMIT_DIR="/home/Competition2025/P02/P02U006/ColossalAI" CMAKE_ARGS="-DCMAKE_AR=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ar -DCMAKE_RANLIB=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ranlib -DCMAKE_LINKER=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ld -DCMAKE_STRIP=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-strip -DCMAKE_BUILD_TYPE=Release" HISTSIZE="1000" HOSTNAME="osk-gpu54" SLURMD_NODENAME="osk-gpu54" FLASH_ATTENTION_DISABLE="1" PMIX_SECURITY_MODE="munge,native" MASTER_PORT="24303" GPROF="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gprof" _CONDA_PYTHON_SYSCONFIGDATA_NAME="_sysconfigdata_x86_64_conda_cos7_linux_gnu" SLURM_STEP_NODELIST="osk-gpu54" STRINGS="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-strings" CPP="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-cpp" NCCL_NET_PLUGIN="none" SLURM_NODE_ALIASES="(null)" SLURM_CLUSTER_NAME="osk-cluster" SLURM_CPUS_ON_NODE="2" SLURM_UMASK="0022" SLURM_JOB_CPUS_PER_NODE="2(x3)" NCCL_SOCKET_IFNAME="enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0" PMIX_GDS_MODULE="ds21,ds12,hash" SLURM_GPUS_ON_NODE="8" PWD="/home/Competition2025/P02/P02U006/ColossalAI" SLURM_GTIDS="0" GSETTINGS_SCHEMA_DIR="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/share/glib-2.0/schemas" LOGNAME="P02U006" UCX_NET_DEVICES="mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1" XDG_SESSION_TYPE="tty" CONDA_PREFIX="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310" SLURM_JOB_PARTITION="P02" MODULESHOME="/usr/share/Modules" MANPATH="/usr/share/man:" ROCR_VISIBLE_DEVICES="0,1,2,3,4,5,6,7" NCCL_DEBUG="INFO" SLURM_JOB_NUM_NODES="3" CXX="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++" CXXFLAGS="-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include  -I/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include" SRUN_DEBUG="3" PMIX_SYSTEM_TMPDIR="/tmp" SLURM_STEPID="0" NCCL_TIMEOUT="900" SLURM_JOBID="312303" GLOO_SOCKET_IFNAME="mlx5_0" NCCL_IB_HCA="mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1" DEBUG_CXXFLAGS="-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -ffunction-sections -pipe -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include" SLURM_LAUNCH_NODE_IPADDR="192.168.11.54" SLURM_JOB_QOS="normal" PMIX_BFROP_BUFFER_TYPE="PMIX_BFROP_BUFFER_NON_DESC" MOTD_SHOWN="pam" TORCH_NCCL_BLOCKING_WAIT="1" PMIX_PTL_MODULE="tcp,usock" LDFLAGS="-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib -Wl,-rpath-link,/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib -L/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib  -L/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib -L/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib/stubs" __MODULES_SHARE_MANPATH=":1" HOME="/home/Competition2025/P02/P02U006" LANG="en_US.UTF-8" PMIX_DSTORE_21_BASE_PATH="/var/spool/slurm/d/pmix.312303.0//pmix_dstor_ds21_986582" DEBUG_CFLAGS="-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -ffunction-sections -pipe -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include" LS_COLORS="rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.m4a=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.oga=01;36:*.opus=01;36:*.spx=01;36:*.xspf=01;36:" NVCC_PREPEND_FLAGS=" -ccbin=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++ -ccbin=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++" SLURM_PROCID="0" PMIX_VERSION="3.2.3" CXX_FOR_BUILD="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++" HF_TRANSFORMERS_CACHE_DISABLE_FLASH_ATTN_2="1" ELFEDIT="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-elfedit" CONDA_PROMPT_MODIFIER="(deepseeksft310) " TMPDIR="/tmp" CMAKE_PREFIX_PATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/x86_64-conda-linux-gnu/sysroot/usr" CUDACXX="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/nvcc" CPPFLAGS="-DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include  -I/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include" SLURM_NTASKS="1" LD="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ld" SLURM_TOPOLOGY_ADDR="osk-gpu54" SSH_CONNECTION="100.113.255.13 65029 10.255.255.101 22" SLURM_PMIX_MAPPING_SERV="(vector,(0,1,1))" PMIX_RANK="0" PMIX_SERVER_URI2="pmix-server.986582;tcp4://127.0.0.1:51367" PMIX_SERVER_URI3="pmix-server.986582;tcp4://127.0.0.1:51367" SLURM_DISTRIBUTION="cyclic" READELF="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-readelf" ZE_AFFINITY_MASK="0,1,2,3,4,5,6,7" PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True" GXX="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-g++" MASTER_ADDR="osk-gpu54" CUDA_VISIBLE_DEVICES="0,1,2,3,4,5,6,7" SLURM_TOPOLOGY_ADDR_PATTERN="node" GCC_AR="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gcc-ar" SLURM_SRUN_COMM_HOST="192.168.11.54" SLURM_PMIXP_ABORT_AGENT_PORT="38559" ADDR2LINE="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-addr2line" XDG_SESSION_CLASS="user" SLURM_WORKING_CLUSTER="osk-cluster:10.255.255.100:6817:9728:109" PYTHONPATH="/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat:/home/Competition2025/P02/P02U006/ColossalAI:" PMIX_SERVER_URI21="pmix-server.986582;tcp4://127.0.0.1:51367" TERM="xterm-256color" GCC_NM="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gcc-nm" SIZE="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-size" TORCH_NCCL_ASYNC_ERROR_HANDLING="1" HOST="x86_64-conda-linux-gnu" LESSOPEN="||/usr/bin/lesspipe.sh %s" CC_FOR_BUILD="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-cc" PMIX_DSTORE_ESH_BASE_PATH="/var/spool/slurm/d/pmix.312303.0//pmix_dstor_ds12_986582" USER="P02U006" LIBRARY_PATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:" SLURM_NODELIST="osk-gpu[54,56,91]" ENVIRONMENT="BATCH" GPU_DEVICE_ORDINAL="0,1,2,3,4,5,6,7" CONDA_SHLVL="1" SLURM_SRUN_COMM_PORT="35519" MODULES_RUN_QUARANTINE="LD_LIBRARY_PATH LD_PRELOAD" AR="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ar" AS="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-as" DEBUG_CPPFLAGS="-D_DEBUG -D_FORTIFY_SOURCE=2 -Og -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include" SLURM_STEP_ID="0" SLURM_PRIO_PROCESS="0" host_alias="x86_64-conda-linux-gnu" SLURM_NPROCS="1" PYTHONFAULTHANDLER="1" SHLVL="2" SLURM_NNODES="1" NM="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-nm" GCC="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gcc" PMIX_MCA_gds="^ds12" XDG_SESSION_ID="48054" SLURM_SUBMIT_HOST="osk-cpu01" PMIX_SERVER_TMPDIR="/var/spool/slurm/d/pmix.312303.0/" LD_GOLD="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ld.gold" CONDA_PYTHON_EXE="/home/Competition2025/P02/P02U006/miniconda3/bin/python" LD_LIBRARY_PATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:" SLURM_JOB_CPUS_PER_NODE_PACK_GROUP_0="2(x3)" XDG_RUNTIME_DIR="/run/user/11034" SLURM_JOB_ID="312303" UCX_MAX_RNDV_RAILS="8" SLURM_NODEID="0" SLURM_STEP_NUM_NODES="1" SSH_CLIENT="100.113.255.13 65029 22" CONDA_DEFAULT_ENV="deepseeksft310" __MODULES_LMINIT="module use --append /home/appli/modulefiles:module use --append /usr/share/Modules/modulefiles:module use --append /etc/modulefiles:module use --append /usr/share/modulefiles" OBJCOPY="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-objcopy" OMPI_MCA_coll_hcoll_enable="0" PMIX_NAMESPACE="slurm.pmix.312303.0" which_declare="declare -f" SLURM_STEP_TASKS_PER_NODE="1" STRIP="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-strip" CUDA_HOME="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310" SLURM_MPI_TYPE="pmix_v3" NVCC_PREPEND_FLAGS_BACKUP=" -ccbin=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++" XDG_DATA_DIRS="/home/Competition2025/P02/P02U006/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share" OBJDUMP="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-objdump" SLURM_CONF="/etc/slurm/slurm.conf" PATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/condabin:/home/Competition2025/P02/P02U006/.local/bin:/home/Competition2025/P02/P02U006/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin" SLURM_JOB_NAME="lora-r1" MODULEPATH="/etc/scl/modulefiles:/etc/scl/modulefiles:/home/appli/modulefiles:/usr/share/Modules/modulefiles:/etc/modulefiles:/usr/share/modulefiles" CC="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-cc" SLURM_NTASKS_PER_NODE="1" CFLAGS="-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include  -I/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include" CXXFILT="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++filt" DBUS_SESSION_BUS_ADDRESS="unix:path=/run/user/11034/bus" BUILD="x86_64-conda-linux-gnu" MAIL="/var/spool/mail/P02U006" SSH_TTY="/dev/pts/92" SLURM_STEP_LAUNCHER_PORT="35519" SLURM_JOB_GID="11034" CPATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/nvidia/cublas/include:" RANLIB="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ranlib" CONDA_BUILD_SYSROOT="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/x86_64-conda-linux-gnu/sysroot" UCX_MAX_EAGER_RAILS="8" OLDPWD="/home/Competition2025/P02/P02U006/ColossalAI/logs" SLURM_JOB_NODELIST="osk-gpu[54,56,91]" MODULES_CMD="/usr/share/Modules/libexec/modulecmd.tcl" _="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/colossalai" CUDA_DEVICE_MAX_CONNECTIONS="1" && torchrun --nproc_per_node=8 --nnodes=3 --node_rank=2 --master_addr=osk-gpu54 --master_port=24303 /home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py --pretrained /home/Competition2025/P02/shareP02/DeepSeek-R1-0528-BF16 --dataset /home/Competition2025/P02/shareP02/hci_colossalai_deepseekr10528_lorasft.jsonl --plugin moe --pp 3 --ep 8 --batch_size 8 --lr 2e-5 --max_length 256 --lora_rank 8 --lora_alpha 16 --num_epochs 2 --warmup_steps 8 --mixed_precision bf16 --use_grad_checkpoint --tensorboard_dir /home/Competition2025/P02/P02U006/ColossalAI/logs/tb --save_dir /home/Competition2025/P02/P02U006/ColossalAI/DeepSeek-R1-0528-lora'

Exit code: 1

Stdout: already printed

Stderr: already printed


==== for epoch in range(0, 2) Start ====
Booster init max device memory: 59297.77 MB
Booster init max CPU memory: 24101.80 MB
==== for epoch in range(0, 2) Start ====
==== for epoch in range(0, 2) Start ====
Error: failed to run torchrun --nproc_per_node=8 --nnodes=3 --node_rank=1 --master_addr=osk-gpu54 --master_port=24303 /home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py --pretrained /home/Competition2025/P02/shareP02/DeepSeek-R1-0528-BF16 --dataset /home/Competition2025/P02/shareP02/hci_colossalai_deepseekr10528_lorasft.jsonl --plugin moe --pp 3 --ep 8 --batch_size 8 --lr 2e-5 --max_length 256 --lora_rank 8 --lora_alpha 16 --num_epochs 2 --warmup_steps 8 --mixed_precision bf16 --use_grad_checkpoint --tensorboard_dir /home/Competition2025/P02/P02U006/ColossalAI/logs/tb --save_dir /home/Competition2025/P02/P02U006/ColossalAI/DeepSeek-R1-0528-lora on osk-gpu56, is localhost: False, exception: Encountered a bad command exit code!

Command: 'cd /home/Competition2025/P02/P02U006/ColossalAI && export SHELL="/bin/bash" SLURM_GPUS_PER_NODE="8" GCC_RANLIB="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gcc-ranlib" SLURM_STEP_NUM_TASKS="1" SLURM_JOB_USER="P02U006" SLURM_TASKS_PER_NODE="1" SLURM_JOB_UID="11034" SLURM_STEP_GPUS="0,1,2,3,4,5,6,7" HISTCONTROL="ignoredups" SLURM_TASK_PID="986591" CONDA_EXE="/home/Competition2025/P02/P02U006/miniconda3/bin/conda" SLURM_JOB_GPUS="0,1,2,3,4,5,6,7" PMIX_HOSTNAME="osk-gpu54" SLURM_LOCALID="0" build_alias="x86_64-conda-linux-gnu" SLURM_SUBMIT_DIR="/home/Competition2025/P02/P02U006/ColossalAI" CMAKE_ARGS="-DCMAKE_AR=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ar -DCMAKE_RANLIB=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ranlib -DCMAKE_LINKER=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ld -DCMAKE_STRIP=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-strip -DCMAKE_BUILD_TYPE=Release" HISTSIZE="1000" HOSTNAME="osk-gpu54" SLURMD_NODENAME="osk-gpu54" FLASH_ATTENTION_DISABLE="1" PMIX_SECURITY_MODE="munge,native" MASTER_PORT="24303" GPROF="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gprof" _CONDA_PYTHON_SYSCONFIGDATA_NAME="_sysconfigdata_x86_64_conda_cos7_linux_gnu" SLURM_STEP_NODELIST="osk-gpu54" STRINGS="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-strings" CPP="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-cpp" NCCL_NET_PLUGIN="none" SLURM_NODE_ALIASES="(null)" SLURM_CLUSTER_NAME="osk-cluster" SLURM_CPUS_ON_NODE="2" SLURM_UMASK="0022" SLURM_JOB_CPUS_PER_NODE="2(x3)" NCCL_SOCKET_IFNAME="enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0" PMIX_GDS_MODULE="ds21,ds12,hash" SLURM_GPUS_ON_NODE="8" PWD="/home/Competition2025/P02/P02U006/ColossalAI" SLURM_GTIDS="0" GSETTINGS_SCHEMA_DIR="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/share/glib-2.0/schemas" LOGNAME="P02U006" UCX_NET_DEVICES="mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1" XDG_SESSION_TYPE="tty" CONDA_PREFIX="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310" SLURM_JOB_PARTITION="P02" MODULESHOME="/usr/share/Modules" MANPATH="/usr/share/man:" ROCR_VISIBLE_DEVICES="0,1,2,3,4,5,6,7" NCCL_DEBUG="INFO" SLURM_JOB_NUM_NODES="3" CXX="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++" CXXFLAGS="-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include  -I/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include" SRUN_DEBUG="3" PMIX_SYSTEM_TMPDIR="/tmp" SLURM_STEPID="0" NCCL_TIMEOUT="900" SLURM_JOBID="312303" GLOO_SOCKET_IFNAME="mlx5_0" NCCL_IB_HCA="mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1" DEBUG_CXXFLAGS="-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -ffunction-sections -pipe -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include" SLURM_LAUNCH_NODE_IPADDR="192.168.11.54" SLURM_JOB_QOS="normal" PMIX_BFROP_BUFFER_TYPE="PMIX_BFROP_BUFFER_NON_DESC" MOTD_SHOWN="pam" TORCH_NCCL_BLOCKING_WAIT="1" PMIX_PTL_MODULE="tcp,usock" LDFLAGS="-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib -Wl,-rpath-link,/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib -L/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib  -L/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib -L/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib/stubs" __MODULES_SHARE_MANPATH=":1" HOME="/home/Competition2025/P02/P02U006" LANG="en_US.UTF-8" PMIX_DSTORE_21_BASE_PATH="/var/spool/slurm/d/pmix.312303.0//pmix_dstor_ds21_986582" DEBUG_CFLAGS="-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -ffunction-sections -pipe -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include" LS_COLORS="rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.m4a=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.oga=01;36:*.opus=01;36:*.spx=01;36:*.xspf=01;36:" NVCC_PREPEND_FLAGS=" -ccbin=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++ -ccbin=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++" SLURM_PROCID="0" PMIX_VERSION="3.2.3" CXX_FOR_BUILD="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++" HF_TRANSFORMERS_CACHE_DISABLE_FLASH_ATTN_2="1" ELFEDIT="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-elfedit" CONDA_PROMPT_MODIFIER="(deepseeksft310) " TMPDIR="/tmp" CMAKE_PREFIX_PATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/x86_64-conda-linux-gnu/sysroot/usr" CUDACXX="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/nvcc" CPPFLAGS="-DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include  -I/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include" SLURM_NTASKS="1" LD="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ld" SLURM_TOPOLOGY_ADDR="osk-gpu54" SSH_CONNECTION="100.113.255.13 65029 10.255.255.101 22" SLURM_PMIX_MAPPING_SERV="(vector,(0,1,1))" PMIX_RANK="0" PMIX_SERVER_URI2="pmix-server.986582;tcp4://127.0.0.1:51367" PMIX_SERVER_URI3="pmix-server.986582;tcp4://127.0.0.1:51367" SLURM_DISTRIBUTION="cyclic" READELF="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-readelf" ZE_AFFINITY_MASK="0,1,2,3,4,5,6,7" PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True" GXX="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-g++" MASTER_ADDR="osk-gpu54" CUDA_VISIBLE_DEVICES="0,1,2,3,4,5,6,7" SLURM_TOPOLOGY_ADDR_PATTERN="node" GCC_AR="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gcc-ar" SLURM_SRUN_COMM_HOST="192.168.11.54" SLURM_PMIXP_ABORT_AGENT_PORT="38559" ADDR2LINE="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-addr2line" XDG_SESSION_CLASS="user" SLURM_WORKING_CLUSTER="osk-cluster:10.255.255.100:6817:9728:109" PYTHONPATH="/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat:/home/Competition2025/P02/P02U006/ColossalAI:" PMIX_SERVER_URI21="pmix-server.986582;tcp4://127.0.0.1:51367" TERM="xterm-256color" GCC_NM="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gcc-nm" SIZE="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-size" TORCH_NCCL_ASYNC_ERROR_HANDLING="1" HOST="x86_64-conda-linux-gnu" LESSOPEN="||/usr/bin/lesspipe.sh %s" CC_FOR_BUILD="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-cc" PMIX_DSTORE_ESH_BASE_PATH="/var/spool/slurm/d/pmix.312303.0//pmix_dstor_ds12_986582" USER="P02U006" LIBRARY_PATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:" SLURM_NODELIST="osk-gpu[54,56,91]" ENVIRONMENT="BATCH" GPU_DEVICE_ORDINAL="0,1,2,3,4,5,6,7" CONDA_SHLVL="1" SLURM_SRUN_COMM_PORT="35519" MODULES_RUN_QUARANTINE="LD_LIBRARY_PATH LD_PRELOAD" AR="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ar" AS="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-as" DEBUG_CPPFLAGS="-D_DEBUG -D_FORTIFY_SOURCE=2 -Og -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include" SLURM_STEP_ID="0" SLURM_PRIO_PROCESS="0" host_alias="x86_64-conda-linux-gnu" SLURM_NPROCS="1" PYTHONFAULTHANDLER="1" SHLVL="2" SLURM_NNODES="1" NM="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-nm" GCC="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gcc" PMIX_MCA_gds="^ds12" XDG_SESSION_ID="48054" SLURM_SUBMIT_HOST="osk-cpu01" PMIX_SERVER_TMPDIR="/var/spool/slurm/d/pmix.312303.0/" LD_GOLD="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ld.gold" CONDA_PYTHON_EXE="/home/Competition2025/P02/P02U006/miniconda3/bin/python" LD_LIBRARY_PATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:" SLURM_JOB_CPUS_PER_NODE_PACK_GROUP_0="2(x3)" XDG_RUNTIME_DIR="/run/user/11034" SLURM_JOB_ID="312303" UCX_MAX_RNDV_RAILS="8" SLURM_NODEID="0" SLURM_STEP_NUM_NODES="1" SSH_CLIENT="100.113.255.13 65029 22" CONDA_DEFAULT_ENV="deepseeksft310" __MODULES_LMINIT="module use --append /home/appli/modulefiles:module use --append /usr/share/Modules/modulefiles:module use --append /etc/modulefiles:module use --append /usr/share/modulefiles" OBJCOPY="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-objcopy" OMPI_MCA_coll_hcoll_enable="0" PMIX_NAMESPACE="slurm.pmix.312303.0" which_declare="declare -f" SLURM_STEP_TASKS_PER_NODE="1" STRIP="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-strip" CUDA_HOME="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310" SLURM_MPI_TYPE="pmix_v3" NVCC_PREPEND_FLAGS_BACKUP=" -ccbin=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++" XDG_DATA_DIRS="/home/Competition2025/P02/P02U006/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share" OBJDUMP="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-objdump" SLURM_CONF="/etc/slurm/slurm.conf" PATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/condabin:/home/Competition2025/P02/P02U006/.local/bin:/home/Competition2025/P02/P02U006/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin" SLURM_JOB_NAME="lora-r1" MODULEPATH="/etc/scl/modulefiles:/etc/scl/modulefiles:/home/appli/modulefiles:/usr/share/Modules/modulefiles:/etc/modulefiles:/usr/share/modulefiles" CC="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-cc" SLURM_NTASKS_PER_NODE="1" CFLAGS="-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include  -I/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include" CXXFILT="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++filt" DBUS_SESSION_BUS_ADDRESS="unix:path=/run/user/11034/bus" BUILD="x86_64-conda-linux-gnu" MAIL="/var/spool/mail/P02U006" SSH_TTY="/dev/pts/92" SLURM_STEP_LAUNCHER_PORT="35519" SLURM_JOB_GID="11034" CPATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/nvidia/cublas/include:" RANLIB="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ranlib" CONDA_BUILD_SYSROOT="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/x86_64-conda-linux-gnu/sysroot" UCX_MAX_EAGER_RAILS="8" OLDPWD="/home/Competition2025/P02/P02U006/ColossalAI/logs" SLURM_JOB_NODELIST="osk-gpu[54,56,91]" MODULES_CMD="/usr/share/Modules/libexec/modulecmd.tcl" _="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/colossalai" CUDA_DEVICE_MAX_CONNECTIONS="1" && torchrun --nproc_per_node=8 --nnodes=3 --node_rank=1 --master_addr=osk-gpu54 --master_port=24303 /home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py --pretrained /home/Competition2025/P02/shareP02/DeepSeek-R1-0528-BF16 --dataset /home/Competition2025/P02/shareP02/hci_colossalai_deepseekr10528_lorasft.jsonl --plugin moe --pp 3 --ep 8 --batch_size 8 --lr 2e-5 --max_length 256 --lora_rank 8 --lora_alpha 16 --num_epochs 2 --warmup_steps 8 --mixed_precision bf16 --use_grad_checkpoint --tensorboard_dir /home/Competition2025/P02/P02U006/ColossalAI/logs/tb --save_dir /home/Competition2025/P02/P02U006/ColossalAI/DeepSeek-R1-0528-lora'

Exit code: 1

Stdout: already printed

Stderr: already printed


Error: failed to run torchrun --nproc_per_node=8 --nnodes=3 --node_rank=0 --master_addr=osk-gpu54 --master_port=24303 /home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py --pretrained /home/Competition2025/P02/shareP02/DeepSeek-R1-0528-BF16 --dataset /home/Competition2025/P02/shareP02/hci_colossalai_deepseekr10528_lorasft.jsonl --plugin moe --pp 3 --ep 8 --batch_size 8 --lr 2e-5 --max_length 256 --lora_rank 8 --lora_alpha 16 --num_epochs 2 --warmup_steps 8 --mixed_precision bf16 --use_grad_checkpoint --tensorboard_dir /home/Competition2025/P02/P02U006/ColossalAI/logs/tb --save_dir /home/Competition2025/P02/P02U006/ColossalAI/DeepSeek-R1-0528-lora on osk-gpu54, is localhost: True, exception: Encountered a bad command exit code!

Command: 'cd /home/Competition2025/P02/P02U006/ColossalAI && export SHELL="/bin/bash" SLURM_GPUS_PER_NODE="8" GCC_RANLIB="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gcc-ranlib" SLURM_STEP_NUM_TASKS="1" SLURM_JOB_USER="P02U006" SLURM_TASKS_PER_NODE="1" SLURM_JOB_UID="11034" SLURM_STEP_GPUS="0,1,2,3,4,5,6,7" HISTCONTROL="ignoredups" SLURM_TASK_PID="986591" CONDA_EXE="/home/Competition2025/P02/P02U006/miniconda3/bin/conda" SLURM_JOB_GPUS="0,1,2,3,4,5,6,7" PMIX_HOSTNAME="osk-gpu54" SLURM_LOCALID="0" build_alias="x86_64-conda-linux-gnu" SLURM_SUBMIT_DIR="/home/Competition2025/P02/P02U006/ColossalAI" CMAKE_ARGS="-DCMAKE_AR=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ar -DCMAKE_RANLIB=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ranlib -DCMAKE_LINKER=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ld -DCMAKE_STRIP=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-strip -DCMAKE_BUILD_TYPE=Release" HISTSIZE="1000" HOSTNAME="osk-gpu54" SLURMD_NODENAME="osk-gpu54" FLASH_ATTENTION_DISABLE="1" PMIX_SECURITY_MODE="munge,native" MASTER_PORT="24303" GPROF="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gprof" _CONDA_PYTHON_SYSCONFIGDATA_NAME="_sysconfigdata_x86_64_conda_cos7_linux_gnu" SLURM_STEP_NODELIST="osk-gpu54" STRINGS="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-strings" CPP="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-cpp" NCCL_NET_PLUGIN="none" SLURM_NODE_ALIASES="(null)" SLURM_CLUSTER_NAME="osk-cluster" SLURM_CPUS_ON_NODE="2" SLURM_UMASK="0022" SLURM_JOB_CPUS_PER_NODE="2(x3)" NCCL_SOCKET_IFNAME="enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0" PMIX_GDS_MODULE="ds21,ds12,hash" SLURM_GPUS_ON_NODE="8" PWD="/home/Competition2025/P02/P02U006/ColossalAI" SLURM_GTIDS="0" GSETTINGS_SCHEMA_DIR="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/share/glib-2.0/schemas" LOGNAME="P02U006" UCX_NET_DEVICES="mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1" XDG_SESSION_TYPE="tty" CONDA_PREFIX="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310" SLURM_JOB_PARTITION="P02" MODULESHOME="/usr/share/Modules" MANPATH="/usr/share/man:" ROCR_VISIBLE_DEVICES="0,1,2,3,4,5,6,7" NCCL_DEBUG="INFO" SLURM_JOB_NUM_NODES="3" CXX="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++" CXXFLAGS="-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include  -I/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include" SRUN_DEBUG="3" PMIX_SYSTEM_TMPDIR="/tmp" SLURM_STEPID="0" NCCL_TIMEOUT="900" SLURM_JOBID="312303" GLOO_SOCKET_IFNAME="mlx5_0" NCCL_IB_HCA="mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1" DEBUG_CXXFLAGS="-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -ffunction-sections -pipe -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include" SLURM_LAUNCH_NODE_IPADDR="192.168.11.54" SLURM_JOB_QOS="normal" PMIX_BFROP_BUFFER_TYPE="PMIX_BFROP_BUFFER_NON_DESC" MOTD_SHOWN="pam" TORCH_NCCL_BLOCKING_WAIT="1" PMIX_PTL_MODULE="tcp,usock" LDFLAGS="-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib -Wl,-rpath-link,/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib -L/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib  -L/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib -L/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib/stubs" __MODULES_SHARE_MANPATH=":1" HOME="/home/Competition2025/P02/P02U006" LANG="en_US.UTF-8" PMIX_DSTORE_21_BASE_PATH="/var/spool/slurm/d/pmix.312303.0//pmix_dstor_ds21_986582" DEBUG_CFLAGS="-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -ffunction-sections -pipe -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include" LS_COLORS="rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.m4a=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.oga=01;36:*.opus=01;36:*.spx=01;36:*.xspf=01;36:" NVCC_PREPEND_FLAGS=" -ccbin=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++ -ccbin=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++" SLURM_PROCID="0" PMIX_VERSION="3.2.3" CXX_FOR_BUILD="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++" HF_TRANSFORMERS_CACHE_DISABLE_FLASH_ATTN_2="1" ELFEDIT="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-elfedit" CONDA_PROMPT_MODIFIER="(deepseeksft310) " TMPDIR="/tmp" CMAKE_PREFIX_PATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/x86_64-conda-linux-gnu/sysroot/usr" CUDACXX="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/nvcc" CPPFLAGS="-DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include  -I/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include" SLURM_NTASKS="1" LD="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ld" SLURM_TOPOLOGY_ADDR="osk-gpu54" SSH_CONNECTION="100.113.255.13 65029 10.255.255.101 22" SLURM_PMIX_MAPPING_SERV="(vector,(0,1,1))" PMIX_RANK="0" PMIX_SERVER_URI2="pmix-server.986582;tcp4://127.0.0.1:51367" PMIX_SERVER_URI3="pmix-server.986582;tcp4://127.0.0.1:51367" SLURM_DISTRIBUTION="cyclic" READELF="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-readelf" ZE_AFFINITY_MASK="0,1,2,3,4,5,6,7" PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True" GXX="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-g++" MASTER_ADDR="osk-gpu54" CUDA_VISIBLE_DEVICES="0,1,2,3,4,5,6,7" SLURM_TOPOLOGY_ADDR_PATTERN="node" GCC_AR="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gcc-ar" SLURM_SRUN_COMM_HOST="192.168.11.54" SLURM_PMIXP_ABORT_AGENT_PORT="38559" ADDR2LINE="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-addr2line" XDG_SESSION_CLASS="user" SLURM_WORKING_CLUSTER="osk-cluster:10.255.255.100:6817:9728:109" PYTHONPATH="/home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat:/home/Competition2025/P02/P02U006/ColossalAI:" PMIX_SERVER_URI21="pmix-server.986582;tcp4://127.0.0.1:51367" TERM="xterm-256color" GCC_NM="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gcc-nm" SIZE="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-size" TORCH_NCCL_ASYNC_ERROR_HANDLING="1" HOST="x86_64-conda-linux-gnu" LESSOPEN="||/usr/bin/lesspipe.sh %s" CC_FOR_BUILD="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-cc" PMIX_DSTORE_ESH_BASE_PATH="/var/spool/slurm/d/pmix.312303.0//pmix_dstor_ds12_986582" USER="P02U006" LIBRARY_PATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:" SLURM_NODELIST="osk-gpu[54,56,91]" ENVIRONMENT="BATCH" GPU_DEVICE_ORDINAL="0,1,2,3,4,5,6,7" CONDA_SHLVL="1" SLURM_SRUN_COMM_PORT="35519" MODULES_RUN_QUARANTINE="LD_LIBRARY_PATH LD_PRELOAD" AR="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ar" AS="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-as" DEBUG_CPPFLAGS="-D_DEBUG -D_FORTIFY_SOURCE=2 -Og -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include" SLURM_STEP_ID="0" SLURM_PRIO_PROCESS="0" host_alias="x86_64-conda-linux-gnu" SLURM_NPROCS="1" PYTHONFAULTHANDLER="1" SHLVL="2" SLURM_NNODES="1" NM="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-nm" GCC="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-gcc" PMIX_MCA_gds="^ds12" XDG_SESSION_ID="48054" SLURM_SUBMIT_HOST="osk-cpu01" PMIX_SERVER_TMPDIR="/var/spool/slurm/d/pmix.312303.0/" LD_GOLD="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ld.gold" CONDA_PYTHON_EXE="/home/Competition2025/P02/P02U006/miniconda3/bin/python" LD_LIBRARY_PATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:" SLURM_JOB_CPUS_PER_NODE_PACK_GROUP_0="2(x3)" XDG_RUNTIME_DIR="/run/user/11034" SLURM_JOB_ID="312303" UCX_MAX_RNDV_RAILS="8" SLURM_NODEID="0" SLURM_STEP_NUM_NODES="1" SSH_CLIENT="100.113.255.13 65029 22" CONDA_DEFAULT_ENV="deepseeksft310" __MODULES_LMINIT="module use --append /home/appli/modulefiles:module use --append /usr/share/Modules/modulefiles:module use --append /etc/modulefiles:module use --append /usr/share/modulefiles" OBJCOPY="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-objcopy" OMPI_MCA_coll_hcoll_enable="0" PMIX_NAMESPACE="slurm.pmix.312303.0" which_declare="declare -f" SLURM_STEP_TASKS_PER_NODE="1" STRIP="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-strip" CUDA_HOME="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310" SLURM_MPI_TYPE="pmix_v3" NVCC_PREPEND_FLAGS_BACKUP=" -ccbin=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++" XDG_DATA_DIRS="/home/Competition2025/P02/P02U006/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share" OBJDUMP="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-objdump" SLURM_CONF="/etc/slurm/slurm.conf" PATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/condabin:/home/Competition2025/P02/P02U006/.local/bin:/home/Competition2025/P02/P02U006/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin" SLURM_JOB_NAME="lora-r1" MODULEPATH="/etc/scl/modulefiles:/etc/scl/modulefiles:/home/appli/modulefiles:/usr/share/Modules/modulefiles:/etc/modulefiles:/usr/share/modulefiles" CC="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-cc" SLURM_NTASKS_PER_NODE="1" CFLAGS="-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include  -I/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include" CXXFILT="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-c++filt" DBUS_SESSION_BUS_ADDRESS="unix:path=/run/user/11034/bus" BUILD="x86_64-conda-linux-gnu" MAIL="/var/spool/mail/P02U006" SSH_TTY="/dev/pts/92" SLURM_STEP_LAUNCHER_PORT="35519" SLURM_JOB_GID="11034" CPATH="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/nvidia/cublas/include:" RANLIB="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/x86_64-conda-linux-gnu-ranlib" CONDA_BUILD_SYSROOT="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/x86_64-conda-linux-gnu/sysroot" UCX_MAX_EAGER_RAILS="8" OLDPWD="/home/Competition2025/P02/P02U006/ColossalAI/logs" SLURM_JOB_NODELIST="osk-gpu[54,56,91]" MODULES_CMD="/usr/share/Modules/libexec/modulecmd.tcl" _="/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/colossalai" CUDA_DEVICE_MAX_CONNECTIONS="1" && torchrun --nproc_per_node=8 --nnodes=3 --node_rank=0 --master_addr=osk-gpu54 --master_port=24303 /home/Competition2025/P02/P02U006/ColossalAI/applications/ColossalChat/examples/training_scripts/lora_finetune.py --pretrained /home/Competition2025/P02/shareP02/DeepSeek-R1-0528-BF16 --dataset /home/Competition2025/P02/shareP02/hci_colossalai_deepseekr10528_lorasft.jsonl --plugin moe --pp 3 --ep 8 --batch_size 8 --lr 2e-5 --max_length 256 --lora_rank 8 --lora_alpha 16 --num_epochs 2 --warmup_steps 8 --mixed_precision bf16 --use_grad_checkpoint --tensorboard_dir /home/Competition2025/P02/P02U006/ColossalAI/logs/tb --save_dir /home/Competition2025/P02/P02U006/ColossalAI/DeepSeek-R1-0528-lora'

Exit code: 1

Stdout: already printed

Stderr: already printed



====== Training on All Nodes =====
osk-gpu54: failure
osk-gpu56: failure
osk-gpu91: failure

====== Stopping All Nodes =====
osk-gpu54: finish
osk-gpu56: finish
osk-gpu91: finish