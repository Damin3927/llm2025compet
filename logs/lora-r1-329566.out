===== ジョブ開始: Wed Aug  6 06:45:58 PM JST 2025 =====
cwd  = /home/Competition2025/P02/P02U006/ColossalAI
host = osk-gpu54
JOB  = 329566
NODES= osk-gpu[54,56,91]
FLASH_ATTENTION_DISABLE=1
HF_TRANSFORMERS_CACHE_DISABLE_FLASH_ATTN_2=1
=== CUDA環境 ===
CUDA_HOME=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/nvcc
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2025 NVIDIA Corporation
Built on Tue_May_27_02:21:03_PDT_2025
Cuda compilation tools, release 12.9, V12.9.86
Build cuda_12.9.r12.9/compiler.36037853_0
=== Pythonライブラリのバージョン ===
python 3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0]
torch 2.4.1+cu124
torchvision 0.19.1+cu124
torchaudio 2.4.1+cu124
numpy 1.26.4
please install Colossal-AI from https://www.colossalai.org/download or from source
colossalai 0.0.0
transformers 4.46.3
PATH=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin:/home/Competition2025/P02/P02U006/miniconda3/condabin:/home/Competition2025/P02/P02U006/.local/bin:/home/Competition2025/P02/P02U006/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
LD_LIBRARY_PATH=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
CPATH=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/include:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/include:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib/python3.10/site-packages/nvidia/cublas/include:
LIBRARY_PATH=/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
[after unset NCCL_NET_PLUGIN]
NCCL_NET_PLUGIN=none
NCCL_SOCKET_IFNAME=enp92s0np0
NCCL_DEBUG=INFO
NCCL_TIMEOUT=3600
NCCL_IB_HCA=mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
TORCH_NCCL_BLOCKING_WAIT=1
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
MASTER_ADDR=osk-gpu54  MASTER_PORT=21566
== [Pre-launch NCCL env] ==
NCCL_NET_PLUGIN=none
NCCL_SOCKET_IFNAME=enp92s0np0
NCCL_DEBUG=INFO
NCCL_TIMEOUT=3600
NCCL_IB_HCA=mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
TORCH_NCCL_BLOCKING_WAIT=1
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[08/06/25 18:46:39] INFO     colossalai - colossalai - INFO:                    
                             /home/Competition2025/P02/P02U006/ColossalAI/coloss
                             alai/initialize.py:75 launch                       
                    INFO     colossalai - colossalai - INFO: Distributed        
                             environment is initialized, world size: 24         
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = [DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
Training Info:
Config file: training_config.json 
Tensorboard logs: /home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb 
Model checkpoint: /home/Competition2025/P02/P02U006/ColossalAI/logs/329566/DeepSeek-R1-0528-lora
Load dataset: /home/Competition2025/P02/shareP02/hci_colossalai_deepseekr10528_lorasft.jsonl
dataset size: 2160
dataloader batch_size: 8, total batches: 33
Max device memory after data loader: 0.00 MB
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=True  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] Creating tensorboard dir: /home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] Tensorboard SummaryWriter created
[DEBUG] Saving config to training_config.json
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=True  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] Creating tensorboard dir: /home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] Tensorboard SummaryWriter created
[DEBUG] Saving config to training_config.json
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[DEBUG] is_master=True  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[08/06/25 18:47:35] WARNING  colossalai - colossalai - WARNING:                 
                             /home/Competition2025/P02/P02U006/ColossalAI/coloss
                             alai/booster/plugin/hybrid_parallel_plugin.py:1518 
                             enable_lora                                        
                    WARNING  colossalai - colossalai - WARNING: You have enabled
                             LoRa training. Please check the hyperparameters    
                             such as lr                                         
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] LoRA enabled ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] Set model to train mode ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] LoRA enabled ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to train mode ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to eval mode ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
Gradient checkpointing enabled successfully
=== [Debug] Set model to eval mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to eval mode ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to eval mode ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] Set model to eval mode ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] Creating tensorboard dir: /home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] Tensorboard SummaryWriter created
[DEBUG] Saving config to training_config.json
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
Model params: 671.03 B
[extension] Time taken to load cpu_adam_x86 op: 0.10124421119689941 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[DEBUG] is_master=True  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.8060040473937988 seconds
[extension] Time taken to load fused_optim_cuda op: 1.338674783706665 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 0.7071897983551025 seconds
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
==== ColossalAI SFT script: train() Start ====
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.08721303939819336 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 0.1034393310546875 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 0.1056363582611084 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.12449026107788086 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 0.4053168296813965 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.15747690200805664 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
Default dtype set to torch.bfloat16
[extension] Time taken to load cpu_adam_x86 op: 0.10663533210754395 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[extension] Time taken to load fused_optim_cuda op: 0.1170189380645752 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.10145020484924316 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.13886141777038574 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
[extension] Time taken to load cpu_adam_x86 op: 0.04996681213378906 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[extension] Time taken to load fused_optim_cuda op: 0.11921381950378418 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
=== [Debug] Entered init_ctx ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=True  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] Booster boost completed: rank=6 ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] Booster boost completed: rank=4 ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Booster boost completed: rank=7 ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Booster boost completed: rank=2 ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] Booster boost completed: rank=0 ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Booster boost completed: rank=1 ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] Booster boost completed: rank=5 ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Booster boost completed: rank=3 ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] Creating tensorboard dir: /home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] Tensorboard SummaryWriter created
[DEBUG] Saving config to training_config.json
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] Creating tensorboard dir: /home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] Tensorboard SummaryWriter created
[DEBUG] Saving config to training_config.json
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== ENV CHECK ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
dataloader batch_size: 8, total batches: 33
=== [Debug] Entered init_ctx ===
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
==== ColossalAI SFT script: train() Start ====
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=True  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] Creating tensorboard dir: /home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] Tensorboard SummaryWriter created
[DEBUG] Saving config to training_config.json
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=True  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=True  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] Creating tensorboard dir: /home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] Tensorboard SummaryWriter created
[DEBUG] Saving config to training_config.json
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== ENV CHECK ===
NCCL_TIMEOUT = 3600
TORCH_ELASTIC_STORE_TIMEOUT = 3600
TORCH_DISTRIBUTED_STORE_TIMEOUT = 3600
MASTER_ADDR = osk-gpu54
MASTER_PORT = 21566
=== END ENV CHECK ===
==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
[DEBUG] Creating tensorboard dir: /home/Competition2025/P02/P02U006/ColossalAI/logs/329566/tb
[DEBUG] Tensorboard SummaryWriter created
[DEBUG] Saving config to training_config.json
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Set model to train mode ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Set model to eval mode ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
=== [Debug] LoRA enabled ===
[extension] Time taken to load cpu_adam_x86 op: 0.8570907115936279 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Set model to eval mode ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 1.4232914447784424 seconds
=== [Debug] LoRA enabled ===
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 16.94107675552368 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 6.852244853973389 seconds
[extension] Time taken to load fused_optim_cuda op: 34.64911246299744 seconds
[extension] Time taken to load cpu_adam_x86 op: 28.74295949935913 seconds
[extension] Time taken to load cpu_adam_x86 op: 10.540763854980469 seconds
[extension] Time taken to load cpu_adam_x86 op: 26.125226497650146 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 9.318411111831665 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 26.544591426849365 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 47.232433557510376 seconds
[extension] Time taken to load cpu_adam_x86 op: 28.60196328163147 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 43.56166315078735 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.38878703117370605 seconds
[extension] Time taken to load fused_optim_cuda op: 0.3532428741455078 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 0.41872286796569824 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 31.785999298095703 seconds
[extension] Time taken to load fused_optim_cuda op: 0.423600435256958 seconds
=== [Debug] Using optimizer: HybridAdam ===
[extension] Time taken to load fused_optim_cuda op: 0.4463191032409668 seconds
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 0.4574100971221924 seconds
[extension] Time taken to load fused_optim_cuda op: 0.47187280654907227 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.4279649257659912 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 0.4786193370819092 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 1.097754955291748 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.459200382232666 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.37776947021484375 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.41678547859191895 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[extension] Time taken to load fused_optim_cuda op: 0.7429924011230469 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Booster boost completed: rank=20 ===
=== [Debug] LoRA enabled ===
=== [Debug] Booster boost completed: rank=22 ===
=== [Debug] Booster boost completed: rank=10 ===
=== [Debug] Set model to train mode ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
=== [Debug] Set model to train mode ===
[extension] Time taken to load cpu_adam_x86 op: 0.306715726852417 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] Gradient checkpointing enabled successfully ===
[extension] Time taken to load fused_optim_cuda op: 0.4945495128631592 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Set model to eval mode ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.13619303703308105 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.455608606338501 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.27813220024108887 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.5681595802307129 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.1273488998413086 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.29489827156066895 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to eval mode ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Booster boost completed: rank=21 ===
=== [Debug] Set model to eval mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] LoRA enabled ===
=== [Debug] Booster boost completed: rank=23 ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.44663000106811523 seconds
=== [Debug] Booster boost completed: rank=8 ===
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.38744139671325684 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Set model to eval mode ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.5833337306976318 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] Booster boost completed: rank=14 ===
[extension] Time taken to load fused_optim_cuda op: 0.24985957145690918 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] LoRA enabled ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.1654980182647705 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] Set model to train mode ===
[extension] Time taken to load fused_optim_cuda op: 0.6202535629272461 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Gradient checkpointing enabled successfully ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
=== [Debug] LoRA enabled ===
[extension] Time taken to load cpu_adam_x86 op: 0.3332679271697998 seconds
=== [Debug] Set model to eval mode ===
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
=== [Debug] Set model to eval mode ===
[extension] Time taken to load fused_optim_cuda op: 0.9467098712921143 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 0.653566837310791 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.2741518020629883 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.4089488983154297 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] LoRA enabled ===
[extension] Time taken to load fused_optim_cuda op: 0.5797171592712402 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to eval mode ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.3954625129699707 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[extension] Time taken to load fused_optim_cuda op: 0.6608481407165527 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] LoRA enabled ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Booster boost completed: rank=18 ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
=== [Debug] LoRA enabled ===
[extension] Time taken to load cpu_adam_x86 op: 0.37415432929992676 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
[extension] Time taken to load fused_optim_cuda op: 0.5185072422027588 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
=== [Debug] Gradient checkpointing enabled successfully ===
[extension] Time taken to load cpu_adam_x86 op: 0.32642531394958496 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] Set model to eval mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
[extension] Time taken to load fused_optim_cuda op: 0.33646249771118164 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Set model to eval mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Booster boost completed: rank=9 ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.21981048583984375 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] Set model to eval mode ===
[extension] Time taken to load fused_optim_cuda op: 0.5015895366668701 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.1192021369934082 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.28475356101989746 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.04935789108276367 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] LoRA enabled ===
[extension] Time taken to load fused_optim_cuda op: 0.14041662216186523 seconds
=== [Debug] Set model to train mode ===
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Gradient checkpointing enabled successfully ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
=== [Debug] Set model to eval mode ===
[extension] Time taken to load cpu_adam_x86 op: 0.15580487251281738 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.4374425411224365 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 0.12024998664855957 seconds
[extension] Time taken to load cpu_adam_x86 op: 0.12041139602661133 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] Booster boost completed: rank=15 ===
=== [Debug] LoRA enabled ===
[extension] Time taken to load fused_optim_cuda op: 0.25093698501586914 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 0.3123915195465088 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.1414628028869629 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] Booster boost completed: rank=16 ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
=== [Debug] Booster boost completed: rank=21 ===
[extension] Time taken to load fused_optim_cuda op: 0.49854016304016113 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 0.310802698135376 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.16063451766967773 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] LoRA enabled ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.08532834053039551 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.17841148376464844 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[extension] Time taken to load cpu_adam_x86 op: 0.17040777206420898 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
=== [Debug] Booster boost completed: rank=23 ===
[extension] Time taken to load fused_optim_cuda op: 0.3605666160583496 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Set model to eval mode ===
=== [Debug] Booster boost completed: rank=19 ===
=== [Debug] Booster boost completed: rank=17 ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.0783379077911377 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.1348128318786621 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.044284820556640625 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.12849831581115723 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.04365086555480957 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.12750244140625 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Booster boost completed: rank=18 ===
=== [Debug] Booster boost completed: rank=22 ===
=== [Debug] Model loaded from pretrained: rank=23 ===
[Debug] rank=23, host=osk-gpu91, Max device mem: 67123.78 MB, Max CPU mem: 21118.16 MB
[Debug] rank=23, host=osk-gpu91, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=16 ===
[Debug] rank=16, host=osk-gpu91, Max device mem: 67123.78 MB, Max CPU mem: 21111.52 MB
[Debug] rank=16, host=osk-gpu91, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=22 ===
[Debug] rank=22, host=osk-gpu91, Max device mem: 67123.78 MB, Max CPU mem: 21111.82 MB
[Debug] rank=22, host=osk-gpu91, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=17 ===
[Debug] rank=17, host=osk-gpu91, Max device mem: 67123.78 MB, Max CPU mem: 21111.20 MB
[Debug] rank=17, host=osk-gpu91, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=18 ===
[Debug] rank=18, host=osk-gpu91, Max device mem: 67123.78 MB, Max CPU mem: 21106.14 MB
[Debug] rank=18, host=osk-gpu91, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=20 ===
[Debug] rank=20, host=osk-gpu91, Max device mem: 67123.78 MB, Max CPU mem: 21118.03 MB
[Debug] rank=20, host=osk-gpu91, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=21 ===
[Debug] rank=21, host=osk-gpu91, Max device mem: 67123.78 MB, Max CPU mem: 21106.96 MB
[Debug] rank=21, host=osk-gpu91, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=19 ===
[Debug] rank=19, host=osk-gpu91, Max device mem: 67123.78 MB, Max CPU mem: 21107.86 MB
[Debug] rank=19, host=osk-gpu91, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=1 ===
[Debug] rank=01, host=osk-gpu54, Max device mem: 59297.77 MB, Max CPU mem: 24207.90 MB
[Debug] rank=01, host=osk-gpu54, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=2 ====== [Debug] Model loaded from pretrained: rank=0 ===

[Debug] rank=00, host=osk-gpu54, Max device mem: 59297.77 MB, Max CPU mem: 24209.61 MB
[Debug] rank=00, host=osk-gpu54, === for epoch in range(0, 2) Start ====
[Debug] rank=02, host=osk-gpu54, Max device mem: 59297.77 MB, Max CPU mem: 24199.37 MB
[Debug] rank=02, host=osk-gpu54, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=7 ===
[Debug] rank=07, host=osk-gpu54, Max device mem: 59297.77 MB, Max CPU mem: 24207.85 MB
[Debug] rank=07, host=osk-gpu54, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=5 ===
[Debug] rank=05, host=osk-gpu54, Max device mem: 59297.77 MB, Max CPU mem: 24202.52 MB
[Debug] rank=05, host=osk-gpu54, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=4 ===
[Debug] rank=04, host=osk-gpu54, Max device mem: 59297.77 MB, Max CPU mem: 24203.95 MB
[Debug] rank=04, host=osk-gpu54, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=6 ===
[Debug] rank=06, host=osk-gpu54, Max device mem: 59297.77 MB, Max CPU mem: 24204.27 MB
[Debug] rank=06, host=osk-gpu54, === for epoch in range(0, 2) Start ====
osk-gpu54:2081323:2081323 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081323:2081323 [0] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.54<0>
osk-gpu54:2081323:2081323 [0] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu54:2081323:2081323 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu54:2081323:2081323 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
osk-gpu54:2081324:2081324 [1] NCCL INFO cudaDriverVersion 12080
osk-gpu54:2081324:2081324 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081324:2081324 [1] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.54<0>
osk-gpu54:2081324:2081324 [1] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu54:2081325:2081325 [2] NCCL INFO cudaDriverVersion 12080
osk-gpu54:2081324:2081324 [1] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu54:2081325:2081325 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081325:2081325 [2] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.54<0>
osk-gpu54:2081325:2081325 [2] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu54:2081325:2081325 [2] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu54:2081330:2081330 [7] NCCL INFO cudaDriverVersion 12080
osk-gpu54:2081330:2081330 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081330:2081330 [7] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.54<0>
osk-gpu54:2081330:2081330 [7] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu54:2081330:2081330 [7] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu54:2081327:2081327 [4] NCCL INFO cudaDriverVersion 12080
osk-gpu54:2081327:2081327 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081327:2081327 [4] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.54<0>
osk-gpu54:2081327:2081327 [4] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu54:2081327:2081327 [4] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu54:2081323:2085942 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081323:2085942 [0] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu54:2081327:2085954 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081325:2085944 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081327:2085954 [4] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu54:2081325:2085944 [2] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu54:2081324:2085943 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081324:2085943 [1] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu54:2081330:2085953 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081330:2085953 [7] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu54:2081323:2085942 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.54<0>
osk-gpu54:2081323:2085942 [0] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081323:2085942 [0] NCCL INFO Using network IB
osk-gpu54:2081325:2085944 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.54<0>
osk-gpu54:2081325:2085944 [2] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081325:2085944 [2] NCCL INFO Using network IB
osk-gpu54:2081327:2085954 [4] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.54<0>
osk-gpu54:2081327:2085954 [4] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081327:2085954 [4] NCCL INFO Using network IB
osk-gpu54:2081324:2085943 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.54<0>
osk-gpu54:2081324:2085943 [1] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081324:2085943 [1] NCCL INFO Using network IB
osk-gpu54:2081330:2085953 [7] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.54<0>
osk-gpu54:2081330:2085953 [7] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081330:2085953 [7] NCCL INFO Using network IB
osk-gpu54:2081328:2081328 [5] NCCL INFO cudaDriverVersion 12080
osk-gpu54:2081328:2081328 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081328:2081328 [5] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.54<0>
osk-gpu54:2081328:2081328 [5] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu54:2081328:2081328 [5] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu54:2081329:2081329 [6] NCCL INFO cudaDriverVersion 12080
osk-gpu54:2081329:2081329 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081329:2081329 [6] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.54<0>
osk-gpu54:2081329:2081329 [6] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu54:2081329:2081329 [6] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu54:2081328:2085997 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081328:2085997 [5] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu54:2081329:2085999 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081329:2085999 [6] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu54:2081328:2085997 [5] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.54<0>
osk-gpu54:2081328:2085997 [5] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081328:2085997 [5] NCCL INFO Using network IB
osk-gpu54:2081329:2085999 [6] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.54<0>
osk-gpu54:2081329:2085999 [6] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081329:2085999 [6] NCCL INFO Using network IB
=== [Debug] Model loaded from pretrained: rank=3 ===
[Debug] rank=03, host=osk-gpu54, Max device mem: 59297.77 MB, Max CPU mem: 24207.86 MB
[Debug] rank=03, host=osk-gpu54, === for epoch in range(0, 2) Start ====
osk-gpu54:2081326:2081326 [3] NCCL INFO cudaDriverVersion 12080
osk-gpu54:2081326:2081326 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081326:2081326 [3] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.54<0>
osk-gpu54:2081326:2081326 [3] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu54:2081326:2081326 [3] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu54:2081326:2086029 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu54:2081326:2086029 [3] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu54:2081326:2086029 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.54<0>
osk-gpu54:2081326:2086029 [3] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081326:2086029 [3] NCCL INFO Using network IB
osk-gpu54:2081327:2085954 [4] NCCL INFO comm 0x401c09b0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 9a000 commId 0xf745a2aa2cc61ab7 - Init START
osk-gpu54:2081328:2085997 [5] NCCL INFO comm 0x4159cbb0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId ab000 commId 0xf745a2aa2cc61ab7 - Init START
osk-gpu54:2081327:2085954 [4] NCCL INFO MNNVL busId 0x9a000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081329:2085999 [6] NCCL INFO comm 0x40f294b0 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId ba000 commId 0xf745a2aa2cc61ab7 - Init START
osk-gpu54:2081330:2085953 [7] NCCL INFO comm 0x412a0cb0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId db000 commId 0xf745a2aa2cc61ab7 - Init START
osk-gpu54:2081330:2085953 [7] NCCL INFO MNNVL busId 0xdb000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081329:2085999 [6] NCCL INFO MNNVL busId 0xba000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081328:2085997 [5] NCCL INFO MNNVL busId 0xab000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081323:2085942 [0] NCCL INFO comm 0x41fbaf90 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 18000 commId 0xf745a2aa2cc61ab7 - Init START
osk-gpu54:2081326:2086029 [3] NCCL INFO comm 0x42044330 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 5d000 commId 0xf745a2aa2cc61ab7 - Init START
osk-gpu54:2081324:2085943 [1] NCCL INFO comm 0x40982970 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 2a000 commId 0xf745a2aa2cc61ab7 - Init START
osk-gpu54:2081325:2085944 [2] NCCL INFO comm 0x40d154f0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 3a000 commId 0xf745a2aa2cc61ab7 - Init START
osk-gpu54:2081326:2086029 [3] NCCL INFO MNNVL busId 0x5d000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081325:2085944 [2] NCCL INFO MNNVL busId 0x3a000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081324:2085943 [1] NCCL INFO MNNVL busId 0x2a000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081323:2085942 [0] NCCL INFO MNNVL busId 0x18000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081326:2086029 [3] NCCL INFO NVLS multicast support is available on dev 3
osk-gpu54:2081323:2085942 [0] NCCL INFO Setting affinity for GPU 0 to 03000000,00000000,00000000,00000003
osk-gpu54:2081330:2085953 [7] NCCL INFO NVLS multicast support is available on dev 7
osk-gpu54:2081323:2085942 [0] NCCL INFO NVLS multicast support is available on dev 0
osk-gpu54:2081325:2085944 [2] NCCL INFO Setting affinity for GPU 2 to 03000000,00000000,00000000,00000003
osk-gpu54:2081324:2085943 [1] NCCL INFO Setting affinity for GPU 1 to 03000000,00000000,00000000,00000003
osk-gpu54:2081325:2085944 [2] NCCL INFO NVLS multicast support is available on dev 2
osk-gpu54:2081324:2085943 [1] NCCL INFO NVLS multicast support is available on dev 1
osk-gpu54:2081329:2085999 [6] NCCL INFO Setting affinity for GPU 6 to 300000,00000000,00000000,00000000,30000000,00000000
osk-gpu54:2081329:2085999 [6] NCCL INFO NVLS multicast support is available on dev 6
osk-gpu54:2081327:2085954 [4] NCCL INFO Setting affinity for GPU 4 to 300000,00000000,00000000,00000000,30000000,00000000
osk-gpu54:2081327:2085954 [4] NCCL INFO NVLS multicast support is available on dev 4
osk-gpu54:2081328:2085997 [5] NCCL INFO Setting affinity for GPU 5 to 300000,00000000,00000000,00000000,30000000,00000000
osk-gpu54:2081328:2085997 [5] NCCL INFO NVLS multicast support is available on dev 5
osk-gpu54:2081328:2085997 [5] NCCL INFO comm 0x4159cbb0 rank 5 nRanks 8 nNodes 1 localRanks 8 localRank 5 MNNVL 0
osk-gpu54:2081329:2085999 [6] NCCL INFO comm 0x40f294b0 rank 6 nRanks 8 nNodes 1 localRanks 8 localRank 6 MNNVL 0
osk-gpu54:2081328:2085997 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/-1/-1->5->4 [6] 6/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->4 [14] 6/-1/-1->5->4 [15] 6/-1/-1->5->4 [16] 6/-1/-1->5->4 [17] 6/-1/-1->5->4 [18] 6/-1/-1->5->4 [19] 6/-1/-1->5->4 [20] 6/-1/-1->5->4 [21] 6/-1/-1->5->4 [22] 6/-1/-1->5->4 [23] 6/-1/-1->5->4
osk-gpu54:2081328:2085997 [5] NCCL INFO P2P Chunksize set to 524288
osk-gpu54:2081329:2085999 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->5 [15] 7/-1/-1->6->5 [16] 7/-1/-1->6->5 [17] 7/-1/-1->6->5 [18] 7/-1/-1->6->5 [19] 7/-1/-1->6->5 [20] 7/-1/-1->6->5 [21] 7/-1/-1->6->5 [22] 7/-1/-1->6->5 [23] 7/-1/-1->6->5
osk-gpu54:2081329:2085999 [6] NCCL INFO P2P Chunksize set to 524288
osk-gpu54:2081325:2085944 [2] NCCL INFO comm 0x40d154f0 rank 2 nRanks 8 nNodes 1 localRanks 8 localRank 2 MNNVL 0
osk-gpu54:2081324:2085943 [1] NCCL INFO comm 0x40982970 rank 1 nRanks 8 nNodes 1 localRanks 8 localRank 1 MNNVL 0
osk-gpu54:2081330:2085953 [7] NCCL INFO comm 0x412a0cb0 rank 7 nRanks 8 nNodes 1 localRanks 8 localRank 7 MNNVL 0
osk-gpu54:2081323:2085942 [0] NCCL INFO comm 0x41fbaf90 rank 0 nRanks 8 nNodes 1 localRanks 8 localRank 0 MNNVL 0
osk-gpu54:2081326:2086029 [3] NCCL INFO comm 0x42044330 rank 3 nRanks 8 nNodes 1 localRanks 8 localRank 3 MNNVL 0
osk-gpu54:2081327:2085954 [4] NCCL INFO comm 0x401c09b0 rank 4 nRanks 8 nNodes 1 localRanks 8 localRank 4 MNNVL 0
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 00/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 01/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 02/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 03/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081330:2085953 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6 [4] -1/-1/-1->7->6 [5] -1/-1/-1->7->6 [6] -1/-1/-1->7->6 [7] -1/-1/-1->7->6 [8] -1/-1/-1->7->6 [9] -1/-1/-1->7->6 [10] -1/-1/-1->7->6 [11] -1/-1/-1->7->6 [12] -1/-1/-1->7->6 [13] -1/-1/-1->7->6 [14] -1/-1/-1->7->6 [15] -1/-1/-1->7->6 [16] -1/-1/-1->7->6 [17] -1/-1/-1->7->6 [18] -1/-1/-1->7->6 [19] -1/-1/-1->7->6 [20] -1/-1/-1->7->6 [21] -1/-1/-1->7->6 [22] -1/-1/-1->7->6 [23] -1/-1/-1->7->6
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 04/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081324:2085943 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->0 [10] 2/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 2/-1/-1->1->0 [17] 2/-1/-1->1->0 [18] 2/-1/-1->1->0 [19] 2/-1/-1->1->0 [20] 2/-1/-1->1->0 [21] 2/-1/-1->1->0 [22] 2/-1/-1->1->0 [23] 2/-1/-1->1->0
osk-gpu54:2081325:2085944 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->1 [11] 3/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 3/-1/-1->2->1 [17] 3/-1/-1->2->1 [18] 3/-1/-1->2->1 [19] 3/-1/-1->2->1 [20] 3/-1/-1->2->1 [21] 3/-1/-1->2->1 [22] 3/-1/-1->2->1 [23] 3/-1/-1->2->1
osk-gpu54:2081330:2085953 [7] NCCL INFO P2P Chunksize set to 524288
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 05/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081324:2085943 [1] NCCL INFO P2P Chunksize set to 524288
osk-gpu54:2081325:2085944 [2] NCCL INFO P2P Chunksize set to 524288
osk-gpu54:2081326:2086029 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2 [4] 4/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->2 [12] 4/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2 [16] 4/-1/-1->3->2 [17] 4/-1/-1->3->2 [18] 4/-1/-1->3->2 [19] 4/-1/-1->3->2 [20] 4/-1/-1->3->2 [21] 4/-1/-1->3->2 [22] 4/-1/-1->3->2 [23] 4/-1/-1->3->2
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 06/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 07/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081326:2086029 [3] NCCL INFO P2P Chunksize set to 524288
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 08/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081327:2085954 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/-1/-1->4->3 [5] 5/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->3 [13] 5/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3 [16] 5/-1/-1->4->3 [17] 5/-1/-1->4->3 [18] 5/-1/-1->4->3 [19] 5/-1/-1->4->3 [20] 5/-1/-1->4->3 [21] 5/-1/-1->4->3 [22] 5/-1/-1->4->3 [23] 5/-1/-1->4->3
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 09/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 10/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 11/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 12/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 13/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081327:2085954 [4] NCCL INFO P2P Chunksize set to 524288
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 14/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 15/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 16/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 17/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 18/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 19/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 20/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 21/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 22/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 23/24 :    0   1   2   3   4   5   6   7
osk-gpu54:2081323:2085942 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] 1/-1/-1->0->-1 [7] 1/-1/-1->0->-1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 1/-1/-1->0->-1 [17] 1/-1/-1->0->-1 [18] 1/-1/-1->0->-1 [19] 1/-1/-1->0->-1 [20] 1/-1/-1->0->-1 [21] 1/-1/-1->0->-1 [22] 1/-1/-1->0->-1 [23] 1/-1/-1->0->-1
osk-gpu54:2081323:2085942 [0] NCCL INFO P2P Chunksize set to 524288
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 02/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 00/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 01/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 02/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 03/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 04/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 05/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 06/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 07/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 08/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 09/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 10/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 08/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 09/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 11/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 02/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 03/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 03/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 13/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 04/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 11/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 05/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 06/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 07/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 12/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 08/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 13/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 09/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 10/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 04/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 11/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 12/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 13/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 14/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 14/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 15/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 15/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 16/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 05/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 17/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 06/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 18/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 16/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 17/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 18/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 19/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 20/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 07/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 21/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 22/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 23/0 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 19/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 20/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 21/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 22/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 23/0 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 08/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 09/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 10/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 11/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 12/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 13/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 14/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 15/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 16/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 17/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 18/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 19/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 20/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 21/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 14/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 22/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 23/0 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 15/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 08/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 17/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 09/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 09/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 10/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 11/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 13/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 15/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 16/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 17/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 19/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 21/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 22/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 23/0 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 19/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 20/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 21/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 23/0 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 00/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 01/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 14/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 02/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 15/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 03/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 16/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 17/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 04/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 05/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 06/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 20/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 21/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 07/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 22/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 08/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Channel 23/0 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 09/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 10/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 11/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 12/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 13/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 14/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 15/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 16/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 02/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 17/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 18/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 03/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 19/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 20/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 04/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 21/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 22/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 23/0 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 05/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 06/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 07/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 08/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 09/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 10/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 11/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 12/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 13/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 14/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 15/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 16/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 17/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 18/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 19/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 20/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 21/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 22/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 23/0 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Connected all rings
osk-gpu54:2081329:2085999 [6] NCCL INFO Connected all rings
osk-gpu54:2081330:2085953 [7] NCCL INFO Connected all rings
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 00/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 01/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 02/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 03/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 04/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 05/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 06/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 07/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 08/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Connected all rings
osk-gpu54:2081325:2085944 [2] NCCL INFO Connected all rings
osk-gpu54:2081328:2085997 [5] NCCL INFO Connected all rings
osk-gpu54:2081326:2086029 [3] NCCL INFO Connected all rings
osk-gpu54:2081327:2085954 [4] NCCL INFO Connected all rings
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 00/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 01/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 02/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 03/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 04/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 05/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 06/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 02/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 03/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 04/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 07/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 05/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 06/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 08/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 07/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 09/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 09/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 08/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 10/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 09/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 11/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 10/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 12/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 11/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 13/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 14/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 12/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 13/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 15/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 14/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 16/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 10/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 15/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 17/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 16/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 18/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 17/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 19/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 18/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 19/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 20/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 20/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 21/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 22/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 21/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2085999 [6] NCCL INFO Channel 23/0 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 22/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2085997 [5] NCCL INFO Channel 23/0 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 11/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 12/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 13/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 14/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 15/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 16/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 08/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 17/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 10/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 18/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 12/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 13/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 19/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 14/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 20/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 16/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 21/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 18/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 19/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 22/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 20/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2085953 [7] NCCL INFO Channel 23/0 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 22/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2085944 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 08/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 09/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 10/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 12/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 09/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 12/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 14/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 13/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 15/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 15/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 16/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 18/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 16/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 19/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 21/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 22/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2085943 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 18/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 20/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 21/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 22/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086029 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 02/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 03/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 04/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 05/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 06/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 07/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 08/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 09/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 10/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 11/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 12/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 13/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 14/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 15/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 16/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 17/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 18/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 19/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 20/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 21/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 22/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2085954 [4] NCCL INFO Channel 23/0 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2085942 [0] NCCL INFO Connected all trees
osk-gpu54:2081323:2085942 [0] NCCL INFO NVLS comm 0x41fbaf90 headRank 0 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 301989888 nvlsTotalSize 2415919104
osk-gpu54:2081330:2085953 [7] NCCL INFO Connected all trees
osk-gpu54:2081324:2085943 [1] NCCL INFO Connected all trees
osk-gpu54:2081324:2085943 [1] NCCL INFO NVLS comm 0x40982970 headRank 1 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 301989888 nvlsTotalSize 2415919104
osk-gpu54:2081330:2085953 [7] NCCL INFO NVLS comm 0x412a0cb0 headRank 7 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 301989888 nvlsTotalSize 2415919104
osk-gpu54:2081325:2085944 [2] NCCL INFO Connected all trees
osk-gpu54:2081325:2085944 [2] NCCL INFO NVLS comm 0x40d154f0 headRank 2 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 301989888 nvlsTotalSize 2415919104
osk-gpu54:2081326:2086029 [3] NCCL INFO Connected all trees
osk-gpu54:2081326:2086029 [3] NCCL INFO NVLS comm 0x42044330 headRank 3 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 301989888 nvlsTotalSize 2415919104
osk-gpu54:2081327:2085954 [4] NCCL INFO Connected all trees
osk-gpu54:2081329:2085999 [6] NCCL INFO Connected all trees
osk-gpu54:2081328:2085997 [5] NCCL INFO Connected all trees
osk-gpu54:2081329:2085999 [6] NCCL INFO NVLS comm 0x40f294b0 headRank 6 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 301989888 nvlsTotalSize 2415919104
osk-gpu54:2081328:2085997 [5] NCCL INFO NVLS comm 0x4159cbb0 headRank 5 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 301989888 nvlsTotalSize 2415919104
osk-gpu54:2081327:2085954 [4] NCCL INFO NVLS comm 0x401c09b0 headRank 4 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 301989888 nvlsTotalSize 2415919104
osk-gpu54:2081324:2085943 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
osk-gpu54:2081326:2086029 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
osk-gpu54:2081326:2086029 [3] NCCL INFO 24 coll channels, 0 collnet channels, 16 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081327:2085954 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
osk-gpu54:2081324:2085943 [1] NCCL INFO 24 coll channels, 0 collnet channels, 16 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081328:2085997 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
osk-gpu54:2081328:2085997 [5] NCCL INFO 24 coll channels, 0 collnet channels, 16 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081327:2085954 [4] NCCL INFO 24 coll channels, 0 collnet channels, 16 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081330:2085953 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
osk-gpu54:2081330:2085953 [7] NCCL INFO 24 coll channels, 0 collnet channels, 16 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081323:2085942 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
osk-gpu54:2081323:2085942 [0] NCCL INFO 24 coll channels, 0 collnet channels, 16 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081325:2085944 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
osk-gpu54:2081329:2085999 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512
osk-gpu54:2081329:2085999 [6] NCCL INFO 24 coll channels, 0 collnet channels, 16 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081325:2085944 [2] NCCL INFO 24 coll channels, 0 collnet channels, 16 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081324:2085943 [1] NCCL INFO comm 0x40982970 rank 1 nranks 8 cudaDev 1 nvmlDev 1 busId 2a000 commId 0xf745a2aa2cc61ab7 - Init COMPLETE
osk-gpu54:2081328:2085997 [5] NCCL INFO comm 0x4159cbb0 rank 5 nranks 8 cudaDev 5 nvmlDev 5 busId ab000 commId 0xf745a2aa2cc61ab7 - Init COMPLETE
osk-gpu54:2081325:2085944 [2] NCCL INFO comm 0x40d154f0 rank 2 nranks 8 cudaDev 2 nvmlDev 2 busId 3a000 commId 0xf745a2aa2cc61ab7 - Init COMPLETE
osk-gpu54:2081329:2085999 [6] NCCL INFO comm 0x40f294b0 rank 6 nranks 8 cudaDev 6 nvmlDev 6 busId ba000 commId 0xf745a2aa2cc61ab7 - Init COMPLETE
osk-gpu54:2081327:2085954 [4] NCCL INFO comm 0x401c09b0 rank 4 nranks 8 cudaDev 4 nvmlDev 4 busId 9a000 commId 0xf745a2aa2cc61ab7 - Init COMPLETE
osk-gpu54:2081323:2085942 [0] NCCL INFO comm 0x41fbaf90 rank 0 nranks 8 cudaDev 0 nvmlDev 0 busId 18000 commId 0xf745a2aa2cc61ab7 - Init COMPLETE
osk-gpu54:2081326:2086029 [3] NCCL INFO comm 0x42044330 rank 3 nranks 8 cudaDev 3 nvmlDev 3 busId 5d000 commId 0xf745a2aa2cc61ab7 - Init COMPLETE
osk-gpu54:2081330:2085953 [7] NCCL INFO comm 0x412a0cb0 rank 7 nranks 8 cudaDev 7 nvmlDev 7 busId db000 commId 0xf745a2aa2cc61ab7 - Init COMPLETE
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 00/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 00/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 01/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 01/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 00/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 02/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 01/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 02/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 03/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 00/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 01/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 02/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 00/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 04/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 05/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 06/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 07/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 08/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 09/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 10/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 11/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 12/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 13/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 14/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 15/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 16/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 17/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 18/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 19/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 20/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 21/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 03/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 22/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 23/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 01/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 24/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 25/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 02/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 26/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 27/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 03/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 28/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 29/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 30/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 04/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 31/1 : 6[6] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 05/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 06/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 07/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 04/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 05/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 06/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 07/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 08/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 09/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 10/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 11/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 12/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 13/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 14/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 15/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 16/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 17/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 18/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 19/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 20/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 21/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 22/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 23/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 24/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 25/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 26/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 27/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 08/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 28/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 29/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 30/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 31/1 : 4[4] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 03/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 09/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 10/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 11/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 12/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 13/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 14/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 15/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 16/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 17/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 18/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 19/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 20/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 21/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 22/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 04/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 23/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 24/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 25/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 26/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 27/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 28/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 29/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 30/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 31/1 : 5[5] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 02/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 00/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 01/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 02/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 03/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 05/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 04/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 05/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 06/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 07/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 08/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 09/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 03/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 10/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 11/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 12/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 13/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 14/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 15/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 16/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 17/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 18/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 19/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 20/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 21/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 22/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 06/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 23/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 24/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 25/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 00/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 01/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 04/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 26/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 27/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 28/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 29/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 30/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 31/1 : 5[5] -> 7[7] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 05/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 06/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 07/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 02/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 03/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 04/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 05/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 06/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 07/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 08/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 09/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 10/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 08/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 09/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 11/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 10/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 11/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 12/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 07/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 13/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 12/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 14/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 08/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 15/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 09/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 10/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 11/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 12/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 13/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 14/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 15/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 16/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 17/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 18/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 19/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 20/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 21/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 22/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 23/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 24/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 25/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 26/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 27/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 28/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 29/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 30/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 31/1 : 7[7] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 16/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 13/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 00/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 01/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 02/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 03/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 04/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 05/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 06/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 07/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 08/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 09/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 10/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 11/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 12/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 13/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 14/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 15/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 16/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 17/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 18/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 14/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 19/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 20/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 21/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 22/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 23/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 24/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 25/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 26/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 27/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 28/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 29/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 30/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 31/1 : 6[6] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 15/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 16/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 00/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 17/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 01/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 02/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 18/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 17/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 18/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 03/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 19/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 19/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 04/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 20/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 20/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 21/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 05/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 22/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 21/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 06/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 23/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 22/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 07/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 24/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 23/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 08/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 25/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 09/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 26/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 24/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 10/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 27/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 11/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 25/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 28/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 26/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 12/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 29/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 27/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 13/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 14/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 30/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 15/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 16/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 28/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 31/1 : 0[0] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 17/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 29/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 30/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 18/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 31/1 : 2[2] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 00/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 01/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 02/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 03/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 04/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 05/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 06/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 07/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 08/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 09/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 10/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 11/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 12/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 13/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 14/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 15/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 16/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 17/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 18/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 19/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 20/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 21/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 22/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 23/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 24/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 25/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 26/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 27/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 28/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 29/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 19/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 30/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 31/1 : 7[7] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 00/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 20/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 01/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 21/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 02/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 22/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 03/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 23/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 24/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 04/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 05/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 25/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 26/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 06/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 07/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 27/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 28/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 29/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 08/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 30/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 31/1 : 3[3] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 09/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 00/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 01/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 02/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 03/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 04/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 05/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 06/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 07/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 08/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 09/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 10/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 10/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 11/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 12/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 13/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 14/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 11/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 15/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 16/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 12/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 17/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 18/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 13/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 19/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 20/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 14/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 21/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 22/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 15/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 23/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 24/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 16/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 25/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 26/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 17/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 27/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 28/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 29/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 30/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 31/1 : 3[3] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 00/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 18/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 19/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 20/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 21/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 01/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 22/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 02/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 00/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 23/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 01/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 02/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 03/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 04/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 05/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 06/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 07/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 08/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 09/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 24/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 10/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 11/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 12/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 13/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 14/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 15/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 03/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 16/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 25/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 17/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 18/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 19/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 26/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 20/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 21/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 27/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 22/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 04/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 23/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 24/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 25/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 26/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 28/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 27/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 28/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 29/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 30/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 31/1 : 5[5] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 29/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 05/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 30/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 06/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 31/1 : 1[1] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 07/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 08/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 09/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 10/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 11/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 00/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 12/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 01/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 13/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 02/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 03/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 04/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 05/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 06/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 07/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 08/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 09/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 10/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 11/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 12/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 13/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 14/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 15/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 16/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 00/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 14/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 15/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 16/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 17/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 17/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 01/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 02/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 18/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 18/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 03/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 19/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 04/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 19/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 20/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 05/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 21/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 20/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 06/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 22/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 21/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 07/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 23/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 08/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 22/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 24/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 09/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 23/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 24/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 25/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 10/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 25/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 11/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 26/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 12/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 26/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 13/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 27/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 27/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 14/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 28/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 15/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 28/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 16/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 29/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 29/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 30/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 17/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 30/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 18/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 31/1 : 4[4] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 19/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 31/1 : 0[0] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 20/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 21/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 22/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 00/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 23/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 24/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 01/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 02/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 03/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 04/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 25/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 26/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 05/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 06/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 07/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 08/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 09/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 10/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 11/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 12/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 13/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 14/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 27/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 28/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 29/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 30/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 31/1 : 1[1] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 00/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 00/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 01/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 02/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 03/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 04/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 05/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 06/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 15/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 16/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 17/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 18/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 19/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 20/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 21/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 22/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 23/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 07/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 08/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 09/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 10/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 11/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 12/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 13/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 14/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 15/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 16/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 01/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 17/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 18/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 19/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 20/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 21/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 22/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 23/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 24/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 25/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 26/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 27/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 28/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 29/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 30/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 31/1 : 7[7] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 00/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 01/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 02/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 03/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 04/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 05/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 06/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 07/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 08/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 09/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 10/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 11/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 12/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 13/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 14/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 15/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 16/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 17/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 18/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 19/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 20/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 24/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 21/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 22/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 23/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 02/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 24/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 25/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 26/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 27/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 28/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 29/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 30/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 31/1 : 3[3] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 03/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 25/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 26/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 27/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 28/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 29/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 30/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 31/1 : 6[6] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 04/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 05/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 06/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 07/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 00/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 08/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 09/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 01/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 10/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 02/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 11/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 12/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 13/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 14/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 15/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 16/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 17/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 18/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 19/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 20/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 21/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 22/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 23/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 03/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 04/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 05/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 24/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 25/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 26/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 27/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 28/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 29/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 30/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 31/1 : 2[2] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 06/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 07/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 00/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 00/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 08/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 01/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 02/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 03/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 04/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 05/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 06/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 07/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 08/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 09/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 10/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 11/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 12/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 13/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 14/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 15/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 16/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 17/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 18/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 19/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 01/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 20/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 21/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 22/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 23/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 24/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 25/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 26/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 09/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 27/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 28/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 29/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 30/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 31/1 : 2[2] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 02/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 10/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 00/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 01/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 02/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 03/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 04/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 05/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 06/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 07/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 08/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 09/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 10/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 11/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 12/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 13/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 14/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 15/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 16/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 17/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 18/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 19/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 20/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 21/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 22/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 23/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 24/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 25/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 26/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 27/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 28/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 29/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 30/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 31/1 : 2[2] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 03/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 11/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 04/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 05/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 06/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 07/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 08/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 09/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 10/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 11/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 12/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 13/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 14/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 15/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 16/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 17/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 18/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 19/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 20/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 21/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 22/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 12/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 23/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 13/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 00/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 24/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 25/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 01/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 14/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 26/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 15/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 02/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 27/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 16/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 28/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 03/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 29/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 17/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 04/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 18/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 05/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 19/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 30/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 31/1 : 1[1] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 20/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 06/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 07/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 21/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 08/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 22/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 23/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 09/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 10/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 24/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 11/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 25/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 26/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 12/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 27/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 13/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 28/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 14/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 29/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 15/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 30/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 16/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 17/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 18/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 31/1 : 4[4] -> 7[7] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 00/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 01/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 19/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 02/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 03/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 04/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 05/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 06/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 07/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 08/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 09/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 10/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 11/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 12/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 13/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 14/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 15/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 16/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 17/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 18/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 19/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 20/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 21/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 22/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 23/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 24/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 25/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 26/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 27/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 28/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 29/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 30/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 31/1 : 7[7] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 20/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 21/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 22/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 00/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 23/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 01/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 02/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 24/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 03/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 25/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 04/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 26/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 05/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 27/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 28/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 06/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 29/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 07/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 30/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 08/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 31/1 : 0[0] -> 3[3] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 09/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 10/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 11/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 00/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 01/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 02/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 03/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 04/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 05/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 06/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 07/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 08/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 09/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 12/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 10/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 11/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 13/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 12/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 13/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 14/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 15/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 16/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 17/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 18/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 19/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 14/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 20/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 21/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 22/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 15/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 23/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 16/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 24/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 25/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 26/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 17/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 27/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 28/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 29/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 30/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 31/1 : 5[5] -> 1[1] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 18/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 19/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 00/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 01/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 02/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 03/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 04/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 05/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 06/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 07/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 08/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 09/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 10/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 11/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 20/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 12/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 00/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 13/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 21/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 14/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 15/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 16/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 17/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 18/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 19/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 20/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 21/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 22/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 23/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 24/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 25/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 26/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 27/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 28/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 29/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 30/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 31/1 : 3[3] -> 7[7] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 00/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 01/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 02/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 03/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 22/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 01/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 00/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 04/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 05/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 06/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 07/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 01/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 08/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 02/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 09/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 00/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 02/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 10/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 11/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 12/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 13/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 14/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 15/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 16/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 17/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 18/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 19/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 20/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 21/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 22/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 23/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 24/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 25/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 26/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 27/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 28/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 29/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 30/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 31/1 : 7[7] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 23/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 01/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 03/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 03/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 02/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 03/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 04/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 05/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 06/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 07/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 08/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 24/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 09/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 10/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 11/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 04/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 12/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 13/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 14/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 15/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 16/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 17/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 18/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 19/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 20/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 21/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 25/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 26/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 04/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 22/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 23/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 24/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 25/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 26/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 27/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 28/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 29/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 30/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 31/1 : 3[3] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 05/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 05/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 27/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 28/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 06/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 06/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 07/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 07/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 29/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 08/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 08/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 30/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 09/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 31/1 : 1[1] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 09/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 10/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 00/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 11/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 10/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 12/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 01/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 02/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 11/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 00/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 01/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 02/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 03/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 04/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 05/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 06/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 07/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 08/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 09/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 10/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 11/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 12/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 13/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 14/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 12/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 15/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 16/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 13/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 17/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 18/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 14/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 13/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 19/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 03/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 20/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 21/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 22/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 23/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 24/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 14/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 25/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 26/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 15/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 27/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 28/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 16/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 29/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 30/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 31/1 : 5[5] -> 2[2] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 15/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 04/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 17/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 18/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 19/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 16/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 05/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 06/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 20/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 17/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 07/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 18/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 21/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 19/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 08/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 22/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 09/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 20/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 23/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 21/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 24/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 10/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 25/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 22/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 11/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 23/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 26/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 12/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 24/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 27/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 13/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 28/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 25/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 26/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 29/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 14/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 27/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 15/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 30/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 16/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 28/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 17/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 31/1 : 0[0] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 29/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 18/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 30/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 31/1 : 6[6] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 19/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 20/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 21/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 00/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 01/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 22/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 02/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 03/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 04/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 05/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 06/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 23/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 07/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 24/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 08/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 25/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 26/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 09/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 10/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 11/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 12/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 13/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 14/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 15/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 16/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 17/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 18/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 19/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 20/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 21/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 22/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 23/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 24/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 25/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 26/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 27/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 28/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 29/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 27/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 30/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 31/1 : 1[1] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 00/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 01/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 28/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 02/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 03/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 04/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 05/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 06/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 07/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 08/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 09/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 10/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 11/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 12/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 29/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 13/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 14/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 15/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 16/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 17/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 18/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 19/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 20/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 21/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 22/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 23/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 24/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 25/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 26/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 27/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 28/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 29/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 30/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 31/1 : 2[2] -> 7[7] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 30/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 31/1 : 4[4] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 00/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 01/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 02/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 00/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 03/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 01/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 04/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 02/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 03/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 05/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 04/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 05/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 06/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 07/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 06/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 08/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 09/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 07/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 10/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 08/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 11/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 09/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 12/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 10/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 11/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 12/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 13/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 13/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 14/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 14/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 15/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 15/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 16/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 17/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 18/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 19/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 20/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 21/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 22/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 23/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 24/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 25/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 26/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 16/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 27/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 28/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 17/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 18/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 29/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 30/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 19/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 20/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 21/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 31/1 : 0[0] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 22/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 23/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 00/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 01/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 02/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 03/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 04/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 05/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 06/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 07/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 08/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 09/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 24/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 10/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 11/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 12/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 13/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 14/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 15/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 16/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 17/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 18/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 25/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 19/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 20/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 21/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 26/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 22/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 27/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 23/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 24/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 25/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 26/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 28/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 27/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 28/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 29/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 29/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 30/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 31/1 : 5[5] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 30/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 00/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 31/1 : 6[6] -> 3[3] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 00/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 01/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 01/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 02/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 03/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 02/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 00/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 01/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 02/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 03/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 03/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 04/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 05/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 06/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 04/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 07/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 04/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 08/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 09/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 10/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 11/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 05/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 12/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 13/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 14/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 06/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 15/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 16/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 07/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 17/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 18/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 08/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 19/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 20/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 21/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 09/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 22/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 23/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 24/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 25/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 26/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 27/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 28/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 29/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 10/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 05/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 30/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 31/1 : 3[3] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 11/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 12/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 13/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 14/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 15/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 16/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 06/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 17/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 07/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 18/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 08/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 09/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 19/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 10/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 00/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 20/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 11/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 21/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 22/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 01/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 12/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 13/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 23/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 14/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 02/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 24/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 03/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 15/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 25/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 16/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 17/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 04/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 26/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 18/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 05/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 27/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 06/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 19/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 28/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 29/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 07/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 20/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 21/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 08/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 22/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 30/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 09/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 31/1 : 0[0] -> 6[6] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 23/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 24/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 10/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 25/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 11/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 26/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 27/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 28/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 29/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 30/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 31/1 : 2[2] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 12/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 13/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 14/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 15/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 16/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 17/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 18/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 19/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 20/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 21/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 22/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 23/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 00/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 24/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 01/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 25/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 02/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 26/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 03/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 27/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 04/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 28/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 05/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 06/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 29/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 30/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 07/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 31/1 : 4[4] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 08/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 00/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 01/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 02/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 03/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 04/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 05/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 06/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 07/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 08/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 09/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 10/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 11/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 12/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 13/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 14/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 15/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 16/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 17/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 18/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 19/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 20/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 21/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 22/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 23/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 24/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 25/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 26/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 27/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 28/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 29/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 30/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 09/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 31/1 : 7[7] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 10/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 00/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 01/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 02/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 03/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 04/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 05/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 06/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 07/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 08/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 09/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 11/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 10/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 11/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 12/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 13/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 14/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 15/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 16/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 17/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 12/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 18/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 19/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 20/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 13/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 21/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 22/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 14/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 23/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 24/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 15/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 25/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 26/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 27/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 28/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 29/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 30/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081328:2086068 [5] NCCL INFO Channel 31/1 : 5[5] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 16/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 00/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 01/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 17/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 18/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 02/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 03/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 04/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 05/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 06/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 07/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 08/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 19/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 09/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 20/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 10/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 21/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 22/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 11/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 23/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 24/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 12/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 13/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 25/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 14/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 15/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 26/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 16/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 27/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 17/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 28/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 18/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 19/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 20/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 21/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 22/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 23/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 24/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 25/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 26/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 27/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 28/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 29/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 30/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 31/1 : 1[1] -> 7[7] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 00/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 01/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 02/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 29/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 03/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 04/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 05/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 06/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 07/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 08/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 09/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 10/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 11/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 12/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 13/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 14/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 15/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 16/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 17/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 18/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 19/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 20/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 21/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 22/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 23/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 24/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 25/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 26/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 27/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 28/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 29/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 30/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 30/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 00/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081330:2086066 [7] NCCL INFO Channel 31/1 : 7[7] -> 6[6] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 31/1 : 6[6] -> 4[4] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 01/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 02/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 03/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 04/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 05/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 06/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 07/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 08/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 09/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 10/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 11/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 12/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 13/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 14/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 15/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 16/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 17/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 18/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 19/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 20/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 21/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 00/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 22/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 23/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 01/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 24/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 02/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 25/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 26/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 03/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 27/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 28/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 04/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 29/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 05/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 30/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081326:2086070 [3] NCCL INFO Channel 31/1 : 3[3] -> 2[2] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 06/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 07/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 08/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 09/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 10/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 11/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 12/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 13/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 14/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 15/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 16/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 17/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 18/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 19/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 20/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 21/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 22/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 23/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 24/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 25/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 26/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 27/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 28/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 29/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 30/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081323:2086072 [0] NCCL INFO Channel 31/1 : 0[0] -> 7[7] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 00/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 01/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 02/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 03/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 04/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 05/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 06/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 07/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 08/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 09/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 10/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 11/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 12/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 13/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 14/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 15/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 16/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 17/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 18/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 19/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 20/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 21/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 22/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 23/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 24/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 25/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 26/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 27/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 28/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 29/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 30/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081324:2086073 [1] NCCL INFO Channel 31/1 : 1[1] -> 0[0] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 00/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 01/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 02/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 03/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 04/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 05/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 06/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 07/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 08/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 09/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 10/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 11/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 12/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 13/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 14/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 15/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 16/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 17/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 18/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 19/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 20/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 21/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 22/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 23/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 24/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 25/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 26/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 27/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 28/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 29/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 30/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 31/1 : 4[4] -> 2[2] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 00/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 01/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 02/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 03/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 04/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 05/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 06/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 07/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 08/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 09/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 10/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 11/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 12/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 13/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 14/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 00/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 15/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 16/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 17/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 18/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 19/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 20/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 01/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 02/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 21/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 03/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 04/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 22/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 05/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 23/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 06/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 24/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 07/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 08/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 09/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 10/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 11/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 12/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 13/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 25/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 14/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 15/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 16/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 26/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 00/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 17/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 27/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 01/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 18/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 28/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 19/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 02/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 29/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 20/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 21/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 30/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 03/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081325:2086069 [2] NCCL INFO Channel 31/1 : 2[2] -> 1[1] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 22/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 23/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 24/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 25/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 04/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 26/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 27/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 28/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 29/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 05/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 30/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 06/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081327:2086071 [4] NCCL INFO Channel 31/1 : 4[4] -> 3[3] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 07/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 08/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 09/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 10/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 11/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 12/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 13/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 14/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 15/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 16/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 17/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 18/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 19/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 20/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 21/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 22/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 23/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 24/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 25/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 26/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 27/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 28/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 29/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 30/1 : 6[6] -> 5[5] via P2P/CUMEM
osk-gpu54:2081329:2086067 [6] NCCL INFO Channel 31/1 : 6[6] -> 5[5] via P2P/CUMEM
NCCL version 2.20.5+cuda12.4NCCL version 2.20.5+cuda12.4NCCL version 2.20.5+cuda12.4

NCCL version 2.20.5+cuda12.4NCCL version 2.20.5+cuda12.4NCCL version 2.20.5+cuda12.4



NCCL version 2.20.5+cuda12.4osk-gpu54:2081324:2086107 [1] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081324:2086107 [1] NCCL INFO Using network IB
osk-gpu54:2081326:2086106 [3] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081326:2086106 [3] NCCL INFO Using network IB
osk-gpu54:2081323:2086108 [0] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081323:2086108 [0] NCCL INFO Using network IB
osk-gpu54:2081325:2086110 [2] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081325:2086110 [2] NCCL INFO Using network IB
osk-gpu54:2081329:2086111 [6] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081329:2086111 [6] NCCL INFO Using network IB
osk-gpu54:2081330:2086112 [7] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081330:2086112 [7] NCCL INFO Using network IB
osk-gpu54:2081328:2086109 [5] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081328:2086109 [5] NCCL INFO Using network IB

osk-gpu54:2081327:2086113 [4] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081327:2086113 [4] NCCL INFO Using network IB
osk-gpu54:2081325:2086110 [2] NCCL INFO comm 0x40d30ae0 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 3a000 commId 0xc6008384ef310b81 - Init START
osk-gpu54:2081330:2086112 [7] NCCL INFO comm 0x412bb160 rank 0 nranks 1 cudaDev 7 nvmlDev 7 busId db000 commId 0xf9b36220ff6ba145 - Init START
osk-gpu54:2081326:2086106 [3] NCCL INFO comm 0x4205f710 rank 0 nranks 1 cudaDev 3 nvmlDev 3 busId 5d000 commId 0xd9ec57788cdf87ff - Init START
osk-gpu54:2081327:2086113 [4] NCCL INFO comm 0x401dae60 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId 9a000 commId 0x6d1fdb8b64889c5 - Init START
osk-gpu54:2081324:2086107 [1] NCCL INFO comm 0x4099cef0 rank 0 nranks 1 cudaDev 1 nvmlDev 1 busId 2a000 commId 0x3eb39b741010a4c4 - Init START
osk-gpu54:2081329:2086111 [6] NCCL INFO comm 0x40f43f10 rank 0 nranks 1 cudaDev 6 nvmlDev 6 busId ba000 commId 0xfccd16df609449f7 - Init START
osk-gpu54:2081328:2086109 [5] NCCL INFO comm 0x415b7060 rank 0 nranks 1 cudaDev 5 nvmlDev 5 busId ab000 commId 0xdd0611a4676c9b85 - Init START
osk-gpu54:2081324:2086107 [1] NCCL INFO MNNVL busId 0x2a000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081329:2086111 [6] NCCL INFO MNNVL busId 0xba000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081324:2086107 [1] NCCL INFO Setting affinity for GPU 1 to 03000000,00000000,00000000,00000003
osk-gpu54:2081324:2086107 [1] NCCL INFO comm 0x4099cef0 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 00/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 01/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 02/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 03/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 04/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 05/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 06/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 07/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 08/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 09/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 10/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 11/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 12/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 13/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 14/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 15/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 16/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 17/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 18/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 19/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 20/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 21/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 22/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 23/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 24/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 25/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 26/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 27/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 28/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 29/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 30/32 :    0
osk-gpu54:2081324:2086107 [1] NCCL INFO Channel 31/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Setting affinity for GPU 6 to 300000,00000000,00000000,00000000,30000000,00000000
osk-gpu54:2081324:2086107 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu54:2081324:2086107 [1] NCCL INFO P2P Chunksize set to 131072
osk-gpu54:2081329:2086111 [6] NCCL INFO comm 0x40f43f10 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 00/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 01/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 02/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 03/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 04/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 05/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 06/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 07/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 08/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 09/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 10/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 11/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 12/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 13/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 14/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 15/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 16/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 17/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 18/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 19/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 20/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 21/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 22/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 23/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 24/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 25/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 26/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 27/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 28/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 29/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 30/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Channel 31/32 :    0
osk-gpu54:2081329:2086111 [6] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu54:2081329:2086111 [6] NCCL INFO P2P Chunksize set to 131072
osk-gpu54:2081325:2086110 [2] NCCL INFO MNNVL busId 0x3a000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081323:2086108 [0] NCCL INFO comm 0x41fd5f50 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 18000 commId 0x6d483630d594a199 - Init START
osk-gpu54:2081327:2086113 [4] NCCL INFO MNNVL busId 0x9a000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081330:2086112 [7] NCCL INFO MNNVL busId 0xdb000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081328:2086109 [5] NCCL INFO MNNVL busId 0xab000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081326:2086106 [3] NCCL INFO MNNVL busId 0x5d000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081323:2086108 [0] NCCL INFO MNNVL busId 0x18000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu54:2081325:2086110 [2] NCCL INFO Setting affinity for GPU 2 to 03000000,00000000,00000000,00000003
osk-gpu54:2081325:2086110 [2] NCCL INFO comm 0x40d30ae0 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 00/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 01/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 02/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 03/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 04/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 05/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 06/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 07/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 08/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 09/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 10/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 11/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 12/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 13/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 14/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 15/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 16/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 17/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 18/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 19/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 20/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 21/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 22/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 23/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 24/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 25/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 26/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 27/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 28/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 29/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 30/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Channel 31/32 :    0
osk-gpu54:2081325:2086110 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu54:2081325:2086110 [2] NCCL INFO P2P Chunksize set to 131072
osk-gpu54:2081330:2086112 [7] NCCL INFO comm 0x412bb160 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 00/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 01/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 02/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 03/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 04/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 05/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 06/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 07/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 08/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 09/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 10/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 11/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 12/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 13/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 14/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 15/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 16/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 17/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 18/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 19/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO comm 0x4205f710 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 20/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 21/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 22/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 23/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 24/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 25/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 26/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 27/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 28/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 29/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 30/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Channel 31/32 :    0
osk-gpu54:2081330:2086112 [7] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu54:2081330:2086112 [7] NCCL INFO P2P Chunksize set to 131072
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 00/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 01/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 02/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 03/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 04/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 05/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 06/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 07/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 08/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 09/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 10/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 11/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 12/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 13/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 14/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 15/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 16/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 17/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 18/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 19/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 20/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 21/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 22/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 23/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 24/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 25/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 26/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 27/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 28/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 29/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 30/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Channel 31/32 :    0
osk-gpu54:2081326:2086106 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu54:2081326:2086106 [3] NCCL INFO P2P Chunksize set to 131072
osk-gpu54:2081328:2086109 [5] NCCL INFO Setting affinity for GPU 5 to 300000,00000000,00000000,00000000,30000000,00000000
osk-gpu54:2081328:2086109 [5] NCCL INFO comm 0x415b7060 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 00/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 01/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 02/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 03/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 04/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 05/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 06/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 07/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 08/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 09/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 10/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 11/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 12/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 13/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 14/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 15/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 16/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 17/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 18/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 19/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 20/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 21/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 22/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 23/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 24/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 25/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 26/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 27/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 28/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 29/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 30/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Channel 31/32 :    0
osk-gpu54:2081328:2086109 [5] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu54:2081328:2086109 [5] NCCL INFO P2P Chunksize set to 131072
osk-gpu54:2081323:2086108 [0] NCCL INFO Setting affinity for GPU 0 to 03000000,00000000,00000000,00000003
osk-gpu54:2081323:2086108 [0] NCCL INFO comm 0x41fd5f50 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 00/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 01/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 02/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 03/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 04/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 05/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 06/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 07/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 08/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 09/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 10/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 11/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 12/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 13/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 14/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 15/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 16/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 17/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 18/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 19/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 20/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 21/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 22/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 23/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 24/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 25/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 26/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 27/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 28/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 29/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 30/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Channel 31/32 :    0
osk-gpu54:2081323:2086108 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu54:2081323:2086108 [0] NCCL INFO P2P Chunksize set to 131072
osk-gpu54:2081327:2086113 [4] NCCL INFO Setting affinity for GPU 4 to 300000,00000000,00000000,00000000,30000000,00000000
osk-gpu54:2081327:2086113 [4] NCCL INFO comm 0x401dae60 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 00/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 01/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 02/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 03/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 04/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 05/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 06/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 07/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 08/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 09/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 10/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 11/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 12/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 13/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 14/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 15/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 16/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 17/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 18/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 19/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 20/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 21/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 22/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 23/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 24/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 25/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 26/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 27/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 28/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 29/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 30/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Channel 31/32 :    0
osk-gpu54:2081327:2086113 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu54:2081327:2086113 [4] NCCL INFO P2P Chunksize set to 131072
osk-gpu54:2081324:2086107 [1] NCCL INFO Connected all rings
osk-gpu54:2081324:2086107 [1] NCCL INFO Connected all trees
osk-gpu54:2081324:2086107 [1] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081324:2086107 [1] NCCL INFO comm 0x4099cef0 rank 0 nranks 1 cudaDev 1 nvmlDev 1 busId 2a000 commId 0x3eb39b741010a4c4 - Init COMPLETE
osk-gpu54:2081329:2086111 [6] NCCL INFO Connected all rings
osk-gpu54:2081329:2086111 [6] NCCL INFO Connected all trees
osk-gpu54:2081329:2086111 [6] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081329:2086111 [6] NCCL INFO comm 0x40f43f10 rank 0 nranks 1 cudaDev 6 nvmlDev 6 busId ba000 commId 0xfccd16df609449f7 - Init COMPLETE
osk-gpu54:2081325:2086110 [2] NCCL INFO Connected all rings
osk-gpu54:2081325:2086110 [2] NCCL INFO Connected all trees
osk-gpu54:2081325:2086110 [2] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081323:2086108 [0] NCCL INFO Connected all rings
osk-gpu54:2081323:2086108 [0] NCCL INFO Connected all trees
osk-gpu54:2081323:2086108 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081330:2086112 [7] NCCL INFO Connected all rings
osk-gpu54:2081330:2086112 [7] NCCL INFO Connected all trees
osk-gpu54:2081330:2086112 [7] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081326:2086106 [3] NCCL INFO Connected all rings
osk-gpu54:2081326:2086106 [3] NCCL INFO Connected all trees
osk-gpu54:2081326:2086106 [3] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081327:2086113 [4] NCCL INFO Connected all rings
osk-gpu54:2081327:2086113 [4] NCCL INFO Connected all trees
osk-gpu54:2081327:2086113 [4] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081328:2086109 [5] NCCL INFO Connected all rings
osk-gpu54:2081328:2086109 [5] NCCL INFO Connected all trees
osk-gpu54:2081328:2086109 [5] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu54:2081325:2086110 [2] NCCL INFO comm 0x40d30ae0 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 3a000 commId 0xc6008384ef310b81 - Init COMPLETE
osk-gpu54:2081323:2086108 [0] NCCL INFO comm 0x41fd5f50 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 18000 commId 0x6d483630d594a199 - Init COMPLETE
osk-gpu54:2081330:2086112 [7] NCCL INFO comm 0x412bb160 rank 0 nranks 1 cudaDev 7 nvmlDev 7 busId db000 commId 0xf9b36220ff6ba145 - Init COMPLETE
osk-gpu54:2081326:2086106 [3] NCCL INFO comm 0x4205f710 rank 0 nranks 1 cudaDev 3 nvmlDev 3 busId 5d000 commId 0xd9ec57788cdf87ff - Init COMPLETE
osk-gpu54:2081328:2086109 [5] NCCL INFO comm 0x415b7060 rank 0 nranks 1 cudaDev 5 nvmlDev 5 busId ab000 commId 0xdd0611a4676c9b85 - Init COMPLETE
osk-gpu54:2081327:2086113 [4] NCCL INFO comm 0x401dae60 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId 9a000 commId 0x6d1fdb8b64889c5 - Init COMPLETE
osk-gpu54:2081329:2086142 [6] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081329:2086142 [6] NCCL INFO Using network IB
osk-gpu54:2081326:2086143 [3] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081326:2086143 [3] NCCL INFO Using network IB
osk-gpu54:2081324:2086144 [1] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081324:2086144 [1] NCCL INFO Using network IB
osk-gpu54:2081327:2086146 [4] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081327:2086146 [4] NCCL INFO Using network IB
osk-gpu54:2081323:2086148 [0] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081323:2086148 [0] NCCL INFO Using network IB
osk-gpu54:2081328:2086150 [5] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081328:2086150 [5] NCCL INFO Using network IB
osk-gpu54:2081325:2086153 [2] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081325:2086153 [2] NCCL INFO Using network IB
osk-gpu54:2081330:2086154 [7] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2081330:2086154 [7] NCCL INFO Using network IB
osk-gpu91:3193195:3193195 [3] NCCL INFO cudaDriverVersion 12080
osk-gpu91:3193206:3193206 [5] NCCL INFO cudaDriverVersion 12080
osk-gpu91:3193195:3193195 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193206:3193206 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193195:3193195 [3] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.91<0>
osk-gpu91:3193195:3193195 [3] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:3193206:3193206 [5] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.91<0>
osk-gpu91:3193206:3193206 [5] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:3193192:3193192 [2] NCCL INFO cudaDriverVersion 12080
osk-gpu91:3193192:3193192 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193192:3193192 [2] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.91<0>
osk-gpu91:3193192:3193192 [2] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:3193229:3193229 [7] NCCL INFO cudaDriverVersion 12080
osk-gpu91:3193229:3193229 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193229:3193229 [7] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.91<0>
osk-gpu91:3193229:3193229 [7] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:3193192:3193192 [2] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:3193206:3193206 [5] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:3193195:3193195 [3] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:3193229:3193229 [7] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:3193187:3193187 [1] NCCL INFO cudaDriverVersion 12080
osk-gpu91:3193187:3193187 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193202:3193202 [4] NCCL INFO cudaDriverVersion 12080
osk-gpu91:3193187:3193187 [1] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.91<0>
osk-gpu91:3193187:3193187 [1] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:3193202:3193202 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193187:3193187 [1] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:3193180:3193180 [0] NCCL INFO cudaDriverVersion 12080
osk-gpu91:3193217:3193217 [6] NCCL INFO cudaDriverVersion 12080
osk-gpu91:3193202:3193202 [4] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.91<0>
osk-gpu91:3193202:3193202 [4] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:3193180:3193180 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193217:3193217 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193202:3193202 [4] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:3193180:3193180 [0] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.91<0>
osk-gpu91:3193180:3193180 [0] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:3193217:3193217 [6] NCCL INFO Bootstrap : Using enp92s0np0:192.168.4.91<0>
osk-gpu91:3193217:3193217 [6] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:3193180:3193180 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:3193217:3193217 [6] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:3193192:3200161 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193192:3200161 [2] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu91:3193217:3200168 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193195:3200162 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193217:3200168 [6] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu91:3193195:3200162 [3] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu91:3193229:3200163 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193229:3200163 [7] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu91:3193206:3200164 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193206:3200164 [5] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu91:3193202:3200166 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193202:3200166 [4] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu91:3193180:3200167 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193180:3200167 [0] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu91:3193187:3200165 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp92s0np0
osk-gpu91:3193187:3200165 [1] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu91:3193192:3200161 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.91<0>
osk-gpu91:3193192:3200161 [2] NCCL INFO Using non-device net plugin version 0
osk-gpu91:3193192:3200161 [2] NCCL INFO Using network IB
osk-gpu91:3193217:3200168 [6] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.91<0>
osk-gpu91:3193217:3200168 [6] NCCL INFO Using non-device net plugin version 0
osk-gpu91:3193217:3200168 [6] NCCL INFO Using network IB
osk-gpu91:3193229:3200163 [7] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.91<0>
osk-gpu91:3193229:3200163 [7] NCCL INFO Using non-device net plugin version 0
osk-gpu91:3193229:3200163 [7] NCCL INFO Using network IB
osk-gpu91:3193195:3200162 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.91<0>
osk-gpu91:3193195:3200162 [3] NCCL INFO Using non-device net plugin version 0
osk-gpu91:3193195:3200162 [3] NCCL INFO Using network IB
osk-gpu91:3193202:3200166 [4] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.91<0>
osk-gpu91:3193202:3200166 [4] NCCL INFO Using non-device net plugin version 0
osk-gpu91:3193202:3200166 [4] NCCL INFO Using network IB
osk-gpu91:3193206:3200164 [5] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.91<0>
osk-gpu91:3193206:3200164 [5] NCCL INFO Using non-device net plugin version 0
osk-gpu91:3193206:3200164 [5] NCCL INFO Using network IB
osk-gpu91:3193187:3200165 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.91<0>
osk-gpu91:3193180:3200167 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp92s0np0:192.168.4.91<0>
osk-gpu91:3193187:3200165 [1] NCCL INFO Using non-device net plugin version 0
osk-gpu91:3193187:3200165 [1] NCCL INFO Using network IB
osk-gpu91:3193180:3200167 [0] NCCL INFO Using non-device net plugin version 0
osk-gpu91:3193180:3200167 [0] NCCL INFO Using network IB
