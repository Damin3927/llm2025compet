please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu91
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = bond0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 28398
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = 7200
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 28398
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 19
LOCAL_RANK               = 3
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = DETAIL
NCCL_SOCKET_IFNAME       = bond0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 356398
SLURM_NODEID             = 2
SLURM_PROCID             = 2
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=28398
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 28398)
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu91
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = bond0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 28398
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = 7200
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 28398
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 17
LOCAL_RANK               = 1
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = DETAIL
NCCL_SOCKET_IFNAME       = bond0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 356398
SLURM_NODEID             = 2
SLURM_PROCID             = 2
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=28398
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 28398)
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu91
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = bond0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 28398
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = 7200
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 28398
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 23
LOCAL_RANK               = 7
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = DETAIL
NCCL_SOCKET_IFNAME       = bond0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 356398
SLURM_NODEID             = 2
SLURM_PROCID             = 2
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=28398
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 28398)
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu91
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = bond0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 28398
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = 7200
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 28398
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 21
LOCAL_RANK               = 5
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = DETAIL
NCCL_SOCKET_IFNAME       = bond0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 356398
SLURM_NODEID             = 2
SLURM_PROCID             = 2
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=28398
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 28398)
[Diag] TCP connect osk-gpu54:28398 -> OK (0 ms)
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu91
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = bond0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 28398
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = 7200
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 28398
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 16
LOCAL_RANK               = 0
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = DETAIL
NCCL_SOCKET_IFNAME       = bond0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 356398
SLURM_NODEID             = 2
SLURM_PROCID             = 2
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=28398
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 28398)
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu91
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = bond0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 28398
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = 7200
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 28398
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 20
LOCAL_RANK               = 4
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = DETAIL
NCCL_SOCKET_IFNAME       = bond0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 356398
SLURM_NODEID             = 2
SLURM_PROCID             = 2
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=28398
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 28398)
[Diag] TCP connect osk-gpu54:28398 -> OK (0 ms)
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu91
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = bond0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 28398
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = 7200
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 28398
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 22
LOCAL_RANK               = 6
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = DETAIL
NCCL_SOCKET_IFNAME       = bond0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 356398
SLURM_NODEID             = 2
SLURM_PROCID             = 2
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=28398
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 28398)
[Diag] TCP connect osk-gpu54:28398 -> OK (26 ms)
[Diag] TCP connect osk-gpu54:28398 -> OK (23 ms)
[Diag] TCP connect osk-gpu54:28398 -> OK (13 ms)
[Diag] TCP connect osk-gpu54:28398 -> OK (20 ms)
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu91
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = bond0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 28398
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = 7200
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 28398
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 18
LOCAL_RANK               = 2
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = DETAIL
NCCL_SOCKET_IFNAME       = bond0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 356398
SLURM_NODEID             = 2
SLURM_PROCID             = 2
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=28398
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 28398)
[Diag] TCP connect osk-gpu54:28398 -> OK (0 ms)
[Diag] TCP connect osk-gpu54:28398 -> OK (4 ms)

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.91/24 
enp41s0np0       UP             192.168.2.91/24 
enp59s0np0       UP             192.168.3.91/24 
enp86s0np0       UP             192.168.11.91/24 
enp92s0np0       UP             192.168.4.91/24 
enp155s0np0      UP             192.168.5.91/24 
enp170s0np0      UP             192.168.6.91/24 
enp187s0np0      UP             192.168.7.91/24 
enp210s0np0      UP             192.168.12.91/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.91/24 
bond0            UP             10.255.255.91/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.91/24 
enp41s0np0       UP             192.168.2.91/24 
enp59s0np0       UP             192.168.3.91/24 
enp86s0np0       UP             192.168.11.91/24 
enp92s0np0       UP             192.168.4.91/24 
enp155s0np0      UP             192.168.5.91/24 
enp170s0np0      UP             192.168.6.91/24 
enp187s0np0      UP             192.168.7.91/24 
enp210s0np0      UP             192.168.12.91/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.91/24 
bond0            UP             10.255.255.91/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.91/24 
enp41s0np0       UP             192.168.2.91/24 
enp59s0np0       UP             192.168.3.91/24 
enp86s0np0       UP             192.168.11.91/24 
enp92s0np0       UP             192.168.4.91/24 
enp155s0np0      UP             192.168.5.91/24 
enp170s0np0      UP             192.168.6.91/24 
enp187s0np0      UP             192.168.7.91/24 
enp210s0np0      UP             192.168.12.91/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.91/24 
bond0            UP             10.255.255.91/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.91/24 
enp41s0np0       UP             192.168.2.91/24 
enp59s0np0       UP             192.168.3.91/24 
enp86s0np0       UP             192.168.11.91/24 
enp92s0np0       UP             192.168.4.91/24 
enp155s0np0      UP             192.168.5.91/24 
enp170s0np0      UP             192.168.6.91/24 
enp187s0np0      UP             192.168.7.91/24 
enp210s0np0      UP             192.168.12.91/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.91/24 
bond0            UP             10.255.255.91/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.91/24 
enp41s0np0       UP             192.168.2.91/24 
enp59s0np0       UP             192.168.3.91/24 
enp86s0np0       UP             192.168.11.91/24 
enp92s0np0       UP             192.168.4.91/24 
enp155s0np0      UP             192.168.5.91/24 
enp170s0np0      UP             192.168.6.91/24 
enp187s0np0      UP             192.168.7.91/24 
enp210s0np0      UP             192.168.12.91/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.91/24 
bond0            UP             10.255.255.91/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.91/24 
enp41s0np0       UP             192.168.2.91/24 
enp59s0np0       UP             192.168.3.91/24 
enp86s0np0       UP             192.168.11.91/24 
enp92s0np0       UP             192.168.4.91/24 
enp155s0np0      UP             192.168.5.91/24 
enp170s0np0      UP             192.168.6.91/24 
enp187s0np0      UP             192.168.7.91/24 
enp210s0np0      UP             192.168.12.91/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.91/24 
bond0            UP             10.255.255.91/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.91/24 
enp41s0np0       UP             192.168.2.91/24 
enp59s0np0       UP             192.168.3.91/24 
enp86s0np0       UP             192.168.11.91/24 
enp92s0np0       UP             192.168.4.91/24 
enp155s0np0      UP             192.168.5.91/24 
enp170s0np0      UP             192.168.6.91/24 
enp187s0np0      UP             192.168.7.91/24 
enp210s0np0      UP             192.168.12.91/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.91/24 
bond0            UP             10.255.255.91/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.91/24 
enp41s0np0       UP             192.168.2.91/24 
enp59s0np0       UP             192.168.3.91/24 
enp86s0np0       UP             192.168.11.91/24 
enp92s0np0       UP             192.168.4.91/24 
enp155s0np0      UP             192.168.5.91/24 
enp170s0np0      UP             192.168.6.91/24 
enp187s0np0      UP             192.168.7.91/24 
enp210s0np0      UP             192.168.12.91/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.91/24 
bond0            UP             10.255.255.91/24

[Diag] ss -lntp | grep :28398:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = 7200

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====
[DEBUG] Set default ProcessGroup timeout to 7200 seconds
=== [Debug] ProcessGroup timeout c10d._DEFAULT_PG_TIMEOUT set to = 2:00:00 ===

[Diag] ss -lntp | grep :28398:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = 7200

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====
[DEBUG] Set default ProcessGroup timeout to 7200 seconds
=== [Debug] ProcessGroup timeout c10d._DEFAULT_PG_TIMEOUT set to = 2:00:00 ===

[Diag] ss -lntp | grep :28398:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = 7200

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====
[DEBUG] Set default ProcessGroup timeout to 7200 seconds
=== [Debug] ProcessGroup timeout c10d._DEFAULT_PG_TIMEOUT set to = 2:00:00 ===

[Diag] ss -lntp | grep :28398:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = 7200

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====
[DEBUG] Set default ProcessGroup timeout to 7200 seconds
=== [Debug] ProcessGroup timeout c10d._DEFAULT_PG_TIMEOUT set to = 2:00:00 ===

[Diag] ss -lntp | grep :28398:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = 7200

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====
[DEBUG] Set default ProcessGroup timeout to 7200 seconds
=== [Debug] ProcessGroup timeout c10d._DEFAULT_PG_TIMEOUT set to = 2:00:00 ===

[Diag] ss -lntp | grep :28398:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = 7200

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====
[DEBUG] Set default ProcessGroup timeout to 7200 seconds
=== [Debug] ProcessGroup timeout c10d._DEFAULT_PG_TIMEOUT set to = 2:00:00 ===

[Diag] ss -lntp | grep :28398:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = 7200

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====
[DEBUG] Set default ProcessGroup timeout to 7200 seconds
=== [Debug] ProcessGroup timeout c10d._DEFAULT_PG_TIMEOUT set to = 2:00:00 ===

[Diag] ss -lntp | grep :28398:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = 7200

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====
[DEBUG] Set default ProcessGroup timeout to 7200 seconds
=== [Debug] ProcessGroup timeout c10d._DEFAULT_PG_TIMEOUT set to = 2:00:00 ===
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/356398/tb: rank=20
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/356398/tb: rank=16
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/356398/tb: rank=19
[DEBUG] is_master=True  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/356398/tb: rank=23
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/356398/tb: rank=21
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/356398/tb: rank=22
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/356398/tb: rank=17
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/356398/tb: rank=18
[DEBUG] Creating tensorboard dir: /home/Competition2025/P02/P02U006/ColossalAI/logs/356398/tb
[DEBUG] Tensorboard SummaryWriter created
[DEBUG] Saving config to training_config.json
dataset size: 2160
dataset size: 2160
dataset size: 2160
dataloader batch_size: 4, total batches: 67
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 4, total batches: 67
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 4, total batches: 67
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataloader batch_size: 4, total batches: 67
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 4, total batches: 67
dataloader batch_size: 4, total batches: 67
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 4, total batches: 67
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 4, total batches: 67
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.24672603607177734 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.2139148712158203 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.1869504451751709 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 2.752713918685913 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 0.32044029235839844 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.5053908824920654 seconds
[extension] Time taken to load cpu_adam_x86 op: 1.0376429557800293 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.4677083492279053 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 1.0321335792541504 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.23465847969055176 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.3696467876434326 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 0.40465283393859863 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 0.22724390029907227 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.4669461250305176 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.18836021423339844 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.4663996696472168 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Booster boost completed: rank=19 ===
=== [Debug] Booster boost completed: rank=23 ===
=== [Debug] Booster boost completed: rank=22 ===
=== [Debug] Booster boost completed: rank=20 ===
=== [Debug] Booster boost completed: rank=16 ===
=== [Debug] Booster boost completed: rank=21 ===
=== [Debug] Booster boost completed: rank=17 ===
=== [Debug] Booster boost completed: rank=18 ===
=== [Debug] Model loaded from pretrained: rank=23 ===
[DBG] default pg backend = nccl
=== [Debug] Model loaded from pretrained: rank=16 ===
[DBG] default pg backend = nccl
=== [Debug] Model loaded from pretrained: rank=22 ===
[DBG] default pg backend = nccl
=== [Debug] Model loaded from pretrained: rank=17 ===
[DBG] default pg backend = nccl
osk-gpu91:2820710:2820710 [7] NCCL INFO NCCL_SOCKET_IFNAME set to bond0
osk-gpu91:2820710:2820710 [7] NCCL INFO Bootstrap : Using bond0:10.255.255.91<0>
osk-gpu91:2820710:2820710 [7] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:2820710:2820710 [7] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:2820710:2820710 [7] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
osk-gpu91:2820710:2846898 [7] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1
osk-gpu91:2820710:2846898 [7] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_11:1/RoCE [RO]; OOB bond0:10.255.255.91<0>
osk-gpu91:2820710:2846898 [7] NCCL INFO Using non-device net plugin version 0
osk-gpu91:2820710:2846898 [7] NCCL INFO Using network IB
osk-gpu91:2820710:2846898 [7] NCCL INFO comm 0x18e2c990 rank 0 nranks 1 cudaDev 7 nvmlDev 7 busId db000 commId 0x211d2bd594947d50 - Init START
osk-gpu91:2820710:2846898 [7] NCCL INFO MNNVL busId 0xdb000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu91:2820710:2846898 [7] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 0 'mlx5_0'
osk-gpu91:2820710:2846898 [7] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 1 'mlx5_1'
osk-gpu91:2820710:2846898 [7] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 2 'mlx5_11'
osk-gpu91:2820710:2846898 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 0
osk-gpu91:2820710:2846898 [7] NCCL INFO GPU Direct RDMA Disabled for GPU db000 / HCA 0 (distance 7 > 4)
osk-gpu91:2820710:2846898 [7] NCCL INFO GPU Direct RDMA Disabled for GPU db000 / HCA 1 (distance 7 > 4)
osk-gpu91:2820710:2846898 [7] NCCL INFO comm 0x18e2c990 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 00/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 01/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 02/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 03/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 04/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 05/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 06/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 07/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 08/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 09/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 10/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 11/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 12/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 13/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 14/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 15/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 16/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 17/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 18/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 19/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 20/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 21/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 22/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 23/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 24/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 25/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 26/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 27/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 28/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 29/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 30/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Channel 31/32 :    0
osk-gpu91:2820710:2846898 [7] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu91:2820710:2846898 [7] NCCL INFO P2P Chunksize set to 131072
osk-gpu91:2820710:2846898 [7] NCCL INFO Connected all rings
osk-gpu91:2820710:2846898 [7] NCCL INFO Connected all trees
osk-gpu91:2820710:2846898 [7] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu91:2820710:2846905 [7] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
osk-gpu91:2820710:2846898 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x145440004df0
osk-gpu91:2820710:2846898 [7] NCCL INFO comm 0x18e2c990 rank 0 nranks 1 cudaDev 7 nvmlDev 7 busId db000 commId 0x211d2bd594947d50 - Init COMPLETE
=== [Debug] Model loaded from pretrained: rank=21 ===
[DBG] default pg backend = nccl
=== [Debug] Model loaded from pretrained: rank=18 ===
[DBG] default pg backend = nccl
osk-gpu91:2820710:2848628 [7] NCCL INFO Using non-device net plugin version 0
osk-gpu91:2820710:2848628 [7] NCCL INFO Using network IB
osk-gpu91:2820710:2848628 [7] NCCL INFO comm 0xa4a83b0 rank 2 nranks 3 cudaDev 7 nvmlDev 7 busId db000 commId 0x6fea729aa05b2547 - Init START
osk-gpu91:2820710:2848628 [7] NCCL INFO MNNVL busId 0xdb000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu91:2820710:2848628 [7] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 0 'mlx5_0'
osk-gpu91:2820710:2848628 [7] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 1 'mlx5_1'
osk-gpu91:2820710:2848628 [7] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 2 'mlx5_11'
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 0
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Disabled for GPU db000 / HCA 0 (distance 7 > 4)
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Disabled for GPU db000 / HCA 1 (distance 7 > 4)
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 0
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Disabled for GPU db000 / HCA 0 (distance 7 > 4)
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Disabled for GPU db000 / HCA 1 (distance 7 > 4)
osk-gpu91:2820710:2848628 [7] NCCL INFO comm 0xa4a83b0 rank 2 nRanks 3 nNodes 3 localRanks 1 localRank 0 MNNVL 0
osk-gpu91:2820710:2848628 [7] NCCL INFO Trees [0] 1/-1/-1->2->0 [1] 1/-1/-1->2->0 [2] -1/-1/-1->2->0 [3] -1/-1/-1->2->0
osk-gpu91:2820710:2848628 [7] NCCL INFO P2P Chunksize set to 131072
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 0
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy recv connection 0 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c004f30
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 00/0 : 1[7] -> 2[7] [receive] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 0
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy recv connection 1 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c004fa8
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 01/0 : 1[7] -> 2[7] [receive] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 0
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy recv connection 2 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c005020
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 02/0 : 1[7] -> 2[7] [receive] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 0
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy recv connection 3 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c005098
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 03/0 : 1[7] -> 2[7] [receive] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 1
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy send connection 4 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c005110
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 00/0 : 2[7] -> 0[7] [send] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 1
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy send connection 5 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c005188
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 01/0 : 2[7] -> 0[7] [send] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 1
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy send connection 6 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c005200
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 02/0 : 2[7] -> 0[7] [send] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 1
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy send connection 7 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c005278
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 03/0 : 2[7] -> 0[7] [send] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848629 [7] NCCL INFO NET/IB: NCCL Dev 2 IbDev 2 Port 1 qpn 16427 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/5B08A8C0FFFF0000) fifoRkey=0x178845 fifoLkey=0x178845
osk-gpu91:2820710:2848629 [7] NCCL INFO NET/IB: NCCL Dev 2 IbDev 2 Port 1 qpn 16430 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/5B08A8C0FFFF0000) fifoRkey=0x174403 fifoLkey=0x174403
osk-gpu91:2820710:2848629 [7] NCCL INFO NET/IB: IbDev 2 Port 1 qpn 129195 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
osk-gpu91:2820710:2848629 [7] NCCL INFO NET/IB: IbDev 2 Port 1 qpn 129197 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
osk-gpu91:2820710:2848629 [7] NCCL INFO NET/IB: NCCL Dev 2 IbDev 2 Port 1 qpn 16433 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/5B08A8C0FFFF0000) fifoRkey=0x1228e6 fifoLkey=0x1228e6
osk-gpu91:2820710:2848629 [7] NCCL INFO NET/IB: NCCL Dev 2 IbDev 2 Port 1 qpn 16434 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/5B08A8C0FFFF0000) fifoRkey=0x1ff1af fifoLkey=0x1ff1af
osk-gpu91:2820710:2848629 [7] NCCL INFO NET/IB: IbDev 2 Port 1 qpn 129199 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
osk-gpu91:2820710:2848629 [7] NCCL INFO NET/IB: IbDev 2 Port 1 qpn 129201 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected all rings
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 0
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy recv connection 8 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c0052f0
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 00/0 : 0[7] -> 2[7] [receive] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 0
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy recv connection 9 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c005368
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 01/0 : 0[7] -> 2[7] [receive] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 0
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy recv connection 10 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c0053e0
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 02/0 : 0[7] -> 2[7] [receive] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 0
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy recv connection 11 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c005458
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 03/0 : 0[7] -> 2[7] [receive] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 1
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy send connection 12 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c0054d0
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 00/0 : 2[7] -> 1[7] [send] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848628 [7] NCCL INFO GPU Direct RDMA Enabled for GPU db000 / HCA 2 (distance 3 <= 4), read 1
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy send connection 13 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c005548
osk-gpu91:2820710:2848628 [7] NCCL INFO Channel 01/0 : 2[7] -> 1[7] [send] via NET/IB/2/GDRDMA
osk-gpu91:2820710:2848629 [7] NCCL INFO NET/IB: NCCL Dev 2 IbDev 2 Port 1 qpn 16439 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/5B08A8C0FFFF0000) fifoRkey=0x179756 fifoLkey=0x179756
osk-gpu91:2820710:2848629 [7] NCCL INFO NET/IB: NCCL Dev 2 IbDev 2 Port 1 qpn 16442 mtu 5 query_ece={supported=1, vendor_id=0x15b3, options=0x30000002, comp_mask=0x0} GID 3 (0/5B08A8C0FFFF0000) fifoRkey=0x17ae6d fifoLkey=0x17ae6d
osk-gpu91:2820710:2848629 [7] NCCL INFO NET/IB: IbDev 2 Port 1 qpn 394 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
osk-gpu91:2820710:2848629 [7] NCCL INFO NET/IB: IbDev 2 Port 1 qpn 396 set_ece={supported=1, vendor_id=0x15b3, options=0x0, comp_mask=0x0}
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected all trees
osk-gpu91:2820710:2848628 [7] NCCL INFO threadThresholds 8/8/64 | 24/8/64 | 512 | 512
osk-gpu91:2820710:2848628 [7] NCCL INFO 4 coll channels, 0 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
osk-gpu91:2820710:2848629 [7] NCCL INFO New proxy send connection 14 from local rank 0, transport 2
osk-gpu91:2820710:2848628 [7] NCCL INFO Connected to proxy localRank 0 -> connection 0x14549c0055c0
osk-gpu91:2820710:2848628 [7] NCCL INFO comm 0xa4a83b0 rank 2 nranks 3 cudaDev 7 nvmlDev 7 busId db000 commId 0x6fea729aa05b2547 - Init COMPLETE
[DBG] barrier passed: rank=23
=== [Debug] Model loaded from pretrained: rank=19 ===
[DBG] default pg backend = nccl
=== [Debug] Model loaded from pretrained: rank=20 ===
[DBG] default pg backend = nccl
osk-gpu91:2820702:2820702 [0] NCCL INFO NCCL_SOCKET_IFNAME set to bond0
osk-gpu91:2820708:2820708 [6] NCCL INFO NCCL_SOCKET_IFNAME set to bond0
osk-gpu91:2820708:2820708 [6] NCCL INFO Bootstrap : Using bond0:10.255.255.91<0>
osk-gpu91:2820702:2820702 [0] NCCL INFO Bootstrap : Using bond0:10.255.255.91<0>
osk-gpu91:2820708:2820708 [6] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:2820702:2820702 [0] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:2820708:2820708 [6] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:2820702:2820702 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:2820708:2820708 [6] NCCL INFO cudaDriverVersion 12080
osk-gpu91:2820702:2820702 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
NCCL version 2.20.5+cuda12.4
osk-gpu91:2820702:2848926 [0] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1
osk-gpu91:2820708:2848927 [6] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1
osk-gpu91:2820702:2848926 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_11:1/RoCE [RO]; OOB bond0:10.255.255.91<0>
osk-gpu91:2820702:2848926 [0] NCCL INFO Using non-device net plugin version 0
osk-gpu91:2820702:2848926 [0] NCCL INFO Using network IB
osk-gpu91:2820708:2848927 [6] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_11:1/RoCE [RO]; OOB bond0:10.255.255.91<0>
osk-gpu91:2820708:2848927 [6] NCCL INFO Using non-device net plugin version 0
osk-gpu91:2820708:2848927 [6] NCCL INFO Using network IB
osk-gpu91:2820702:2848926 [0] NCCL INFO comm 0x1ab5d8d0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 18000 commId 0x1d550a42c46673c1 - Init START
osk-gpu91:2820702:2848926 [0] NCCL INFO MNNVL busId 0x18000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu91:2820702:2848926 [0] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 0 'mlx5_0'
osk-gpu91:2820702:2848926 [0] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 1 'mlx5_1'
osk-gpu91:2820702:2848926 [0] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 2 'mlx5_11'
osk-gpu91:2820702:2848926 [0] NCCL INFO GPU Direct RDMA Enabled for GPU 18000 / HCA 0 (distance 3 <= 4), read 0
osk-gpu91:2820702:2848926 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 18000 / HCA 1 (distance 6 > 4)
osk-gpu91:2820702:2848926 [0] NCCL INFO GPU Direct RDMA Disabled for GPU 18000 / HCA 2 (distance 7 > 4)
osk-gpu91:2820702:2848926 [0] NCCL INFO comm 0x1ab5d8d0 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 00/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 01/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 02/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 03/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 04/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 05/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 06/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 07/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 08/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 09/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 10/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 11/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 12/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 13/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 14/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 15/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 16/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 17/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 18/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 19/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 20/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 21/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 22/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 23/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 24/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 25/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 26/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 27/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 28/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 29/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 30/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Channel 31/32 :    0
osk-gpu91:2820702:2848926 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu91:2820702:2848926 [0] NCCL INFO P2P Chunksize set to 131072
osk-gpu91:2820708:2848927 [6] NCCL INFO comm 0x1a629d30 rank 0 nranks 1 cudaDev 6 nvmlDev 6 busId ba000 commId 0x49924be103428115 - Init START
osk-gpu91:2820708:2848927 [6] NCCL INFO MNNVL busId 0xba000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu91:2820708:2848927 [6] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 0 'mlx5_0'
osk-gpu91:2820708:2848927 [6] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 1 'mlx5_1'
osk-gpu91:2820708:2848927 [6] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 2 'mlx5_11'
osk-gpu91:2820708:2848927 [6] NCCL INFO GPU Direct RDMA Disabled for GPU ba000 / HCA 0 (distance 7 > 4)
osk-gpu91:2820708:2848927 [6] NCCL INFO GPU Direct RDMA Disabled for GPU ba000 / HCA 1 (distance 7 > 4)
osk-gpu91:2820708:2848927 [6] NCCL INFO GPU Direct RDMA Disabled for GPU ba000 / HCA 2 (distance 7 > 4)
osk-gpu91:2820708:2848927 [6] NCCL INFO Setting affinity for GPU 6 to 100000,00000000,00000000,00000000,10000000,00000000
osk-gpu91:2820708:2848927 [6] NCCL INFO comm 0x1a629d30 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 00/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 01/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 02/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 03/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 04/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 05/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 06/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 07/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 08/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 09/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 10/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 11/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 12/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 13/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 14/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 15/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 16/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 17/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 18/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 19/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 20/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 21/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 22/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 23/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 24/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 25/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 26/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 27/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 28/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 29/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 30/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Channel 31/32 :    0
osk-gpu91:2820708:2848927 [6] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu91:2820708:2848927 [6] NCCL INFO P2P Chunksize set to 131072
osk-gpu91:2820702:2848926 [0] NCCL INFO Connected all rings
osk-gpu91:2820702:2848926 [0] NCCL INFO Connected all trees
osk-gpu91:2820702:2848926 [0] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu91:2820702:2848935 [0] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
osk-gpu91:2820702:2848926 [0] NCCL INFO Connected to proxy localRank 0 -> connection 0x14f890005960
osk-gpu91:2820708:2848927 [6] NCCL INFO Connected all rings
osk-gpu91:2820708:2848927 [6] NCCL INFO Connected all trees
osk-gpu91:2820708:2848927 [6] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu91:2820708:2848937 [6] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
osk-gpu91:2820708:2848927 [6] NCCL INFO Connected to proxy localRank 0 -> connection 0x14ae8c032600
osk-gpu91:2820702:2848926 [0] NCCL INFO comm 0x1ab5d8d0 rank 0 nranks 1 cudaDev 0 nvmlDev 0 busId 18000 commId 0x1d550a42c46673c1 - Init COMPLETE
osk-gpu91:2820708:2848927 [6] NCCL INFO comm 0x1a629d30 rank 0 nranks 1 cudaDev 6 nvmlDev 6 busId ba000 commId 0x49924be103428115 - Init COMPLETE
[DBG] barrier passed: rank=16
osk-gpu91:2820703:2820703 [1] NCCL INFO NCCL_SOCKET_IFNAME set to bond0
osk-gpu91:2820703:2820703 [1] NCCL INFO Bootstrap : Using bond0:10.255.255.91<0>
osk-gpu91:2820703:2820703 [1] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:2820703:2820703 [1] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:2820703:2820703 [1] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
osk-gpu91:2820705:2820705 [3] NCCL INFO NCCL_SOCKET_IFNAME set to bond0
osk-gpu91:2820705:2820705 [3] NCCL INFO Bootstrap : Using bond0:10.255.255.91<0>
osk-gpu91:2820705:2820705 [3] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:2820705:2820705 [3] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:2820705:2820705 [3] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
osk-gpu91:2820707:2820707 [5] NCCL INFO NCCL_SOCKET_IFNAME set to bond0
osk-gpu91:2820707:2820707 [5] NCCL INFO Bootstrap : Using bond0:10.255.255.91<0>
osk-gpu91:2820707:2820707 [5] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:2820707:2820707 [5] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:2820707:2820707 [5] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
osk-gpu91:2820704:2820704 [2] NCCL INFO NCCL_SOCKET_IFNAME set to bond0
osk-gpu91:2820704:2820704 [2] NCCL INFO Bootstrap : Using bond0:10.255.255.91<0>
osk-gpu91:2820704:2820704 [2] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:2820706:2820706 [4] NCCL INFO NCCL_SOCKET_IFNAME set to bond0
osk-gpu91:2820706:2820706 [4] NCCL INFO Bootstrap : Using bond0:10.255.255.91<0>
osk-gpu91:2820706:2820706 [4] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu91:2820706:2820706 [4] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:2820706:2820706 [4] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
osk-gpu91:2820704:2820704 [2] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu91:2820704:2820704 [2] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
osk-gpu91:2820707:2849836 [5] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1
osk-gpu91:2820703:2849832 [1] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1
osk-gpu91:2820705:2849834 [3] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1
osk-gpu91:2820706:2849838 [4] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1
osk-gpu91:2820704:2849840 [2] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1
osk-gpu91:2820707:2849836 [5] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_11:1/RoCE [RO]; OOB bond0:10.255.255.91<0>
osk-gpu91:2820707:2849836 [5] NCCL INFO Using non-device net plugin version 0
osk-gpu91:2820707:2849836 [5] NCCL INFO Using network IB
osk-gpu91:2820705:2849834 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_11:1/RoCE [RO]; OOB bond0:10.255.255.91<0>
osk-gpu91:2820705:2849834 [3] NCCL INFO Using non-device net plugin version 0
osk-gpu91:2820705:2849834 [3] NCCL INFO Using network IB
osk-gpu91:2820706:2849838 [4] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_11:1/RoCE [RO]; OOB bond0:10.255.255.91<0>
osk-gpu91:2820706:2849838 [4] NCCL INFO Using non-device net plugin version 0
osk-gpu91:2820706:2849838 [4] NCCL INFO Using network IB
osk-gpu91:2820703:2849832 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_11:1/RoCE [RO]; OOB bond0:10.255.255.91<0>
osk-gpu91:2820703:2849832 [1] NCCL INFO Using non-device net plugin version 0
osk-gpu91:2820703:2849832 [1] NCCL INFO Using network IB
osk-gpu91:2820704:2849840 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_11:1/RoCE [RO]; OOB bond0:10.255.255.91<0>
osk-gpu91:2820704:2849840 [2] NCCL INFO Using non-device net plugin version 0
osk-gpu91:2820704:2849840 [2] NCCL INFO Using network IB
osk-gpu91:2820707:2849836 [5] NCCL INFO comm 0x174b32a0 rank 0 nranks 1 cudaDev 5 nvmlDev 5 busId ab000 commId 0x83b8b7733f3d63b - Init START
osk-gpu91:2820707:2849836 [5] NCCL INFO MNNVL busId 0xab000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu91:2820707:2849836 [5] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 0 'mlx5_0'
osk-gpu91:2820707:2849836 [5] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 1 'mlx5_1'
osk-gpu91:2820707:2849836 [5] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 2 'mlx5_11'
osk-gpu91:2820707:2849836 [5] NCCL INFO GPU Direct RDMA Disabled for GPU ab000 / HCA 0 (distance 7 > 4)
osk-gpu91:2820707:2849836 [5] NCCL INFO GPU Direct RDMA Disabled for GPU ab000 / HCA 1 (distance 7 > 4)
osk-gpu91:2820707:2849836 [5] NCCL INFO GPU Direct RDMA Disabled for GPU ab000 / HCA 2 (distance 7 > 4)
osk-gpu91:2820707:2849836 [5] NCCL INFO Setting affinity for GPU 5 to 100000,00000000,00000000,00000000,10000000,00000000
osk-gpu91:2820707:2849836 [5] NCCL INFO comm 0x174b32a0 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 00/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 01/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 02/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 03/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 04/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 05/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 06/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 07/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 08/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 09/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 10/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 11/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 12/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 13/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 14/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 15/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 16/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 17/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 18/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 19/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 20/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 21/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 22/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 23/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 24/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 25/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 26/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 27/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 28/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 29/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 30/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Channel 31/32 :    0
osk-gpu91:2820707:2849836 [5] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu91:2820707:2849836 [5] NCCL INFO P2P Chunksize set to 131072
osk-gpu91:2820705:2849834 [3] NCCL INFO comm 0x19b7ba00 rank 0 nranks 1 cudaDev 3 nvmlDev 3 busId 5d000 commId 0xa1e70e23a131f3a2 - Init START
osk-gpu91:2820705:2849834 [3] NCCL INFO MNNVL busId 0x5d000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu91:2820706:2849838 [4] NCCL INFO comm 0x19040780 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId 9a000 commId 0x38b2d480c8214bcc - Init START
osk-gpu91:2820706:2849838 [4] NCCL INFO MNNVL busId 0x9a000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu91:2820705:2849834 [3] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 0 'mlx5_0'
osk-gpu91:2820705:2849834 [3] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 1 'mlx5_1'
osk-gpu91:2820705:2849834 [3] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 2 'mlx5_11'
osk-gpu91:2820705:2849834 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 5d000 / HCA 0 (distance 7 > 4)
osk-gpu91:2820705:2849834 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 5d000 / HCA 1 (distance 7 > 4)
osk-gpu91:2820705:2849834 [3] NCCL INFO GPU Direct RDMA Disabled for GPU 5d000 / HCA 2 (distance 7 > 4)
osk-gpu91:2820705:2849834 [3] NCCL INFO comm 0x19b7ba00 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 00/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 01/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 02/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 03/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 04/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 05/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 06/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 07/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 08/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 09/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 10/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 11/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 12/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 13/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 14/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 15/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 16/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 17/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 18/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 19/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 20/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 21/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 22/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 23/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 24/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 25/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 26/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 27/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 28/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 29/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 30/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Channel 31/32 :    0
osk-gpu91:2820705:2849834 [3] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu91:2820705:2849834 [3] NCCL INFO P2P Chunksize set to 131072
osk-gpu91:2820704:2849840 [2] NCCL INFO comm 0x13b022b0 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 3a000 commId 0xea31916a383ef956 - Init START
osk-gpu91:2820704:2849840 [2] NCCL INFO MNNVL busId 0x3a000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu91:2820703:2849832 [1] NCCL INFO comm 0x1ac132c0 rank 0 nranks 1 cudaDev 1 nvmlDev 1 busId 2a000 commId 0x2752a152206cf889 - Init START
osk-gpu91:2820703:2849832 [1] NCCL INFO MNNVL busId 0x2a000 fabric UUID 0.0 cliqueId 0x0 state 3 healthMask 0x0
osk-gpu91:2820704:2849840 [2] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 0 'mlx5_0'
osk-gpu91:2820704:2849840 [2] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 1 'mlx5_1'
osk-gpu91:2820704:2849840 [2] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 2 'mlx5_11'
osk-gpu91:2820704:2849840 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 3a000 / HCA 0 (distance 6 > 4)
osk-gpu91:2820704:2849840 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 3a000 / HCA 1 (distance 6 > 4)
osk-gpu91:2820704:2849840 [2] NCCL INFO GPU Direct RDMA Disabled for GPU 3a000 / HCA 2 (distance 7 > 4)
osk-gpu91:2820704:2849840 [2] NCCL INFO comm 0x13b022b0 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 00/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 01/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 02/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 03/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 04/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 05/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 06/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 07/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 08/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 09/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 10/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 11/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 12/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 13/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 14/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 15/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 16/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 17/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 18/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 19/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 20/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 21/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 22/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 23/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 24/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 25/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 26/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 27/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 28/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 29/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 30/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Channel 31/32 :    0
osk-gpu91:2820704:2849840 [2] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu91:2820704:2849840 [2] NCCL INFO P2P Chunksize set to 131072
osk-gpu91:2820706:2849838 [4] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 0 'mlx5_0'
osk-gpu91:2820706:2849838 [4] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 1 'mlx5_1'
osk-gpu91:2820706:2849838 [4] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 2 'mlx5_11'
osk-gpu91:2820706:2849838 [4] NCCL INFO GPU Direct RDMA Disabled for GPU 9a000 / HCA 0 (distance 7 > 4)
osk-gpu91:2820706:2849838 [4] NCCL INFO GPU Direct RDMA Disabled for GPU 9a000 / HCA 1 (distance 7 > 4)
osk-gpu91:2820706:2849838 [4] NCCL INFO GPU Direct RDMA Disabled for GPU 9a000 / HCA 2 (distance 7 > 4)
osk-gpu91:2820706:2849838 [4] NCCL INFO Setting affinity for GPU 4 to 100000,00000000,00000000,00000000,10000000,00000000
osk-gpu91:2820706:2849838 [4] NCCL INFO comm 0x19040780 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 00/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 01/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 02/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 03/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 04/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 05/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 06/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 07/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 08/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 09/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 10/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 11/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 12/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 13/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 14/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 15/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 16/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 17/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 18/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 19/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 20/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 21/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 22/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 23/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 24/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 25/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 26/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 27/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 28/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 29/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 30/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Channel 31/32 :    0
osk-gpu91:2820706:2849838 [4] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu91:2820706:2849838 [4] NCCL INFO P2P Chunksize set to 131072
osk-gpu91:2820703:2849832 [1] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 0 'mlx5_0'
osk-gpu91:2820703:2849832 [1] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 1 'mlx5_1'
osk-gpu91:2820703:2849832 [1] NCCL INFO NET/IB : GPU Direct RDMA Enabled for HCA 2 'mlx5_11'
osk-gpu91:2820703:2849832 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 2a000 / HCA 0 (distance 6 > 4)
osk-gpu91:2820703:2849832 [1] NCCL INFO GPU Direct RDMA Enabled for GPU 2a000 / HCA 1 (distance 3 <= 4), read 0
osk-gpu91:2820703:2849832 [1] NCCL INFO GPU Direct RDMA Disabled for GPU 2a000 / HCA 2 (distance 7 > 4)
osk-gpu91:2820703:2849832 [1] NCCL INFO comm 0x1ac132c0 rank 0 nRanks 1 nNodes 1 localRanks 1 localRank 0 MNNVL 0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 00/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 01/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 02/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 03/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 04/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 05/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 06/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 07/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 08/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 09/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 10/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 11/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 12/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 13/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 14/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 15/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 16/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 17/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 18/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 19/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 20/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 21/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 22/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 23/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 24/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 25/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 26/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 27/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 28/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 29/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 30/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Channel 31/32 :    0
osk-gpu91:2820703:2849832 [1] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
osk-gpu91:2820703:2849832 [1] NCCL INFO P2P Chunksize set to 131072
osk-gpu91:2820705:2849834 [3] NCCL INFO Connected all rings
osk-gpu91:2820705:2849834 [3] NCCL INFO Connected all trees
osk-gpu91:2820705:2849834 [3] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu91:2820705:2849864 [3] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
osk-gpu91:2820705:2849834 [3] NCCL INFO Connected to proxy localRank 0 -> connection 0x14e95c005960
osk-gpu91:2820707:2849836 [5] NCCL INFO Connected all rings
osk-gpu91:2820707:2849836 [5] NCCL INFO Connected all trees
osk-gpu91:2820707:2849836 [5] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu91:2820707:2849862 [5] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
osk-gpu91:2820707:2849836 [5] NCCL INFO Connected to proxy localRank 0 -> connection 0x14910c005960
osk-gpu91:2820706:2849838 [4] NCCL INFO Connected all rings
osk-gpu91:2820706:2849838 [4] NCCL INFO Connected all trees
osk-gpu91:2820706:2849838 [4] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu91:2820706:2849868 [4] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
osk-gpu91:2820706:2849838 [4] NCCL INFO Connected to proxy localRank 0 -> connection 0x1503480056d0
osk-gpu91:2820703:2849832 [1] NCCL INFO Connected all rings
osk-gpu91:2820703:2849832 [1] NCCL INFO Connected all trees
osk-gpu91:2820703:2849832 [1] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu91:2820703:2849870 [1] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
osk-gpu91:2820703:2849832 [1] NCCL INFO Connected to proxy localRank 0 -> connection 0x14df440008d0
osk-gpu91:2820705:2849834 [3] NCCL INFO comm 0x19b7ba00 rank 0 nranks 1 cudaDev 3 nvmlDev 3 busId 5d000 commId 0xa1e70e23a131f3a2 - Init COMPLETE
osk-gpu91:2820706:2849838 [4] NCCL INFO comm 0x19040780 rank 0 nranks 1 cudaDev 4 nvmlDev 4 busId 9a000 commId 0x38b2d480c8214bcc - Init COMPLETE
osk-gpu91:2820704:2849840 [2] NCCL INFO Connected all rings
osk-gpu91:2820704:2849840 [2] NCCL INFO Connected all trees
osk-gpu91:2820704:2849840 [2] NCCL INFO 32 coll channels, 0 collnet channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
osk-gpu91:2820707:2849836 [5] NCCL INFO comm 0x174b32a0 rank 0 nranks 1 cudaDev 5 nvmlDev 5 busId ab000 commId 0x83b8b7733f3d63b - Init COMPLETE
osk-gpu91:2820703:2849832 [1] NCCL INFO comm 0x1ac132c0 rank 0 nranks 1 cudaDev 1 nvmlDev 1 busId 2a000 commId 0x2752a152206cf889 - Init COMPLETE
osk-gpu91:2820704:2849866 [2] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
osk-gpu91:2820704:2849840 [2] NCCL INFO Connected to proxy localRank 0 -> connection 0x1518d0032540
osk-gpu91:2820704:2849840 [2] NCCL INFO comm 0x13b022b0 rank 0 nranks 1 cudaDev 2 nvmlDev 2 busId 3a000 commId 0xea31916a383ef956 - Init COMPLETE
[DBG] barrier passed: rank=22
[DBG] barrier passed: rank=17
[DBG] barrier passed: rank=20
[DBG] barrier passed: rank=18
[DBG] barrier passed: rank=21
[DBG] barrier passed: rank=19
