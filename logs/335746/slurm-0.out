please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
please install Colossal-AI from https://www.colossalai.org/download or from source
=== CONDA ENV CHECK ===
=== CONDA ENV CHECK ===sys.executable      :
 sys.executable      :/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10 
/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : CONDA_DEFAULT_ENV   :deepseeksft310 
deepseeksft310CONDA_PREFIX        :
 /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu54
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 40343
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu54
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 40343
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = None
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 40343
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 3
LOCAL_RANK               = 3
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = None
NCCL_SOCKET_IFNAME       = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 335746
SLURM_NODEID             = 0
SLURM_PROCID             = 0
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=40343
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 40343)
[Diag] TCP connect osk-gpu54:40343 -> FAIL (0 ms) err=ConnectionRefusedError(111, 'Connection refused')
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu54
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 40343
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = None
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 40343
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 5
LOCAL_RANK               = 5
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = None
NCCL_SOCKET_IFNAME       = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 335746
SLURM_NODEID             = 0
SLURM_PROCID             = 0
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=40343
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 40343)
[Diag] TCP connect osk-gpu54:40343 -> FAIL (0 ms) err=ConnectionRefusedError(111, 'Connection refused')
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu54
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 40343
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = None
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 40343
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 0
LOCAL_RANK               = 0
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:TORCH_DIST_INIT_BARRIER  = None

TORCH_DISTRIBUTED_DEBUG  = NoneRDZV_TIMEOUT                 = None

NCCL_SOCKET_IFNAME       = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0=== END ENV CHECK ===


NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
=== RDZV / torch.distributed DIAGNOSTICS ===NCCL_DEBUG               = INFO

MASTER_ADDR              = osk-gpu54NCCL_ASYNC_ERROR_HANDLING = None

MASTER_PORT              = 40343NCCL_BLOCKING_WAIT       = None

RDZV_ENDPOINT            = NoneNCCL_P2P_DISABLE         = None

RDZV_ID                  = NoneNCCL_SHM_DISABLE         = None

RDZV_BACKEND             = NoneGLOO_SOCKET_IFNAME       = bond0

WORLD_SIZE               = 24CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7

RANK                     = 2NVIDIA_VISIBLE_DEVICES   = None

LOCAL_RANK               = 2
--- SLURM ---LOCAL_WORLD_SIZE         = 8

SLURM_JOB_ID             = 335746NODE_RANK                = None

SLURM_NODEID             = 0NPROC_PER_NODE           = None

SLURM_PROCID             = 0TORCH_DIST_INIT_BARRIER  = None

SLURM_LOCALID            = 0TORCH_DISTRIBUTED_DEBUG  = None

SLURM_NTASKS             = 3NCCL_SOCKET_IFNAME       = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0

SLURM_JOB_NODELIST       = osk-gpu[54,56,91]NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1

SLURM_STEP_NODELIST      = osk-gpu[54,56,91]NCCL_DEBUG               = INFO


[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=40343NCCL_ASYNC_ERROR_HANDLING = None

NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 335746
SLURM_NODEID             = 0
SLURM_PROCID             = 0
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=40343
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 40343)
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 40343)
[Diag] TCP connect osk-gpu54:40343 -> FAIL (0 ms) err=ConnectionRefusedError(111, 'Connection refused')
[Diag] TCP connect osk-gpu54:40343 -> FAIL (0 ms) err=ConnectionRefusedError(111, 'Connection refused')
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu54
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 40343
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = None
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 40343
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 7
LOCAL_RANK               = 7
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = None
NCCL_SOCKET_IFNAME       = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 335746
SLURM_NODEID             = 0
SLURM_PROCID             = 0
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=40343
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 40343)
[Diag] TCP connect osk-gpu54:40343 -> FAIL (0 ms) err=ConnectionRefusedError(111, 'Connection refused')
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu54
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 40343
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = None
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 40343
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 6
LOCAL_RANK               = 6
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = None
NCCL_SOCKET_IFNAME       = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 335746
SLURM_NODEID             = 0
SLURM_PROCID             = 0
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=40343
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 40343)
[Diag] TCP connect osk-gpu54:40343 -> FAIL (0 ms) err=ConnectionRefusedError(111, 'Connection refused')
=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu54
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 40343
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = None
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 40343
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 1
LOCAL_RANK               = 1
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = None
NCCL_SOCKET_IFNAME       = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 335746=== CONDA ENV CHECK ===
sys.executable      : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/bin/python3.10
CONDA_DEFAULT_ENV   : deepseeksft310
CONDA_PREFIX        : /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310
python version      : 3.10.18
hostname            : osk-gpu54
torch version       : 2.4.1+cu124
=== END CONDA ENV CHECK ===

=== ENV CHECK ===
NCCL_SOCKET_IFNAME           = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA                  = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_NET_PLUGIN              = none
NCCL_DEBUG                   = INFO
NCCL_TIMEOUT                 = 7200
TORCHELASTIC_TIMEOUT         = 7200
TORCH_DISTRIBUTED_TIMEOUT    = 7200
TORCH_ELASTIC_STORE_TIMEOUT  = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
MASTER_ADDR                  = osk-gpu54
MASTER_PORT                  = 40343
CUDA_VISIBLE_DEVICES         = 0,1,2,3,4,5,6,7
LD_LIBRARY_PATH              = /home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/lib64:/home/Competition2025/P02/P02U006/miniconda3/envs/deepseeksft310/targets/x86_64-linux/lib:
RDZV_TIMEOUT                 = None
=== END ENV CHECK ===

=== RDZV / torch.distributed DIAGNOSTICS ===
MASTER_ADDR              = osk-gpu54
MASTER_PORT              = 40343
RDZV_ENDPOINT            = None
RDZV_ID                  = None
RDZV_BACKEND             = None
WORLD_SIZE               = 24
RANK                     = 4
LOCAL_RANK               = 4
LOCAL_WORLD_SIZE         = 8
NODE_RANK                = None
NPROC_PER_NODE           = None
TORCH_DIST_INIT_BARRIER  = None
TORCH_DISTRIBUTED_DEBUG  = None
NCCL_SOCKET_IFNAME       = enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
NCCL_IB_HCA              = mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
NCCL_DEBUG               = INFO
NCCL_ASYNC_ERROR_HANDLING = None
NCCL_BLOCKING_WAIT       = None
NCCL_P2P_DISABLE         = None
NCCL_SHM_DISABLE         = None
GLOO_SOCKET_IFNAME       = bond0
CUDA_VISIBLE_DEVICES     = 0,1,2,3,4,5,6,7
NVIDIA_VISIBLE_DEVICES   = None
--- SLURM ---
SLURM_JOB_ID             = 335746
SLURM_NODEID             = 0
SLURM_PROCID             = 0
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=40343
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 40343)
[Diag] TCP connect osk-gpu54:40343 -> FAIL (0 ms) err=ConnectionRefusedError(111, 'Connection refused')

SLURM_NODEID             = 0
SLURM_PROCID             = 0
SLURM_LOCALID            = 0
SLURM_NTASKS             = 3
SLURM_JOB_NODELIST       = osk-gpu[54,56,91]
SLURM_STEP_NODELIST      = osk-gpu[54,56,91]

[Diag] Using MASTER_ADDR/PORT for checks -> host=osk-gpu54, port=40343
[Diag] getaddrinfo:
  - family=AF_INET  sockaddr=('192.168.11.54', 40343)
[Diag] TCP connect osk-gpu54:40343 -> FAIL (0 ms) err=ConnectionRefusedError(111, 'Connection refused')

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.54/24 
enp41s0np0       UP             192.168.2.54/24 
enp59s0np0       UP             192.168.3.54/24 
enp86s0np0       UP             192.168.11.54/24 
enp92s0np0       UP             192.168.4.54/24 
enp155s0np0      UP             192.168.5.54/24 
enp170s0np0      UP             192.168.6.54/24 
enp187s0np0      UP             192.168.7.54/24 
enp210s0np0      UP             192.168.12.54/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.54/24 
bond0            UP             10.255.255.54/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.54/24 
enp41s0np0       UP             192.168.2.54/24 
enp59s0np0       UP             192.168.3.54/24 
enp86s0np0       UP             192.168.11.54/24 
enp92s0np0       UP             192.168.4.54/24 
enp155s0np0      UP             192.168.5.54/24 
enp170s0np0      UP             192.168.6.54/24 
enp187s0np0      UP             192.168.7.54/24 
enp210s0np0      UP             192.168.12.54/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.54/24 
bond0            UP             10.255.255.54/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.54/24 
enp41s0np0       UP             192.168.2.54/24 
enp59s0np0       UP             192.168.3.54/24 
enp86s0np0       UP             192.168.11.54/24 
enp92s0np0       UP             192.168.4.54/24 
enp155s0np0      UP             192.168.5.54/24 
enp170s0np0      UP             192.168.6.54/24 
enp187s0np0      UP             192.168.7.54/24 
enp210s0np0      UP             192.168.12.54/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.54/24 
bond0            UP             10.255.255.54/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.54/24 
enp41s0np0       UP             192.168.2.54/24 
enp59s0np0       UP             192.168.3.54/24 
enp86s0np0       UP             192.168.11.54/24 
enp92s0np0       UP             192.168.4.54/24 
enp155s0np0      UP             192.168.5.54/24 
enp170s0np0      UP             192.168.6.54/24 
enp187s0np0      UP             192.168.7.54/24 
enp210s0np0      UP             192.168.12.54/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.54/24 
bond0            UP             10.255.255.54/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.54/24 
enp41s0np0       UP             192.168.2.54/24 
enp59s0np0       UP             192.168.3.54/24 
enp86s0np0       UP             192.168.11.54/24 
enp92s0np0       UP             192.168.4.54/24 
enp155s0np0      UP             192.168.5.54/24 
enp170s0np0      UP             192.168.6.54/24 
enp187s0np0      UP             192.168.7.54/24 
enp210s0np0      UP             192.168.12.54/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.54/24 
bond0            UP             10.255.255.54/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.54/24 
enp41s0np0       UP             192.168.2.54/24 
enp59s0np0       UP             192.168.3.54/24 
enp86s0np0       UP             192.168.11.54/24 
enp92s0np0       UP             192.168.4.54/24 
enp155s0np0      UP             192.168.5.54/24 
enp170s0np0      UP             192.168.6.54/24 
enp187s0np0      UP             192.168.7.54/24 
enp210s0np0      UP             192.168.12.54/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.54/24 
bond0            UP             10.255.255.54/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.54/24 
enp41s0np0       UP             192.168.2.54/24 
enp59s0np0       UP             192.168.3.54/24 
enp86s0np0       UP             192.168.11.54/24 
enp92s0np0       UP             192.168.4.54/24 
enp155s0np0      UP             192.168.5.54/24 
enp170s0np0      UP             192.168.6.54/24 
enp187s0np0      UP             192.168.7.54/24 
enp210s0np0      UP             192.168.12.54/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.54/24 
bond0            UP             10.255.255.54/24

[Diag] ip -brief addr:
lo               UNKNOWN        127.0.0.1/8 ::1/128 
enp25s0np0       UP             192.168.1.54/24 
enp41s0np0       UP             192.168.2.54/24 
enp59s0np0       UP             192.168.3.54/24 
enp86s0np0       UP             192.168.11.54/24 
enp92s0np0       UP             192.168.4.54/24 
enp155s0np0      UP             192.168.5.54/24 
enp170s0np0      UP             192.168.6.54/24 
enp187s0np0      UP             192.168.7.54/24 
enp210s0np0      UP             192.168.12.54/24 
enp213s0f0np0    UP             
enp213s0f1np1    UP             
enp218s0np0      UP             192.168.8.54/24 
bond0            UP             10.255.255.54/24

[Diag] ss -lntp | grep :40343:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = None

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====

[Diag] ss -lntp | grep :40343:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = None

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====

[Diag] ss -lntp | grep :40343:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = None

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====

[Diag] ss -lntp | grep :40343:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = None

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====

[Diag] ss -lntp | grep :40343:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = None

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====

[Diag] ss -lntp | grep :40343:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = None

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====

[Diag] ss -lntp | grep :40343:
(no listener found or ss unavailable)

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = None

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====

[Diag] ss -lntp | grep :40343:
LISTEN 0      16384              *:40343            *:*

[Diag] Timeouts:
NCCL_TIMEOUT             = 7200
TORCHELASTIC_TIMEOUT     = 7200
TORCH_DISTRIBUTED_TIMEOUT = 7200
TORCH_ELASTIC_STORE_TIMEOUT = 7200
TORCH_DISTRIBUTED_STORE_TIMEOUT = 7200
RDZV_TIMEOUT             = None

[Hints]
- 全ノード/全ランクで MASTER_ADDR/MASTER_PORT/RDZV_ID/GLOO_SOCKET_IFNAME/NCCL_SOCKET_IFNAME が完全一致しているか確認してください。
- DNS解決失敗がある場合は MASTER_ADDR を FQDN か IP に変更するか、/etc/hosts を整備してください。
- 共有クラスタやDockerでは --network=host、固定RDZV_ID、安定した MASTER_ADDR を推奨します。
- 依然として通信で固まる場合は NCCL_DEBUG=INFO と TORCH_DISTRIBUTED_DEBUG=DETAIL を有効化すると原因特定に役立ちます。
=== END RDZV / torch.distributed DIAGNOSTICS ===

==== ColossalAI SFT script: train() Start ====
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/335746/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/335746/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/335746/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/335746/tb
[08/08/25 11:06:54] INFO     colossalai - colossalai - INFO:                    
                             /home/Competition2025/P02/P02U006/ColossalAI/coloss
                             alai/initialize.py:75 launch                       
                    INFO     colossalai - colossalai - INFO: Distributed        
                             environment is initialized, world size: 24         
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/335746/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/335746/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/335746/tb
[DEBUG] is_master=False  tensorboard_dir=/home/Competition2025/P02/P02U006/ColossalAI/logs/335746/tb
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
Training Info:
Config file: training_config.json 
Tensorboard logs: /home/Competition2025/P02/P02U006/ColossalAI/logs/335746/tb 
Model checkpoint: /home/Competition2025/P02/P02U006/ColossalAI/logs/335746/DeepSeek-R1-0528-lora
Load dataset: /home/Competition2025/P02/shareP02/hci_colossalai_deepseekr10528_lorasft.jsonl
dataset size: 2160
dataloader batch_size: 8, total batches: 33
Max device memory after data loader: 0.00 MB
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
dataset size: 2160
dataloader batch_size: 8, total batches: 33
=== [Debug] After dataloader, before model config ===
=== [Debug] Using attention implementation: eager ===
=== [Debug] AutoConfig loaded. model_type=deepseek_v3, architectures=['DeepseekV3ForCausalLM'] ===
=== [Debug] Entered init_ctx ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
[08/08/25 11:10:38] WARNING  colossalai - colossalai - WARNING:                 
                             /home/Competition2025/P02/P02U006/ColossalAI/coloss
                             alai/booster/plugin/hybrid_parallel_plugin.py:1518 
                             enable_lora                                        
                    WARNING  colossalai - colossalai - WARNING: You have enabled
                             LoRa training. Please check the hyperparameters    
                             such as lr                                         
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] Model created: DeepseekV3ForCausalLM ===
=== [Debug] Setting up LoRA ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] LoRA enabled ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Set model to train mode ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Gradient checkpointing enabled successfully ===
Gradient checkpointing enabled successfully
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Gradient checkpointing enabled successfully ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
=== [Debug] Set model to eval mode ===
Model params: 672.13 B
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 0.2509896755218506 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.6148078441619873 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 0.13474655151367188 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Loading the JIT-built cpu_adam_x86 kernel during runtime now
[extension] Time taken to load cpu_adam_x86 op: 2.4418771266937256 seconds
[extension] Time taken to load cpu_adam_x86 op: 2.2488930225372314 seconds
[extension] Time taken to load fused_optim_cuda op: 1.906630516052246 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 2.742030143737793 seconds
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.30516839027404785 seconds
[extension] Time taken to load fused_optim_cuda op: 0.30426478385925293 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load fused_optim_cuda op: 0.30424046516418457 seconds
[extension] Time taken to load cpu_adam_x86 op: 2.0092296600341797 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 2.3322534561157227 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
Default dtype set to torch.bfloat16
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.40619587898254395 seconds
[extension] Time taken to load fused_optim_cuda op: 0.4060037136077881 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Time taken to load cpu_adam_x86 op: 2.6299796104431152 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
[extension] Loading the JIT-built fused_optim_cuda kernel during runtime now
[extension] Time taken to load fused_optim_cuda op: 0.4052259922027588 seconds
=== [Debug] Using optimizer: HybridAdam ===
=== [Debug] warmup_steps: 8 ===
=== [Debug] Using LR scheduler: CosineAnnealingWarmupLR ===
=== [Debug] Booster boost completed: rank=3 ===
=== [Debug] Booster boost completed: rank=1 ===
=== [Debug] Booster boost completed: rank=6 ===
=== [Debug] Booster boost completed: rank=2 ===
=== [Debug] Booster boost completed: rank=0 ===
=== [Debug] Booster boost completed: rank=4 ===
=== [Debug] Booster boost completed: rank=7 ===
=== [Debug] Booster boost completed: rank=5 ===
=== [Debug] Model loaded from pretrained: rank=7 ===
[Debug] rank=07, host=osk-gpu54, Max device mem: 59391.18 MB, Max CPU mem: 24638.27 MB
[Debug] rank=07, host=osk-gpu54, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=0 ===
[Debug] rank=00, host=osk-gpu54, Max device mem: 59391.18 MB, Max CPU mem: 24645.17 MB
[Debug] rank=00, host=osk-gpu54, === for epoch in range(0, 2) Start ====
=== [Debug] Model loaded from pretrained: rank=1 ===
[Debug] rank=01, host=osk-gpu54, Max device mem: 59391.18 MB, Max CPU mem: 24640.35 MB
[Debug] rank=01, host=osk-gpu54, === for epoch in range(0, 2) Start ====
osk-gpu54:2563864:2563864 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
osk-gpu54:2563864:2563864 [0] NCCL INFO Bootstrap : Using enp25s0np0:192.168.1.54<0>
osk-gpu54:2563864:2563864 [0] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu54:2563864:2563864 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu54:2563864:2563864 [0] NCCL INFO cudaDriverVersion 12080
NCCL version 2.20.5+cuda12.4
osk-gpu54:2563871:2563871 [7] NCCL INFO cudaDriverVersion 12080
osk-gpu54:2563871:2563871 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
osk-gpu54:2563871:2563871 [7] NCCL INFO Bootstrap : Using enp25s0np0:192.168.1.54<0>
osk-gpu54:2563871:2563871 [7] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu54:2563871:2563871 [7] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu54:2563865:2563865 [1] NCCL INFO cudaDriverVersion 12080
osk-gpu54:2563865:2563865 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
osk-gpu54:2563865:2563865 [1] NCCL INFO Bootstrap : Using enp25s0np0:192.168.1.54<0>
osk-gpu54:2563865:2563865 [1] NCCL INFO Plugin name set by env to libnccl-net-none.so
osk-gpu54:2563865:2563865 [1] NCCL INFO NET/Plugin : dlerror=libnccl-net-none.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net-none.so), using internal implementation
osk-gpu54:2563864:2578863 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
osk-gpu54:2563864:2578863 [0] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu54:2563871:2578864 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
osk-gpu54:2563871:2578864 [7] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu54:2563864:2578863 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp25s0np0:192.168.1.54<0>
osk-gpu54:2563864:2578863 [0] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2563864:2578863 [0] NCCL INFO Using network IB
osk-gpu54:2563871:2578864 [7] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp25s0np0:192.168.1.54<0>
osk-gpu54:2563871:2578864 [7] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2563871:2578864 [7] NCCL INFO Using network IB
osk-gpu54:2563865:2578872 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to enp25s0np0,enp41s0np0,enp59s0np0,enp92s0np0,enp155s0np0,enp170s0np0,enp187s0np0,enp218s0np0
osk-gpu54:2563865:2578872 [1] NCCL INFO NCCL_IB_HCA set to mlx5_0:1,mlx5_1:1,mlx5_2:1,mlx5_4:1,mlx5_5:1,mlx5_6:1,mlx5_7:1,mlx5_11:1
osk-gpu54:2563865:2578872 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/RoCE [2]mlx5_2:1/RoCE [3]mlx5_4:1/RoCE [4]mlx5_5:1/RoCE [5]mlx5_6:1/RoCE [6]mlx5_7:1/RoCE [7]mlx5_11:1/RoCE [RO]; OOB enp25s0np0:192.168.1.54<0>
osk-gpu54:2563865:2578872 [1] NCCL INFO Using non-device net plugin version 0
osk-gpu54:2563865:2578872 [1] NCCL INFO Using network IB
