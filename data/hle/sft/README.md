# SFT ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

ã“ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ã¯ã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ç”¨ã«å‡¦ç†ã™ã‚‹ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ãƒ„ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã¯ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€å‡¦ç†ã€Hugging Faceã¸ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¾ã™ã€‚

## ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
data/hle/sft/
â”œâ”€â”€ OpenMathReasoningFiltering.py          # LLMãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ OpenMathReasoningFiltering_bylabel.py  # ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆé«˜é€Ÿï¼‰
â”œâ”€â”€ generateFromSeed.py                    # ã‚·ãƒ¼ãƒ‰å•é¡Œã‹ã‚‰ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
â”œâ”€â”€ upload_data.py                         # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’Parquetã«å¤‰æ›ã—ã€jsonã¨Parquetã‚’HFã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
â”œâ”€â”€ difficulty_scorer.py                   # å¤šæŒ‡æ¨™é›£æ˜“åº¦è©•ä¾¡ãƒ„ãƒ¼ãƒ«
â”œâ”€â”€ length_selector.py                     # å›ç­”é•·ãƒ™ãƒ¼ã‚¹åŠã‚¬ã‚¦ã‚·ã‚¢ãƒ³åˆ†å¸ƒãƒ‡ãƒ¼ã‚¿é¸æŠãƒ„ãƒ¼ãƒ«
â”œâ”€â”€ run_filter.sh                          # LLMãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨SLURMã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ run_label_filter.sh                    # ãƒ©ãƒ™ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨SLURMã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ run_length_selector.sh                 # ãƒ‡ãƒ¼ã‚¿é¸æŠç”¨SLURMã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ universal_length_selector.sh           # ãƒ¦ãƒ‹ãƒãƒ¼ã‚µãƒ«ãƒ‡ãƒ¼ã‚¿é¸æŠã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ keys.json.example                      # APIã‚­ãƒ¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
â”œâ”€â”€ results/                               # å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
```

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# ä»®æƒ³ç’°å¢ƒã®ä½œæˆã¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
python -m venv hfenv
source hfenv/bin/activate  # Linux/Mac
# ã¾ãŸã¯
hfenv\Scripts\activate     # Windows

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install torch transformers datasets huggingface-hub tqdm pandas pyarrow
pip install vllm --extra-index-url https://download.pytorch.org/whl/cu124
```

### 2. APIã‚­ãƒ¼ã®è¨­å®š

```bash
# ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
cp keys.json.example keys.json

# ãƒˆãƒ¼ã‚¯ãƒ³ã§ç·¨é›†
{
  "llm": "your_huggingface_token_here"
}
```

## ğŸ”„ SFTãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

SFTãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ä»¥ä¸‹ã®æ®µéšçš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«å¾“ã„ã¾ã™ï¼š

### ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿é¸æŠãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
**ç›®çš„**: å“è³ªã®é«˜ã„ã‚·ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠã—ã¦ã€åŠ¹æœçš„ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³ A: é«˜é€Ÿãƒ‡ãƒ¼ã‚¿é¸æŠï¼ˆæ¨å¥¨ï¼‰**
```bash
# å›ç­”é•·ãƒ™ãƒ¼ã‚¹ã§ã®é«˜é€Ÿé¸æŠ
python length_selector.py \
    --input "dataset-name" \
    --total_samples 10000 \
    --output "selected_seeds.json"
```
- âœ… é«˜é€Ÿå‡¦ç†ï¼ˆå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¯¾å¿œï¼‰
- âœ… åŠã‚¬ã‚¦ã‚·ã‚¢ãƒ³åˆ†å¸ƒã§é•·ã„å›ç­”ã‚’å„ªå…ˆé¸æŠ
- âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†å¯¾å¿œ

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³ B: é«˜ç²¾åº¦é›£æ˜“åº¦ãƒ™ãƒ¼ã‚¹é¸æŠ**
```bash
# å¤šæŒ‡æ¨™é›£æ˜“åº¦è©•ä¾¡ã«ã‚ˆã‚‹ç²¾å¯†é¸æŠ
python difficulty_scorer.py \
    --input "dataset-name" \
    --output "difficulty_scores.json" \
    --max_samples 50000
```
- âœ… è¤‡æ•°LLMã«ã‚ˆã‚‹ç·åˆé›£æ˜“åº¦è©•ä¾¡
- âœ… å¯¾æ•°ç¢ºç‡ãƒ»æ­£è§£ç‡ãƒ»IRTåˆ†æ
- âš ï¸ å‡¦ç†æ™‚é–“ãŒé•·ã„ï¼ˆå°ã€œä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‘ã‘ï¼‰

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³ C: ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹é«˜é€Ÿãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**
```bash
# äº‹å‰è¨ˆç®—ãƒ©ãƒ™ãƒ«ã«ã‚ˆã‚‹è¶…é«˜é€Ÿãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
python OpenMathReasoningFiltering_bylabel.py \
    --filter-by-pass-rate 0.1 \
    --save-per-iteration 10000
```
- âœ… æœ€é«˜é€Ÿï¼ˆLLMæ¨è«–ä¸è¦ï¼‰
- âœ… å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¯¾å¿œ
- âš ï¸ äº‹å‰ãƒ©ãƒ™ãƒ«ãŒå¿…è¦

### ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
**ç›®çš„**: é¸æŠã•ã‚ŒãŸã‚·ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ–°ã—ã„å­¦ç¿’ä¾‹ã‚’ç”Ÿæˆ

```bash
# ã‚·ãƒ¼ãƒ‰å•é¡Œã‹ã‚‰æ–°è¦ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
python generateFromSeed.py \
    --model Qwen/Qwen3-32B \
    --input_file selected_seeds.json \
    --output_file expanded_solutions.json \
    --max_tokens 4096
```
- ğŸ“ å¤šæ§˜ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ
- ğŸ¯ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§å‘ä¸Š
- âš ï¸ å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«æ¨å¥¨ï¼ˆå“è³ªç¢ºä¿ã®ãŸã‚ï¼‰

### ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
**ç›®çš„**: å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’Hugging Face Hubã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å…±æœ‰  
**æº–å‚™**: é•ã†splitã«å…¥ã‚Œã‚‹äºˆå®šã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ¥ã€…ã®ãƒ•ã‚©ãƒ«ãƒ€ã«å…¥ã‚Œã‚‹

```bash
# JSONâ†’Parquetå¤‰æ› & HFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
python upload_data.py \
    --dataset_path ./results/processed_dataset \
    --repo_id your-username/sft-dataset-name
```
- ğŸ”„ JSONâ†’Parquetè‡ªå‹•å¤‰æ›
- ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•ç”Ÿæˆ
- ğŸ”’ ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆ/ãƒ‘ãƒ–ãƒªãƒƒã‚¯ãƒªãƒã‚¸ãƒˆãƒªå¯¾å¿œ

### æ¨å¥¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¾‹

**å°è¦æ¨¡ãƒ»é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ<10Kä»¶ï¼‰**
```bash
# 1. é›£æ˜“åº¦ãƒ™ãƒ¼ã‚¹ç²¾å¯†é¸æŠ
python difficulty_scorer.py --input "dataset" --max_samples 5000
# 2. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
python generateFromSeed.py --input_file scored_data.json
# 3. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
python upload_data.py --dataset_path ./results
```

**å¤§è¦æ¨¡ãƒ»åŠ¹ç‡é‡è¦–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ>100Kä»¶ï¼‰**
```bash
# 1. é•·ã•ãƒ™ãƒ¼ã‚¹é«˜é€Ÿé¸æŠ
python length_selector.py --input "dataset" --total_samples 50000
# 2. ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæ‹¡å¼µã‚¹ã‚­ãƒƒãƒ—ï¼‰
python upload_data.py --dataset_path ./results
```

**è¶…å¤§è¦æ¨¡ãƒ»ãƒ©ãƒ™ãƒ«åˆ©ç”¨å¯èƒ½ï¼ˆ>1Mä»¶ï¼‰**
```bash
# 1. ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹è¶…é«˜é€Ÿãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
python OpenMathReasoningFiltering_bylabel.py --filter-by-pass-rate 0.05
# 2. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
python upload_data.py --dataset_path ./results
```


## ğŸ“‹ ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½¿ç”¨ã‚¬ã‚¤ãƒ‰

### ğŸ·ï¸ ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ¨å¥¨ï¼‰

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆ:** `OpenMathReasoningFiltering_bylabel.py`  
**ç›®çš„:** äº‹å‰è¨ˆç®—ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨ã—ãŸé«˜é€Ÿãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€LLMæ¨è«–ä¸è¦

```bash
# åŸºæœ¬ä½¿ç”¨æ³• - ãƒ‘ã‚¹ç‡é–¾å€¤ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
python OpenMathReasoningFiltering_bylabel.py \
    --filter-by-pass-rate 0.1 \
    --save-per-iteration 10000

# å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”¨ã®ã‚«ã‚¹ã‚¿ãƒ ãƒãƒƒãƒã‚µã‚¤ã‚º
python OpenMathReasoningFiltering_bylabel.py \
    --filter-by-pass-rate 0.05 \
    --save-per-iteration 50000 \
    --batch-size 5000
```

**ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `--filter-by-pass-rate`: ãƒ‘ã‚¹ç‡é–¾å€¤ï¼ˆ0.0-1.0ï¼‰ã€‚ä½ã„ã»ã©é›£ã—ã„å•é¡Œ
- `--save-per-iteration`: ãƒ¡ãƒ¢ãƒªå•é¡Œã‚’é¿ã‘ã‚‹ãŸã‚Nä¾‹ã”ã¨ã«çµæœã‚’ä¿å­˜
- `--batch-size`: ãƒ¡ãƒ¢ãƒªç®¡ç†ç”¨ã®å‡¦ç†ãƒãƒƒãƒã‚µã‚¤ã‚º

**å‡ºåŠ›:** `results/filtered_dataset/`å†…ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿JSONãƒ•ã‚¡ã‚¤ãƒ«

---

### ğŸ¤– LLMãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå°‘é‡ãƒ‡ãƒ¼ã‚¿ã®é«˜ç²¾åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆ:** `OpenMathReasoningFiltering.py`  
**ç›®çš„:** ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°åŸºæº–ã®ãŸã‚ã®LLMæ¨è«–ä½¿ç”¨   
**æ³¨æ„:**ã€€æ¨è«–é€Ÿåº¦ãŒã‹ãªã‚Šé…ã„ï¼ˆQwen3-32Bã§ï¼•ï¼s/ä»¶ï¼‰ã‹ã‚‰å¤§é‡ãƒ‡ãƒ¼ã‚¿ï¼ˆï¼ï¼•ï¼ï¼ï¼ä»¶ï¼‰ã§ã¯ä½¿ãˆãªã„

```bash
# Qwenãƒ¢ãƒ‡ãƒ«ã§ã®åŸºæœ¬LLMãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
python OpenMathReasoningFiltering.py \
    --inference-model Qwen/Qwen3-32B \
    --judgement-model Qwen/Qwen3-32B \
    --inference-batch-size 8 \
    --judgement-batch-size 8 \
    --start-from-percentage 0.0 \
    --end-at-percentage 1.0

# ãƒ†ãƒ³ã‚½ãƒ«ä¸¦åˆ—åŒ–ã«ã‚ˆã‚‹ãƒãƒ«ãƒGPUã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
python OpenMathReasoningFiltering.py \
    --inference-model Qwen/Qwen3-32B \
    --inference-tp 2 \
    --inference-batch-size 4 \
    --vllm-batch-size 32 \
    --judgement-model Qwen/Qwen3-32B \
    --judgement-tp 2
```

**ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `--inference-model`: ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆç”¨ãƒ¢ãƒ‡ãƒ«
- `--judgement-model`: ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡ç”¨ãƒ¢ãƒ‡ãƒ«
- `--inference-tp`: ãƒ†ãƒ³ã‚½ãƒ«ä¸¦åˆ—åŒ–ã‚µã‚¤ã‚ºï¼ˆ2GPUã®å ´åˆã¯2ï¼‰
- `--vllm-batch-size`: vLLMå‡¦ç†ç”¨ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆå¤§ãã„ã»ã©åŠ¹ç‡çš„ï¼‰
- `--start-from-percentage/--end-at-percentage`: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸€éƒ¨ã‚’å‡¦ç†

**å‡ºåŠ›:** æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®æ¨è«–ã¨åˆ¤å®šçµæœ

---

### ğŸŒ± ã‚·ãƒ¼ãƒ‰å•é¡Œã‹ã‚‰ã®ç”Ÿæˆ

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆ:** `generateFromSeed.py`  
**ç›®çš„:** ã‚·ãƒ¼ãƒ‰å•é¡Œã‹ã‚‰æ–°ã—ã„ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ
**æ³¨æ„:** 
1. ç”Ÿæˆã®è³ªã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã€Qwen3-32Bãªã©å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ãŒãŠã™ã™ã‚ã€‚å°ã•ã„ãƒ¢ãƒ‡ãƒ«ï¼ˆQwen3-8Bï¼‰ã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ±å‘ŠãŒã‚ã‚‹
2. æ¨è«–é€Ÿåº¦ãŒã‹ãªã‚Šé…ã„ï¼ˆQwen3-32Bã§ï¼•ï¼s/ä»¶ï¼‰ã‹ã‚‰å¤§é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆï¼ï¼•ï¼ï¼ï¼ä»¶ï¼‰ã§ã¯ä½¿ãˆãªã„

```bash
# Qwenãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ
python generateFromSeed.py \
    --model Qwen/Qwen3-32B \
    --input_file seed_problems.json \
    --output_file generated_solutions.json \
    --max_tokens 4096 \
    --temperature 0.3
```

**ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `--model`: ç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
- `--input_file`: ã‚·ãƒ¼ãƒ‰å•é¡Œã‚’å«ã‚€JSONãƒ•ã‚¡ã‚¤ãƒ«
- `--output_file`: ç”Ÿæˆã•ã‚ŒãŸã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¿å­˜å…ˆ
- `--max_tokens`: ç”Ÿæˆã‚ãŸã‚Šã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
- `--temperature`: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸©åº¦ï¼ˆ0.0 = æ±ºå®šè«–çš„ã€1.0 = ãƒ©ãƒ³ãƒ€ãƒ ï¼‰

---

### ğŸ¯ é›£æ˜“åº¦è©•ä¾¡ãƒ„ãƒ¼ãƒ«

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆ:** `difficulty_scorer.py`  
**ç›®çš„:** è³ªå•å›ç­”ãƒ‡ãƒ¼ã‚¿ã®é›£æ˜“åº¦ã‚’è¤‡æ•°ã®æŒ‡æ¨™ã§è©•ä¾¡ã—ã€ã‚¹ã‚³ã‚¢åŒ–

**æ©Ÿèƒ½:**
- è¤‡æ•°ã®å°å‹LLMï¼ˆâ‰¤8Bï¼‰ã«ã‚ˆã‚‹è©•ä¾¡
- 3ã¤ã®æŒ‡æ¨™ã‚’ä½¿ç”¨:
  1. é‡‘å›ç­”ã®å¹³å‡å¯¾æ•°ç¢ºç‡
  2. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ­£è§£ç‡  
  3. IRTé›£æ˜“åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ Î²
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„
- GPU/CPUä¸¡å¯¾å¿œã€OOMå¯¾ç­–æ¸ˆã¿
- ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¯¾å¿œ

```bash
# åŸºæœ¬çš„ãªä½¿ç”¨
python difficulty_scorer.py \
    --input "dataset-name" \
    --output "difficulty_scores.json" \
    --max_samples 10000

# HuggingFaceãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
python difficulty_scorer.py \
    --input "neko-llm/SFT_OpenMathReasoning" \
    --dataset_spec "cot" \
    --question_field "problem" \
    --answer_field "generated_solution" \
    --max_samples 50000 \
    --max_sequence_length 1024 \
    --use_float32 \
    --disable_flash_attention \
    --output "math_difficulty_scores.json"

# SLURMã§ã®å®Ÿè¡Œ
sbatch run_difficulty_scorer.sh
```

**ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `--primary_model`: ãƒ­ã‚°ç¢ºç‡è¨ˆç®—ç”¨ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: microsoft/Phi-4-mini-reasoningï¼‰
- `--ensemble_models`: è¿½åŠ è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ
- `--max_sequence_length`: å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æœ€å¤§é•·ï¼ˆOOMå¯¾ç­–ï¼‰
- `--max_input_length`: ç”Ÿæˆæ™‚å…¥åŠ›æœ€å¤§é•·ï¼ˆOOMå¯¾ç­–ï¼‰
- `--disable_flash_attention`: Flash Attentionã‚¨ãƒ©ãƒ¼å¯¾ç­–

**å‡ºåŠ›å½¢å¼:**
```json
[
  {
    "id": "item_1",
    "avg_logprob": -2.1,
    "ensemble_acc": 0.75,
    "irt_beta": 0.3,
    "difficulty_z": 1.2
  }
]
```

---

### ğŸ“Š ãƒ‡ãƒ¼ã‚¿é¸æŠãƒ„ãƒ¼ãƒ«ï¼ˆé•·ã•ãƒ™ãƒ¼ã‚¹ï¼‰

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆ:** `length_selector.py`  
**ç›®çš„:** å¿«é€Ÿã«SFTç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°  
**æ©Ÿèƒ½:**
- å›ç­”é•·ã«åŸºã¥ãåŠã‚¬ã‚¦ã‚·ã‚¢ãƒ³åˆ†å¸ƒãƒ‡ãƒ¼ã‚¿é¸æŠï¼ˆæœ€é•·å›ç­”æœ€å¤šã€æœ€çŸ­å›ç­”æœ€å°‘ï¼‰
- å‹•çš„ãƒ“ãƒ³ä½œæˆï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã«åŸºã¥ãï¼‰
- åŠã‚¬ã‚¦ã‚·ã‚¢ãƒ³åˆ†å¸ƒã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
- ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰æ–¹å¼ï¼ˆå¤–ã‚Œå€¤ã‚‚å«ã‚€ï¼‰
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†å¯¾å¿œ
- ãƒªã‚¶ãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

```bash
# åŸºæœ¬çš„ãªä½¿ç”¨
python length_selector.py \
    --input "dataset-name" \
    --total_samples 5000 \
    --output "selected_data.json"

# è©³ç´°è¨­å®š
python length_selector.py \
    --input "neko-llm/SFT_OpenMathReasoning" \
    --dataset_spec "cot" \
    --answer_field "generated_solution" \
    --total_samples 10000 \
    --num_bins 8 \
    --curve_sharpness 3.0 \
    --sample_size_for_stats 2000 \
    --shuffle \
    --output "math_selected.json"

# SLURMã§ã®å®Ÿè¡Œ
sbatch run_length_selector.sh
# ã¾ãŸã¯
./universal_length_selector.sh "dataset-name" 5000
```

**ä¸»è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:**
- `--curve_sharpness`: åˆ†å¸ƒã®é‹­ã•ï¼ˆ1.0=ç·©ã‚„ã‹ã€2.0=æ¨™æº–ã€4.0=é‹­ã„ï¼‰
- `--num_bins`: ãƒ“ãƒ³æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 6ï¼‰
- `--sample_size_for_stats`: ãƒ“ãƒ³ä½œæˆç”¨ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1000ï¼‰
- `--shuffle`: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ©ãƒ³ãƒ€ãƒ é †ã§å‡¦ç†

**åˆ†å¸ƒä¾‹ï¼ˆ6ãƒ“ãƒ³ï¼‰:**
```
Bin 0 (shortest): 100 samples (10%)   â† æœ€å°‘
Bin 1: 200 samples (20%)
Bin 2: 300 samples (30%)
Bin 3: 400 samples (40%)
Bin 4: 500 samples (50%)
Bin 5 (longest): 600 samples (60%)    â† æœ€å¤š
```

---

### ğŸ“¤ Hugging Faceã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆ:** `upload_data.py`
**ç›®çš„:** JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’Parquetã«å¤‰æ›ã—ã€JSONã¨Parquetä¸¡æ–¹ã‚’Hugging Face Hubã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰  
**èª¬æ˜:** Parquetå½¢å¼ãŒ`datasets.load_dataset()`ã§ç›´æ¥ä½¿ãˆã‚‹ã€‚JSON/JSONLãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§è¦æ¨¡ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ™‚ã«ä½¿ã„ã‚„ã™ã„ã€‚  
**æ©Ÿèƒ½:**
- å„JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å€‹åˆ¥ã®Parquetãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ï¼‰
- splitãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ããƒ•ã‚¡ã‚¤ãƒ«åã§åŒºåˆ¥å¯èƒ½
- äº’æ›æ€§ã®ãŸã‚å…ƒã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿æŒ
- YAML ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§å„splitã®è¨­å®šã‚’è‡ªå‹•ç”Ÿæˆ
- ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¯¾å¿œ
- æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¹ã‚­ãƒƒãƒ—æ©Ÿèƒ½


```bash
# åŸºæœ¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚«ãƒ¼ãƒ‰è‡ªå‹•ç”Ÿæˆï¼‰
python upload_data.py \
    --dataset_path ./results/filtered_dataset \
    --repo_id your-username/dataset-name

# æ—¢å­˜ã®READMEãŒã‚ã‚‹å ´åˆã¯original_README.logã‹ã‚‰èª­ã¿è¾¼ã¿
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã¯å¸¸ã«ç”Ÿæˆã•ã‚Œã‚‹
```

**æœŸå¾…ã•ã‚Œã‚‹å…¥åŠ›æ§‹é€ :**
```
dataset_path/
â”œâ”€â”€ split_1(ãƒãƒ¼ãƒ ã¯è‡ªç”±)/
â”‚   â”œâ”€â”€ file1.json
â”‚   â”œâ”€â”€ file2.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ split_2/
â”‚   â”œâ”€â”€ file1.json
â”‚   â””â”€â”€ ...
â””â”€â”€ split_3/
â”‚   â””â”€â”€ file1.json
â””â”€â”€ original_readme.log (ä»»æ„, mdå½¢å¼ã§huggingfaceã§ä½¿ã„ãŸã„readmeã‚’ä¸­ã«ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ã¨readmeã‚’è‡ªå‹•ç”Ÿæˆ)
```

**å‡ºåŠ›æ§‹é€ :**
```
dataset_path/
â”œâ”€â”€ train/ (å…ƒã®JSONãƒ•ã‚¡ã‚¤ãƒ«)
â”œâ”€â”€ validation/ (å…ƒã®JSONãƒ•ã‚¡ã‚¤ãƒ«)  
â”œâ”€â”€ test/ (å…ƒã®JSONãƒ•ã‚¡ã‚¤ãƒ«)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train_file1.parquet    # splitãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ã
â”‚   â”œâ”€â”€ train_file2.parquet    # splitãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ã
â”‚   â”œâ”€â”€ validation_file1.parquet
â”‚   â””â”€â”€ test_file1.parquet
â””â”€â”€ README.md (YAML ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ã)
```

**è‡ªå‹•ç”Ÿæˆã™ã‚‹YAML ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¾‹:**
```yaml
---
configs:
- config_name: cot
  data_files:
    - "data/cot_file1.parquet"
    - "data/cot_file2.parquet"
- config_name: genselect
  data_files: "data/genselect_file1.parquet"
---
```

**ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿æ–¹æ³•:**
```python
from datasets import load_dataset

# ç‰¹å®šã®splitã‚’èª­ã¿è¾¼ã‚€
train_data = load_dataset("your-username/dataset-name", "cot", "split"="train")
val_data = load_dataset("your-username/dataset-name", "genselect", "split"="train")

# ã¾ãŸã¯æ‰‹å‹•ã§data_filesã‚’æŒ‡å®š
dataset = load_dataset(
    "parquet",
    data_files={
        "train": "data/train_*.parquet",
        "validation": "data/validation_*.parquet",
    }
)

# å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
import pandas as pd
df = pd.read_parquet("data/train_file1.parquet")
```

---

## ğŸ–¥ï¸ SLURMã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### HPC/ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä½¿ç”¨ç”¨

**ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°:**
```bash
sbatch run_label_filter.sh
```

**LLMãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°:**
```bash
sbatch run_filter.sh
```

**é›£æ˜“åº¦è©•ä¾¡:**
```bash
sbatch run_difficulty_scorer.sh
```

**ãƒ‡ãƒ¼ã‚¿é¸æŠ:**
```bash
sbatch run_length_selector.sh
# ã¾ãŸã¯
./universal_length_selector.sh "dataset-name" 5000
```

å„ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™:
- GPUãƒªã‚½ãƒ¼ã‚¹å‰²ã‚Šå½“ã¦
- ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- CUDAè¨­å®š
- ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–è¨­å®š

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒ

å‡¦ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ä»¥ä¸‹ã®ã‚¹ã‚­ãƒ¼ãƒã«å¾“ã„ã¾ã™ (OpenMathã‚’ä¾‹ã«):

```json
{
  "problem": "string",           // æ•°å­¦å•é¡Œæ–‡
  "answer": "string",           // æ­£è§£
  "generated_solution": "string", // ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³
  "problem_type": "string",     // å•é¡Œã‚¿ã‚¤ãƒ—è­˜åˆ¥å­
  "pass_rate_72b_tir": "float", // é›£æ˜“åº¦ãƒ¡ãƒˆãƒªãƒƒã‚¯ï¼ˆ0.0-1.0ï¼‰
  "dataset": "string"           // ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè­˜åˆ¥å­
}
```

## ğŸ”§ è¨­å®šã®ãƒ’ãƒ³ãƒˆ

### å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”¨
- åˆæœŸå‡¦ç†ã«ã¯ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨
- é©åˆ‡ãª`--save-per-iteration`å€¤ã‚’è¨­å®š
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åˆ¶å¾¡ã™ã‚‹ãŸã‚`--batch-size`ã‚’ä½¿ç”¨

### ãƒãƒ«ãƒGPUã‚·ã‚¹ãƒ†ãƒ ç”¨
- ãƒ†ãƒ³ã‚½ãƒ«ä¸¦åˆ—åŒ–ã‚’ä½¿ç”¨ï¼ˆ`--inference-tp 2`ã§2GPUï¼‰
- ã‚ˆã‚Šè‰¯ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®ãŸã‚`--vllm-batch-size`ã‚’å¢—åŠ 
- `nvidia-smi`ã§GPUãƒ¡ãƒ¢ãƒªã‚’ç›£è¦–

### ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ç”¨
- å€‹åˆ¥ã®Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ï¼ˆãƒãƒ¼ã‚¸ã—ãªã„ï¼‰
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã§å‡¦ç†
- åˆ©ç”¨å¯èƒ½ãªRAMã«åŸºã¥ã„ã¦é©åˆ‡ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’è¨­å®š

### ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨
- ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã§ã¯YAMLãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
- `original_README.log`ã§æ—¢å­˜READMEã‚’ä¿æŒ
- æ—¢å­˜Parquetãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹
- splitãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ•´ç†

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ä¸€èˆ¬çš„ãªå•é¡Œ

**ãƒ¡ãƒ¢ãƒªä¸è¶³:**
```bash
# ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
--inference-batch-size 1 --vllm-batch-size 16

# ãƒ†ãƒ³ã‚½ãƒ«ä¸¦åˆ—åŒ–ã‚’ä½¿ç”¨
--inference-tp 2
```

**CUDAã‚¨ãƒ©ãƒ¼:**
```bash
# ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
export CUDA_VISIBLE_DEVICES=0,1
export VLLM_USE_FLASH_ATTENTION=1
```

**ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—:**
```bash
# Hugging Faceãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç¢ºèª
cat keys.json

# ãƒªãƒã‚¸ãƒˆãƒªæ¨©é™ã‚’ç¢ºèª
# ãƒªãƒã‚¸ãƒˆãƒªã¸ã®æ›¸ãè¾¼ã¿æ¨©é™ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
```

## ğŸ“ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¾‹

### å®Œå…¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```bash
# 1. ãƒ©ãƒ™ãƒ«ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆé«˜é€Ÿï¼‰
python OpenMathReasoningFiltering_bylabel.py \
    --filter-by-pass-rate 0.1 \
    --save-per-iteration 10000

# 2. Hugging Faceã«å¤‰æ›ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
python upload_data.py \
    --dataset_path ./results/filtered_dataset \
    --repo_id your-username/openmath-filtered

# 3. è¿½åŠ ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
python generateFromSeed.py \
    --model Qwen/Qwen3-8B \
    --input_file ./results/filtered_dataset/train/hard_problems.json \
    --output_file ./results/generated_solutions.json
```

### ã‚«ã‚¹ã‚¿ãƒ LLMãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```bash
# 1. ã‚«ã‚¹ã‚¿ãƒ åŸºæº–ã§å‰åŠã‚’å‡¦ç†
python OpenMathReasoningFiltering.py \
    --inference-model Qwen/Qwen3-32B \
    --start-from-percentage 0.0 \
    --end-at-percentage 0.5

# 2. ä¸¦åˆ—ã§å¾ŒåŠã‚’å‡¦ç†
python OpenMathReasoningFiltering.py \
    --inference-model Qwen/Qwen3-32B \
    --start-from-percentage 0.5 \
    --end-at-percentage 1.0

# 3. çµæœã‚’çµåˆã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
python upload_data.py \
    --dataset_path ./results/combined_dataset \
    --repo_id your-username/custom-filtered
```

## ğŸ“‹ è¦ä»¶

- Python 3.8+
- CUDAã‚µãƒãƒ¼ãƒˆä»˜ãPyTorch
- åŠ¹ç‡çš„ãªæ¨è«–ç”¨vLLM
- Hugging Face Hubã‚¢ã‚«ã‚¦ãƒ³ãƒˆ
- ååˆ†ãªGPUãƒ¡ãƒ¢ãƒªï¼ˆ8GB+æ¨å¥¨ï¼‰
- å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”¨: 32GB+ RAMæ¨å¥¨

## ğŸ“ ã‚µãƒãƒ¼ãƒˆ

å•é¡Œã‚„è³ªå•ã«ã¤ã„ã¦ã¯:
1. ä¸Šè¨˜ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç¢ºèª
2. `--help`ã§ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç¢ºèª
3. å‡¦ç†ä¸­ã®ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ã‚’ç›£è¦–
4. é©åˆ‡ãªç’°å¢ƒè¨­å®šã‚’ç¢ºèª
5. Slackã§`@Junyu Liu`ã«é€£çµ¡
